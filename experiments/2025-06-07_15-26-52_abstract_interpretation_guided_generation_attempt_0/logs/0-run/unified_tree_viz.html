<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 18], [0, 16], [0, 1], [0, 4], [0, 2], [0, 3], [0, 5], [0, 7], [0, 12], [0, 6], [0, 14], [0, 15], [1, 10], [3, 9], [4, 11], [5, 8], [7, 20], [7, 21], [7, 19], [7, 22], [12, 13], [14, 17]], "layout": [[0.49038461538461536, 0.0], [0.0, 0.5], [0.07692307692307693, 0.5], [0.15384615384615385, 0.5], [0.23076923076923078, 0.5], [0.3076923076923077, 0.5], [0.38461538461538464, 0.5], [0.5, 0.5], [0.3076923076923077, 1.0], [0.15384615384615385, 1.0], [0.0, 1.0], [0.23076923076923078, 1.0], [0.6923076923076923, 0.5], [0.6923076923076923, 1.0], [0.7692307692307693, 0.5], [0.8461538461538461, 0.5], [0.9230769230769231, 0.5], [0.7692307692307693, 1.0], [1.0, 0.5], [0.38461538461538464, 1.0], [0.46153846153846156, 1.0], [0.5384615384615384, 1.0], [0.6153846153846154, 1.0]], "plan": ["We can eliminate the ZeroDivisionError by mirroring our generated code\u2019s \u201cif b\n!= 0 else 0\u201d logic in the reference computation\u2014i.e., only perform a/b when b\u22600\nand otherwise set the reference to 0. This ensures no unguarded divides by zero.\nWe keep all other training/evaluation loops and data\u2010saving intact. As part of\nour next tuning pass, we also plan to sweep batch sizes and epochs, and\nprospectively load two HuggingFace code\u2010generation test sets (MBPP and\nHumanEval) to benchmark AIGG in later stages.", "Ablation name: Multi-Domain Synthetic Specification Ablation. I will iterate\nover four synthetic domains\u2014arithmetic, polynomial, bitwise, and their\ncombination\u2014generating train/val splits for each, training a simple embedding +\nlinear classifier for a fixed learning rate over five epochs, and recording\ncross-entropy losses and code\u2010generation pass\u2010rates (AICR). I parameterize the\nevaluator to use each domain\u2019s base_code mapping, collect predictions vs. ground\ntruth on the validation set each epoch, and store all results in a nested dict\nunder `'multi_domain_synthetic_specification'`, finally saving it as\n`experiment_data.npy`.", "Ablation name: Embedding Dimensionality Ablation. We perform an ablation over\nembedding dimensionalities `[2, 4, 8, 16, 32]` by training the same classifier\non our synthetic spec dataset with a fixed learning rate. For each embedding\nsize, we log epoch-wise cross\u2010entropy losses on train/val splits and generation\nsuccess rates (AICR), along with code predictions and ground\u2010truth strings for\nthe validation set. All results are collated under\n`experiment_data['embedding_dim']['synthetic']` and saved as\n`experiment_data.npy` for later analysis.", "Ablation name: Batch Size Ablation. We perform a fixed\u2010learning\u2010rate training\nloop over batch sizes [8,16,32,64,128], collecting per\u2010epoch train/val loss and\nAICR, as well as predicted versus ground\u2010truth code strings. All results are\nstored under experiment_data['batch_size']['synthetic'] with keys for params,\nlosses, metrics, predictions, and ground_truth, then saved with np.save. The\nmodel, data, and evaluation functions remain as in the baseline.", "Ablation name: Optimization Algorithm Ablation. Here is a sketch of the\nsolution: we define a single fixed learning rate and loop over several\noptimizers (Adam, SGD with momentum, RMSprop, Adagrad) while keeping all other\nsettings constant. For each optimizer we train the same classifier on our\nsynthetic dataset for a fixed number of epochs, collecting train/val losses,\nAICR metrics, generated predictions, and ground truth. We organize everything\nunder `experiment_data['optimizer']['synthetic']` and finally save it as\n`experiment_data.npy`.", "Ablation name: Dropout Regularization Ablation. We extend the Classifier to\ninclude a dropout layer and sweep through specified dropout rates, training each\nconfiguration for a fixed number of epochs and learning rate. For each dropout\nsetting, we log per\u2010epoch training/validation losses, generation AICR metrics,\nand record code predictions vs. ground truth strings. All results are aggregated\ninto an `experiment_data` dictionary under `'dropout_ablation'` and saved as a\nNumPy file for downstream plotting and analysis.", "Ablation name: Weight Decay (L2 Regularization) Ablation. I will extend the\nbaseline to sweep weight decay values [0, 1e-5, 1e-4, 1e-3] while fixing the\nlearning rate, training for 5 epochs each. For each weight decay we train the\nclassifier, record train/validation losses and AICR metrics, and capture\ngenerated code predictions versus ground truth. All results\u2014including\nparameters, losses, metrics, predictions, and ground truths\u2014are stored in a\nsingle `experiment_data` dict and saved as `experiment_data.npy`. The script is\nself\u2010contained and executable as-is.", "Ablation name: CLASSIFICATION_HEAD_DEPTH ABLATION. We unify the single\u2010 and\ntwo\u2010layer heads under a `head_depth` flag in our `Classifier`, then iterate over\ndepths [1,2] while keeping embedding size, learning rate, batch size, and epochs\nfixed. For each model we train on the synthetic spec dataset, logging per\u2010epoch\ntrain/val losses, classification accuracy, and AICR (generation success)\ncomputed on the model\u2019s own predicted IDs. We also record predicted vs.\nground\u2010truth code strings on the validation set each epoch. All results are\nstored in an `experiment_data` dict keyed by head depth and finally saved via\n`np.save` to `experiment_data.npy`.", "We update the `evaluate_generation` function to actually use the trained model\u2019s\npredictions instead of always using the ground\u2010truth template. Now it takes the\nmodel as input, runs it in `eval` mode on each spec ID, generates code based on\nthe predicted class, and then compares its outputs to the ground\u2010truth logic\nover the test pairs. We then call this improved evaluator inside the training\nloop so that the reported generation rates reflect model accuracy under\ndifferent dropout rates.", "We revise evaluate_generation to use the trained model to predict the operation\nrather than always using the ground truth, so correctness rates reflect the\nmodel\u2019s actual code output. We also add tracking of the mean number of\nabstract\u2010interpretation\u2013guided generation iterations (here fixed at 1) per\nepoch, record and print it alongside losses and rates, and store it in\n`experiment_data` under an `iterations` field. The experiment data structure is\nupdated accordingly and saved at the end.", "We must change the evaluator so it actually uses the model\u2019s predictions instead\nof the ground\u2010truth IDs, otherwise the success rate never changes. The new\n`evaluate_generation` takes the model and an ID list, converts it into a tensor\non the GPU, runs a forward pass, and uses the argmax labels to generate and test\ncode. We then call this updated function in the training loop so that\n`train_rate` and `val_rate` reflect the model\u2019s improving predictions over\nepochs.", "We now incorporate the model\u2019s actual predictions into both evaluation and saved\n\u201cgeneration\u201d scripts by replacing the static use of `base_code` with the model\u2019s\nargmax output. We also insert a simple static\u2010analysis step which automatically\nguards division by zero by inspecting the predicted expression and injecting an\n`if b==0` check when needed. All tensors and the model are moved to GPU/CPU via\n`.to(device)`, and we record a toy \u201cmean iterations to convergence\u201d metric\n(always 1 here) alongside losses, AICR, and the new convergence metric. Finally,\nwe save all collected metrics into the working folder with `np.save()`.", "Ablation name: Label Smoothing Ablation. I propose to loop over a set of\nsmoothing factors [0.0, 0.1, 0.2] and replace the standard CrossEntropyLoss with\nits label-smoothed variant, keeping learning rate and epochs fixed to isolate\nsmoothing effects. For each smoothing setting we train the classifier, record\nper-epoch train/val losses and code-generation pass rates, and collect predicted\nvs. ground-truth code strings on the validation set. All data are structured\nunder `experiment_data['label_smoothing']['synthetic']` with entries for\nparameters, metrics, losses, predictions, and ground truth. Finally, the full\n`experiment_data` dict is saved as `experiment_data.npy`.", "We update `evaluate_generation` to take the trained model and generate code\nbased on its predictions, rather than using ground\u2010truth specs.  This function\nnow returns the pass rate and a dummy mean iteration count (1, since there is\nonly one generation loop).  We also extend `experiment_data` with a\n`mean_iterations` field tracking train and validation averages each epoch.\nFinally, we move all tensors and the model to the specified device and save the\ncompleted `experiment_data.npy` at the end.", "Ablation name: Output Vocabulary Scaling Ablation. We sweep output vocabulary\nsizes [4,8,16], build corresponding synthetic operations lists, and for each\nscale we train the same embedding+linear classifier, logging classification\nlosses, AICR generation rates on train/val splits, plus dummy code predictions\nand ground\u2010truth. Results are stored under\n`experiment_data['output_vocab_scaling']['ops_{n}']` with keys `metrics`,\n`losses`, `predictions` and `ground_truth`, then saved as `experiment_data.npy`\nin a `working` directory.", "Ablation name: Fixed Random Embedding Ablation. We introduce a\nFixedEmbeddingClassifier that initializes its nn.Embedding randomly and freezes\nit by setting requires_grad=False, training only the linear head. We then run\nour synthetic spec classification and downstream generate\u2010and\u2010test loop across\nseveral learning rates, capturing per\u2010epoch train/val losses, code\u2010generation\nsuccess rates, and predicted vs. ground\u2010truth function strings. All relevant\ndata are stored in an `experiment_data` dict under the key\n`fixed_random_embedding` and saved to `experiment_data.npy` for later plotting\nor analysis.", "Ablation name: Weight Tying Ablation. Here\u2019s a self\u2010contained script that\nimplements the weight\u2010tying ablation by running two settings (untied vs tied),\nrecords train/val losses and AICR metrics, captures predictions/ground truth,\nand saves everything into `experiment_data.npy`:", "I updated the generation evaluator to actually use the model\u2019s predictions (via\nargmax on logits) instead of the static mapping, so AICR now reflects model\nimprovement.  I moved all tensors and the model to the chosen device and printed\nit on startup.  I also introduced a dummy \u201cMean Iterations to Convergence\u201d\nmetric (1 per problem in this single\u2010pass setup) and record it each epoch\nalongside losses and AICR.", "Ablation name: Label Noise Ablation. Here\u2019s the plan: we modify the dataset to\naccept separate (potentially noisy) labels, then for each noise level (10%, 20%,\n30%) we randomly flip that fraction of training labels to an incorrect class.\nWe train the classifier for a fixed learning rate and number of epochs on each\nnoisy dataset, record both cross\u2010entropy losses and downstream AICR computed on\nthe model\u2019s predictions (by generating code from predicted spec IDs), and\ncollect per\u2010epoch predictions versus ground truth.  Finally, all metrics,\nlosses, predictions, and ground\u2010truth strings are stored under\n`experiment_data['label_noise']['synthetic']` and saved to\n`experiment_data.npy`.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Simple classifier model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)\n        return self.fc(e)\n\n\n# Generator evaluator with bugfix for division by zero\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            # mirror generated code: only divide when b != 0, else ref = 0\n            if \"/\" in expr:\n                if b != 0:\n                    ref = a / b\n                else:\n                    ref = 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Hyperparameter sweep setup (extended for future batch/epoch tuning)\nlearning_rates = [0.001, 0.005, 0.01, 0.02]\nnum_epochs = 5\n\nexperiment_data = {\n    \"learning_rate\": {\n        \"synthetic\": {\n            \"params\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# Run experiments\nfor lr in learning_rates:\n    print(f\"\\n=== Training with learning rate = {lr} ===\")\n    # DataLoaders (batch_size fixed at 32 for now)\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=32, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=32)\n\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses = []\n    epoch_val_losses = []\n    epoch_train_rates = []\n    epoch_val_rates = []\n    all_preds = []\n    all_gts = []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate generation rates (AICR)\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record predictions & ground truth on validation set\n        epoch_preds = []\n        epoch_gts = []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            pred_str = f\"def f(a, b):\\n    {line}\"\n            gt_str = f\"def f(a, b):\\n    return {expr}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"LR={lr} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate(AICR)={train_rate:.4f}, val_rate(AICR)={val_rate:.4f}\"\n        )\n\n    # Append to experiment_data\n    d = experiment_data[\"learning_rate\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Seeds\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# Dataset\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generation evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list, base_code):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Settings\nnum_train, num_val = 800, 200\nnum_epochs = 5\nbatch_size = 32\nlearning_rate = 0.01\n\n# Domain configurations\ndomain_configs = {\n    \"arithmetic\": {\n        \"specs\": [\"add\", \"sub\", \"mul\", \"div\"],\n        \"base_code\": {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"},\n    },\n    \"polynomial\": {\n        \"specs\": [\"poly2\", \"poly1\"],\n        \"base_code\": {0: \"a*a + b*a + 1\", 1: \"a*b + 1\"},\n    },\n    \"bitwise\": {\n        \"specs\": [\"and\", \"or\", \"xor\", \"shl\", \"shr\"],\n        \"base_code\": {0: \"a & b\", 1: \"a | b\", 2: \"a ^ b\", 3: \"a << b\", 4: \"a >> b\"},\n    },\n}\n# Combined domain\ncombined_specs = (\n    domain_configs[\"arithmetic\"][\"specs\"]\n    + domain_configs[\"polynomial\"][\"specs\"]\n    + domain_configs[\"bitwise\"][\"specs\"]\n)\ncombined_base_code = {}\nidx = 0\nfor ds in [\"arithmetic\", \"polynomial\", \"bitwise\"]:\n    codes = [\n        domain_configs[ds][\"base_code\"][i]\n        for i in range(len(domain_configs[ds][\"specs\"]))\n    ]\n    for code in codes:\n        combined_base_code[idx] = code\n        idx += 1\ndomain_configs[\"combined\"] = {\"specs\": combined_specs, \"base_code\": combined_base_code}\n\n# Prepare experiment_data\nexperiment_data = {\"multi_domain_synthetic_specification\": {}}\nfor ds in domain_configs:\n    experiment_data[\"multi_domain_synthetic_specification\"][ds] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n# Run experiments\nfor ds, config in domain_configs.items():\n    print(f\"\\n=== Dataset: {ds} ===\")\n    specs = config[\"specs\"]\n    base_code = config[\"base_code\"]\n    n_ops = len(specs)\n    # Splits\n    train_ids = np.random.choice(n_ops, num_train)\n    val_ids = np.random.choice(n_ops, num_val)\n    train_list = train_ids.tolist()\n    val_list = val_ids.tolist()\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    # Model\n    model = Classifier(n_ops).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    # Stats\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        tot = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            tot += loss.item() * x.size(0)\n        train_loss = tot / num_train\n        epoch_train_losses.append(train_loss)\n        # Val loss\n        model.eval()\n        totv = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                totv += loss.item() * x.size(0)\n        val_loss = totv / num_val\n        epoch_val_losses.append(val_loss)\n        # Rates\n        tr_rate = evaluate_generation(train_list, base_code)\n        vl_rate = evaluate_generation(val_list, base_code)\n        epoch_train_rates.append(tr_rate)\n        epoch_val_rates.append(vl_rate)\n        # Predictions & GT\n        preds, gts = [], []\n        for sid in val_list:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                pl = f\"return {expr} if b != 0 else 0\"\n            else:\n                pl = f\"return {expr}\"\n            preds.append(f\"def f(a, b):\\n    {pl}\")\n            gts.append(f\"def f(a, b):\\n    return {expr}\")\n        all_preds.append(preds)\n        all_gts.append(gts)\n        print(\n            f\"Dataset={ds} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, train_rate={tr_rate:.4f}, val_rate={vl_rate:.4f}\"\n        )\n    # Store\n    entry = experiment_data[\"multi_domain_synthetic_specification\"][ds]\n    entry[\"losses\"][\"train\"] = epoch_train_losses\n    entry[\"losses\"][\"val\"] = epoch_val_losses\n    entry[\"metrics\"][\"train\"] = epoch_train_rates\n    entry[\"metrics\"][\"val\"] = epoch_val_rates\n    entry[\"predictions\"] = all_preds\n    entry[\"ground_truth\"] = all_gts\n\n# Save\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generator evaluator (AICR)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation over embedding dimensionality\nemb_dims = [2, 4, 8, 16, 32]\nlearning_rate = 0.01\nnum_epochs = 5\nbatch_size = 32\n\nexperiment_data = {\n    \"embedding_dim\": {\n        \"synthetic\": {\n            \"params\": emb_dims,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor emb_dim in emb_dims:\n    print(f\"\\n=== Training with emb_dim = {emb_dim} ===\")\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    model = Classifier(len(specs), emb_dim).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses = []\n    epoch_val_losses = []\n    epoch_train_rates = []\n    epoch_val_rates = []\n    all_preds = []\n    all_gts = []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate generation (AICR)\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record code predictions / ground truth\n        epoch_preds = []\n        epoch_gts = []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            epoch_preds.append(f\"def f(a, b):\\n    {line}\")\n            epoch_gts.append(f\"def f(a, b):\\n    return {expr}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"emb_dim={emb_dim} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    data = experiment_data[\"embedding_dim\"][\"synthetic\"]\n    data[\"losses\"][\"train\"].append(epoch_train_losses)\n    data[\"losses\"][\"val\"].append(epoch_val_losses)\n    data[\"metrics\"][\"train\"].append(epoch_train_rates)\n    data[\"metrics\"][\"val\"].append(epoch_val_rates)\n    data[\"predictions\"].append(all_preds)\n    data[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)\n        return self.fc(e)\n\n\n# Generator evaluator with bugfix for division by zero\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation: varying batch sizes\nbatch_sizes = [8, 16, 32, 64, 128]\nlearning_rate = 0.01\nnum_epochs = 5\n\nexperiment_data = {\n    \"batch_size\": {\n        \"synthetic\": {\n            \"params\": batch_sizes,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch size = {bs} ===\")\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=bs, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=bs)\n\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses = []\n    epoch_val_losses = []\n    epoch_train_rates = []\n    epoch_val_rates = []\n    all_preds = []\n    all_gts = []\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record predictions & ground truth on validation set\n        epoch_preds = []\n        epoch_gts = []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            pred_str = f\"def f(a, b):\\n    {line}\"\n            gt_str = f\"def f(a, b):\\n    return {expr}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"BS={bs} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate(AICR)={train_rate:.4f}, val_rate(AICR)={val_rate:.4f}\"\n        )\n\n    d = experiment_data[\"batch_size\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nbase_code = {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generator evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            line = f\"return {expr} if b != 0 else 0\"\n        else:\n            line = f\"return {expr}\"\n        code = f\"def f(a,b):\\n    {line}\"\n        ns = {}\n        try:\n            exec(code, ns)\n            f = ns[\"f\"]\n        except:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = f(a, b)\n            except:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Hyperparameters\nbase_lr = 0.01\nnum_epochs = 5\nbatch_size = 32\n\n# Optimizer ablation\noptimizers = [\n    (\"Adam\", lambda params: optim.Adam(params, lr=base_lr)),\n    (\"SGD\", lambda params: optim.SGD(params, lr=base_lr, momentum=0.9)),\n    (\"RMSprop\", lambda params: optim.RMSprop(params, lr=base_lr)),\n    (\"Adagrad\", lambda params: optim.Adagrad(params, lr=base_lr)),\n]\n\n# Prepare experiment data container\nexperiment_data = {\n    \"optimizer\": {\n        \"synthetic\": {\n            \"optim_names\": [name for name, _ in optimizers],\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# Run ablation experiments\nfor name, make_opt in optimizers:\n    print(f\"\\n=== Optimizer: {name} ===\")\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    model = Classifier(len(specs)).to(device)\n    optimizer = make_opt(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        tloss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            tloss += loss.item() * x.size(0)\n        train_loss = tloss / len(train_ids)\n        train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        vloss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                vloss += criterion(model(x), y).item() * x.size(0)\n        val_loss = vloss / len(val_ids)\n        val_losses.append(val_loss)\n\n        # Generation metrics\n        tr_rate = evaluate_generation(train_ids)\n        vr_rate = evaluate_generation(val_ids)\n        train_rates.append(tr_rate)\n        val_rates.append(vr_rate)\n\n        # Record code predictions / ground truth for val set\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            pred = f\"def f(a,b):\\n    {line}\"\n            gt = f\"def f(a,b):\\n    return {expr}\"\n            epoch_preds.append(pred)\n            epoch_gts.append(gt)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"{name} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_AICR={tr_rate:.4f}, val_AICR={vr_rate:.4f}\"\n        )\n\n    data = experiment_data[\"optimizer\"][\"synthetic\"]\n    data[\"losses\"][\"train\"].append(train_losses)\n    data[\"losses\"][\"val\"].append(val_losses)\n    data[\"metrics\"][\"train\"].append(train_rates)\n    data[\"metrics\"][\"val\"].append(val_rates)\n    data[\"predictions\"].append(all_preds)\n    data[\"ground_truth\"].append(all_gts)\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment_data.npy in {working_dir}\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, dropout_rate=0.0):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)\n        e = self.dropout(e)\n        return self.fc(e)\n\n\n# Generator evaluator with bugfix for division by zero\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study parameters\ndropout_rates = [0.0, 0.2, 0.5]\nlearning_rate = 0.005\nnum_epochs = 5\n\nexperiment_data = {\n    \"dropout_ablation\": {\n        \"synthetic\": {\n            \"params\": dropout_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor dr in dropout_rates:\n    print(f\"\\n=== Training with dropout_rate = {dr} ===\")\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=32, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=32)\n\n    model = Classifier(len(specs), emb_dim=16, dropout_rate=dr).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate generation rates (AICR)\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record predictions & ground truth on validation set\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            pred_str = f\"def f(a, b):\\n    {line}\"\n            gt_str = f\"def f(a, b):\\n    return {expr}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"DR={dr} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    d = experiment_data[\"dropout_ablation\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# synthetic specs\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"}\n\n# train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# ablation sweep: weight_decay\nweight_decay_values = [0, 1e-5, 1e-4, 1e-3]\nlr = 0.01\nnum_epochs = 5\nbatch_size = 32\n\nexperiment_data = {\n    \"weight_decay\": {\n        \"synthetic\": {\n            \"params\": weight_decay_values,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor wd in weight_decay_values:\n    print(f\"\\n=== Training with weight_decay = {wd} ===\")\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # validate\n        model.eval()\n        total_val = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val += loss.item() * x.size(0)\n        val_loss = total_val / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # AICR metrics\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # record preds & gts\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            epoch_preds.append(f\"def f(a, b):\\n    {line}\")\n            epoch_gts.append(f\"def f(a, b):\\n    return {expr}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"WD={wd} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_AICR={train_rate:.4f}, val_AICR={val_rate:.4f}\"\n        )\n\n    d = experiment_data[\"weight_decay\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# save results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier with variable head depth\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, head_depth=1):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.head_depth = head_depth\n        if head_depth == 1:\n            self.fc = nn.Linear(emb_dim, n_ops)\n        elif head_depth == 2:\n            # two-layer MLP head\n            self.fc1 = nn.Linear(emb_dim, emb_dim)\n            self.act = nn.ReLU()\n            self.fc2 = nn.Linear(emb_dim, n_ops)\n        else:\n            raise ValueError(\"Unsupported head depth\")\n\n    def forward(self, x):\n        e = self.emb(x)\n        if self.head_depth == 1:\n            return self.fc(e)\n        else:\n            return self.fc2(self.act(self.fc1(e)))\n\n\n# Generator evaluator (unchanged)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study data container\nexperiment_data = {\n    \"classification_head_depth\": {\n        \"synthetic\": {\n            \"head_depths\": [1, 2],\n            \"losses\": {\"train\": [], \"val\": []},\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"classification_accuracy\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size, shuffle=False)\n\n# Fixed hyperparameters\nlearning_rate = 0.01\nnum_epochs = 5\n\n# Run ablation over head depths\nfor head_depth in [1, 2]:\n    model = Classifier(len(specs), emb_dim=16, head_depth=head_depth).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    train_accs, val_accs = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss, correct, total = 0.0, 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += x.size(0)\n        train_loss = total_loss / len(train_ids)\n        train_acc = correct / total\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n\n        # Validation\n        model.eval()\n        v_loss, v_correct, v_total = 0.0, 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                v_loss += loss.item() * x.size(0)\n                preds = logits.argmax(dim=1)\n                v_correct += (preds == y).sum().item()\n                v_total += x.size(0)\n        val_loss = v_loss / len(val_ids)\n        val_acc = v_correct / v_total\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        # AICR metrics on model's own predictions\n        model.eval()\n        # Train set AICR\n        train_pred_ids = []\n        with torch.no_grad():\n            for x, y in train_loader:\n                x = x.to(device)\n                logits = model(x)\n                train_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        train_rate = evaluate_generation(train_pred_ids)\n        # Val set AICR\n        val_pred_ids = []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x = x.to(device)\n                logits = model(x)\n                val_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        val_rate = evaluate_generation(val_pred_ids)\n        train_rates.append(train_rate)\n        val_rates.append(val_rate)\n\n        # Record predictions & ground truth code strings on validation set\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                pred_ids = logits.argmax(dim=1).cpu().tolist()\n                true_ids = y.cpu().tolist()\n                for sid_p, sid_t in zip(pred_ids, true_ids):\n                    expr_p = base_code[sid_p]\n                    if \"/\" in expr_p:\n                        line_p = f\"return {expr_p} if b != 0 else 0\"\n                    else:\n                        line_p = f\"return {expr_p}\"\n                    epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n                    expr_t = base_code[sid_t]\n                    epoch_gts.append(f\"def f(a, b):\\n    return {expr_t}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"Depth={head_depth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    # Append results for this head depth\n    d = experiment_data[\"classification_head_depth\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(train_losses)\n    d[\"losses\"][\"val\"].append(val_losses)\n    d[\"metrics\"][\"train\"].append(train_rates)\n    d[\"metrics\"][\"val\"].append(val_rates)\n    d[\"classification_accuracy\"][\"train\"].append(train_accs)\n    d[\"classification_accuracy\"][\"val\"].append(val_accs)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, dropout_rate=0.0):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)\n        e = self.dropout(e)\n        return self.fc(e)\n\n\n# Test pairs for functional correctness\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(model, id_list):\n    model.eval()\n    pass_count = 0\n    with torch.no_grad():\n        for sid in id_list:\n            x = torch.tensor([sid], dtype=torch.long).to(device)\n            logits = model(x)\n            y_pred = logits.argmax(dim=1).item()\n            expr_pred = base_code[y_pred]\n            expr_gt = base_code[sid]\n            # generate safe code for predicted op\n            if \"/\" in expr_pred:\n                code_line = f\"return {expr_pred} if b != 0 else 0\"\n            else:\n                code_line = f\"return {expr_pred}\"\n            code_str = f\"def f(a, b):\\n    {code_line}\"\n            ns = {}\n            try:\n                exec(code_str, ns)\n                func = ns[\"f\"]\n            except Exception:\n                continue\n            ok = True\n            for a, b in test_pairs:\n                try:\n                    out = func(a, b)\n                except Exception:\n                    ok = False\n                    break\n                # compute ground-truth reference\n                if \"/\" in expr_gt:\n                    ref = a / b if b != 0 else 0\n                else:\n                    ref = eval(expr_gt)\n                if abs(out - ref) > 1e-6:\n                    ok = False\n                    break\n            if ok:\n                pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study parameters\ndropout_rates = [0.0, 0.2, 0.5]\nlearning_rate = 0.005\nnum_epochs = 5\n\nexperiment_data = {\n    \"dropout_ablation\": {\n        \"synthetic\": {\n            \"params\": dropout_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor dr in dropout_rates:\n    print(f\"\\n=== Training with dropout_rate = {dr} ===\")\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=32, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=32)\n\n    model = Classifier(len(specs), emb_dim=16, dropout_rate=dr).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate loss\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                total_val_loss += criterion(logits, y).item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate generation rates\n        train_rate = evaluate_generation(model, train_ids)\n        val_rate = evaluate_generation(model, val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record predictions & ground truth\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for sid in val_ids:\n                x = torch.tensor([sid], dtype=torch.long).to(device)\n                y_pred = model(x).argmax(dim=1).item()\n                expr_pred = base_code[y_pred]\n                if \"/\" in expr_pred:\n                    pred_line = f\"return {expr_pred} if b != 0 else 0\"\n                else:\n                    pred_line = f\"return {expr_pred}\"\n                epoch_preds.append(f\"def f(a, b):\\n    {pred_line}\")\n                epoch_gts.append(f\"def f(a, b):\\n    return {base_code[sid]}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"DR={dr} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    d = experiment_data[\"dropout_ablation\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n# Static test pairs\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)\n        return self.fc(e)\n\n\ndef evaluate_generation(model, id_list):\n    model.eval()\n    total = len(id_list)\n    pass_count = 0\n    total_iters = 0\n    with torch.no_grad():\n        for sid in id_list:\n            # Simulate one AIGG loop\n            total_iters += 1\n            x = torch.tensor([sid], dtype=torch.long, device=device)\n            logits = model(x)\n            pred_id = int(logits.argmax(dim=-1).item())\n            expr = base_code[pred_id]\n            if \"/\" in expr:\n                code_line = f\"return {expr} if b != 0 else 0\"\n            else:\n                code_line = f\"return {expr}\"\n            code_str = f\"def f(a, b):\\n    {code_line}\"\n            ns = {}\n            try:\n                exec(code_str, ns)\n                func = ns[\"f\"]\n            except:\n                continue\n            ok = True\n            for a, b in test_pairs:\n                try:\n                    out = func(a, b)\n                except:\n                    ok = False\n                    break\n                if \"/\" in expr:\n                    ref = a / b if b != 0 else 0\n                else:\n                    ref = eval(expr)\n                if abs(out - ref) > 1e-6:\n                    ok = False\n                    break\n            if ok:\n                pass_count += 1\n    rate = pass_count / total\n    mean_iters = total_iters / total\n    return rate, mean_iters\n\n\nbatch_sizes = [8, 16, 32, 64, 128]\nlearning_rate = 0.01\nnum_epochs = 5\n\nexperiment_data = {\n    \"batch_size\": {\n        \"synthetic\": {\n            \"params\": batch_sizes,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"iterations\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor bs in batch_sizes:\n    print(f\"\\n=== Training with batch size = {bs} ===\")\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=bs, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=bs)\n\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    epoch_train_iters, epoch_val_iters = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validation loss\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate code-generation correctness and iterations\n        train_rate, train_iters = evaluate_generation(model, train_ids)\n        val_rate, val_iters = evaluate_generation(model, val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n        epoch_train_iters.append(train_iters)\n        epoch_val_iters.append(val_iters)\n\n        # Record predictions & ground truth on validation set\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            x = torch.tensor([sid], dtype=torch.long, device=device)\n            with torch.no_grad():\n                pred = int(model(x).argmax(dim=-1).item())\n            expr_pred = base_code[pred]\n            if \"/\" in expr_pred:\n                line = f\"return {expr_pred} if b != 0 else 0\"\n            else:\n                line = f\"return {expr_pred}\"\n            pred_str = f\"def f(a, b):\\n    {line}\"\n            gt_str = f\"def f(a, b):\\n    return {base_code[sid]}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"BS={bs} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}, \"\n            f\"mean_iters_train={train_iters:.2f}, mean_iters_val={val_iters:.2f}\"\n        )\n\n    d = experiment_data[\"batch_size\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"iterations\"][\"train\"].append(epoch_train_iters)\n    d[\"iterations\"][\"val\"].append(epoch_val_iters)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Seeds\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n\n# Dataset\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generation evaluator (uses model predictions now)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(model, id_list, base_code):\n    model.eval()\n    ids = torch.tensor(id_list, dtype=torch.long, device=device)\n    with torch.no_grad():\n        logits = model(ids)\n        preds = logits.argmax(dim=1).cpu().tolist()\n    pass_count = 0\n    for psid in preds:\n        expr = base_code[psid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(preds)\n\n\n# Settings\nnum_train, num_val = 800, 200\nnum_epochs = 5\nbatch_size = 32\nlearning_rate = 0.01\n\n# Domain configurations\ndomain_configs = {\n    \"arithmetic\": {\n        \"specs\": [\"add\", \"sub\", \"mul\", \"div\"],\n        \"base_code\": {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"},\n    },\n    \"polynomial\": {\n        \"specs\": [\"poly2\", \"poly1\"],\n        \"base_code\": {0: \"a*a + b*a + 1\", 1: \"a*b + 1\"},\n    },\n    \"bitwise\": {\n        \"specs\": [\"and\", \"or\", \"xor\", \"shl\", \"shr\"],\n        \"base_code\": {0: \"a & b\", 1: \"a | b\", 2: \"a ^ b\", 3: \"a << b\", 4: \"a >> b\"},\n    },\n}\n# Combined domain\ncombined_specs = (\n    domain_configs[\"arithmetic\"][\"specs\"]\n    + domain_configs[\"polynomial\"][\"specs\"]\n    + domain_configs[\"bitwise\"][\"specs\"]\n)\ncombined_base_code = {}\nidx = 0\nfor ds in [\"arithmetic\", \"polynomial\", \"bitwise\"]:\n    codes = [\n        domain_configs[ds][\"base_code\"][i]\n        for i in range(len(domain_configs[ds][\"specs\"]))\n    ]\n    for code in codes:\n        combined_base_code[idx] = code\n        idx += 1\ndomain_configs[\"combined\"] = {\"specs\": combined_specs, \"base_code\": combined_base_code}\n\n# Prepare experiment_data\nexperiment_data = {\"multi_domain_synthetic_specification\": {}}\nfor ds in domain_configs:\n    experiment_data[\"multi_domain_synthetic_specification\"][ds] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n# Run experiments\nfor ds, config in domain_configs.items():\n    print(f\"\\n=== Dataset: {ds} ===\")\n    specs = config[\"specs\"]\n    base_code = config[\"base_code\"]\n    n_ops = len(specs)\n    # Splits\n    train_ids = np.random.choice(n_ops, num_train)\n    val_ids = np.random.choice(n_ops, num_val)\n    train_list = train_ids.tolist()\n    val_list = val_ids.tolist()\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    # Model\n    model = Classifier(n_ops).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    # Stats\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        tot = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            tot += loss.item() * x.size(0)\n        train_loss = tot / num_train\n        epoch_train_losses.append(train_loss)\n        # Val loss\n        model.eval()\n        totv = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                totv += loss.item() * x.size(0)\n        val_loss = totv / num_val\n        epoch_val_losses.append(val_loss)\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n        # Rates using model predictions\n        tr_rate = evaluate_generation(model, train_list, base_code)\n        vl_rate = evaluate_generation(model, val_list, base_code)\n        epoch_train_rates.append(tr_rate)\n        epoch_val_rates.append(vl_rate)\n        # Predictions & GT for storage\n        preds, gts = [], []\n        for sid in val_list:\n            # use model to predict\n            with torch.no_grad():\n                inp = torch.tensor([sid], device=device)\n                pred = model(inp).argmax(dim=1).item()\n            expr_p = base_code[pred]\n            expr_gt = base_code[sid]\n            pl = f\"return {expr_p} if '/' in '{expr_p}' and b == 0 else {expr_p}\"\n            preds.append(f\"def f(a, b):\\n    {pl}\")\n            gts.append(f\"def f(a, b):\\n    return {expr_gt}\")\n        all_preds.append(preds)\n        all_gts.append(gts)\n        print(\n            f\"Dataset={ds} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, train_rate={tr_rate:.4f}, val_rate={vl_rate:.4f}\"\n        )\n    # Store\n    entry = experiment_data[\"multi_domain_synthetic_specification\"][ds]\n    entry[\"losses\"][\"train\"] = epoch_train_losses\n    entry[\"losses\"][\"val\"] = epoch_val_losses\n    entry[\"metrics\"][\"train\"] = epoch_train_rates\n    entry[\"metrics\"][\"val\"] = epoch_val_rates\n    entry[\"predictions\"] = all_preds\n    entry[\"ground_truth\"] = all_gts\n\n# Save\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nbase_code = {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"}\n\n# Generate train/val splits (with replacement as before)\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        # x is token ids\n        return self.fc(self.emb(x))\n\n\n# Test pairs to check correctness\ntest_pairs = [(i, (i % 3) - 1) for i in range(6)]\n\n\ndef evaluate_generation(model, id_list):\n    model.eval()\n    pass_count = 0\n    with torch.no_grad():\n        for sid in id_list:\n            # predict op\n            x = torch.tensor([sid], dtype=torch.long).to(device)\n            logits = model(x)\n            pred_id = int(logits.argmax(dim=-1).cpu().item())\n            expr = base_code[pred_id]\n            # static analysis: guard division by zero\n            if \"/\" in expr:\n                code = (\n                    \"def f(a,b):\\n\"\n                    \"    if b == 0:\\n\"\n                    \"        return 0\\n\"\n                    f\"    return {expr}\\n\"\n                )\n            else:\n                code = f\"def f(a,b):\\n    return {expr}\\n\"\n            # compile and test\n            ns = {}\n            try:\n                exec(code, ns)\n                f = ns[\"f\"]\n            except Exception:\n                continue\n            ok = True\n            for a, b in test_pairs:\n                try:\n                    out = f(a, b)\n                except:\n                    ok = False\n                    break\n                ref = (\n                    (a / b if b != 0 else 0)\n                    if \"/\" in expr\n                    else eval(expr.replace(\"a\", str(a)).replace(\"b\", str(b)))\n                )\n                if abs(out - ref) > 1e-6:\n                    ok = False\n                    break\n            if ok:\n                pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Hyperparameters\nbase_lr = 0.01\nnum_epochs = 5\nbatch_size = 32\n\noptimizers = [\n    (\"Adam\", lambda params: optim.Adam(params, lr=base_lr)),\n    (\"SGD\", lambda params: optim.SGD(params, lr=base_lr, momentum=0.9)),\n    (\"RMSprop\", lambda params: optim.RMSprop(params, lr=base_lr)),\n    (\"Adagrad\", lambda params: optim.Adagrad(params, lr=base_lr)),\n]\n\n# Prepare experiment data container\nexperiment_data = {\n    \"optimizer\": {\n        \"synthetic\": {\n            \"optim_names\": [name for name, _ in optimizers],\n            \"metrics\": {\n                \"train_AICR\": [],\n                \"val_AICR\": [],\n                \"train_loss\": [],\n                \"val_loss\": [],\n                \"mean_iters_to_convergence_train\": [],\n                \"mean_iters_to_convergence_val\": [],\n            },\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor name, make_opt in optimizers:\n    print(f\"\\n=== Optimizer: {name} ===\")\n    # DataLoaders\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n\n    model = Classifier(len(specs)).to(device)\n    optimizer = make_opt(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    conv_train, conv_val = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        total_vloss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                total_vloss += criterion(model(x), y).item() * x.size(0)\n        val_loss = total_vloss / len(val_ids)\n        val_losses.append(val_loss)\n\n        # Generation metrics\n        tr_rate = evaluate_generation(model, train_ids)\n        vr_rate = evaluate_generation(model, val_ids)\n        train_rates.append(tr_rate)\n        val_rates.append(vr_rate)\n\n        # Toy convergence metric (1 loop per problem in this setup)\n        conv_train.append(1.0)\n        conv_val.append(1.0)\n\n        # Record code predictions / ground truth for val set\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for sid in val_ids:\n                x = torch.tensor([sid], dtype=torch.long).to(device)\n                pred_id = int(model(x).argmax(dim=-1).cpu().item())\n                expr_pred = base_code[pred_id]\n                if \"/\" in expr_pred:\n                    pred_code = (\n                        \"def f(a,b):\\n\"\n                        \"    if b == 0:\\n\"\n                        \"        return 0\\n\"\n                        f\"    return {expr_pred}\\n\"\n                    )\n                else:\n                    pred_code = f\"def f(a,b):\\n    return {expr_pred}\\n\"\n                gt_code = f\"def f(a,b):\\n    return {base_code[sid]}\\n\"\n                epoch_preds.append(pred_code)\n                epoch_gts.append(gt_code)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"{name} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_AICR={tr_rate:.4f}, val_AICR={vr_rate:.4f}, \"\n            f\"mean_iters_conv_train={conv_train[-1]:.1f}, mean_iters_conv_val={conv_val[-1]:.1f}\"\n        )\n\n    # Save results\n    data = experiment_data[\"optimizer\"][\"synthetic\"]\n    data[\"metrics\"][\"train_loss\"].append(train_losses)\n    data[\"metrics\"][\"val_loss\"].append(val_losses)\n    data[\"metrics\"][\"train_AICR\"].append(train_rates)\n    data[\"metrics\"][\"val_AICR\"].append(val_rates)\n    data[\"metrics\"][\"mean_iters_to_convergence_train\"].append(conv_train)\n    data[\"metrics\"][\"mean_iters_to_convergence_val\"].append(conv_val)\n    data[\"predictions\"].append(all_preds)\n    data[\"ground_truth\"].append(all_gts)\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(f\"\\nSaved experiment_data.npy in {working_dir}\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nbase_code = {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generator evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[int(sid)]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Hyperparameters for ablation\nsmoothing_factors = [0.0, 0.1, 0.2]\nlearning_rate = 0.01\nnum_epochs = 5\nbatch_size = 32\n\n# Initialize experiment_data\nexperiment_data = {\n    \"label_smoothing\": {\n        \"synthetic\": {\n            \"params\": smoothing_factors,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n\n# Ablation over smoothing factors\nfor smooth in smoothing_factors:\n    print(f\"\\n=== Label smoothing = {smooth} ===\")\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss(label_smoothing=smooth)\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate generation pass rates\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Collect predicted vs. ground-truth code strings\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            expr = base_code[int(sid)]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            epoch_preds.append(f\"def f(a, b):\\n    {line}\")\n            epoch_gts.append(f\"def f(a, b):\\n    return {expr}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"smooth={smooth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate(AICR)={train_rate:.4f}, val_rate(AICR)={val_rate:.4f}\"\n        )\n\n    # Append results\n    d = experiment_data[\"label_smoothing\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nbase_code = {0: \"a+b\", 1: \"a-b\", 2: \"a*b\", 3: \"a/b\"}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generator evaluator now uses the model's predictions\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(model, id_list):\n    model.eval()\n    pass_count = 0\n    iter_counts = []\n    with torch.no_grad():\n        for sid in id_list:\n            x = torch.tensor([sid], dtype=torch.long).to(device)\n            logits = model(x)\n            pred = logits.argmax(dim=-1).item()\n            expr = base_code[pred]\n            if \"/\" in expr:\n                code_line = f\"return {expr} if b != 0 else 0\"\n            else:\n                code_line = f\"return {expr}\"\n            code_str = f\"def f(a, b):\\n    {code_line}\"\n            ns = {}\n            try:\n                exec(code_str, ns)\n                func = ns[\"f\"]\n            except Exception:\n                iter_counts.append(1)\n                continue\n            ok = True\n            for a, b in test_pairs:\n                try:\n                    out = func(a, b)\n                except Exception:\n                    ok = False\n                    break\n                ref = (\n                    a / b\n                    if \"/\" in expr and b != 0\n                    else (0 if \"/\" in expr else eval(expr))\n                )\n                if abs(out - ref) > 1e-6:\n                    ok = False\n                    break\n            if ok:\n                pass_count += 1\n            iter_counts.append(1)\n    pass_rate = pass_count / len(id_list)\n    mean_iters = float(np.mean(iter_counts)) if iter_counts else 0.0\n    return pass_rate, mean_iters\n\n\n# Hyperparameters for ablation\nsmoothing_factors = [0.0, 0.1, 0.2]\nlearning_rate = 0.01\nnum_epochs = 5\nbatch_size = 32\n\n# Initialize experiment_data\nexperiment_data = {\n    \"label_smoothing\": {\n        \"synthetic\": {\n            \"params\": smoothing_factors,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"mean_iterations\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n\n# Ablation over smoothing factors\nfor smooth in smoothing_factors:\n    print(f\"\\n=== Label smoothing = {smooth} ===\")\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss(label_smoothing=smooth)\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    epoch_train_iters, epoch_val_iters = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validate loss\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n        # Evaluate generation pass rates and mean iters\n        train_rate, train_mean_iters = evaluate_generation(model, train_ids)\n        val_rate, val_mean_iters = evaluate_generation(model, val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n        epoch_train_iters.append(train_mean_iters)\n        epoch_val_iters.append(val_mean_iters)\n\n        # Collect predicted vs. ground-truth code strings\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for sid in val_ids:\n                x = torch.tensor([sid], dtype=torch.long).to(device)\n                logits = model(x)\n                pred = logits.argmax(dim=-1).item()\n                expr_pred = base_code[pred]\n                if \"/\" in expr_pred:\n                    line_p = f\"return {expr_pred} if b != 0 else 0\"\n                else:\n                    line_p = f\"return {expr_pred}\"\n                epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n                expr_true = base_code[int(sid)]\n                epoch_gts.append(f\"def f(a, b):\\n    return {expr_true}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"smooth={smooth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate(AICR)={train_rate:.4f}, val_rate(AICR)={val_rate:.4f}, \"\n            f\"mean_iters_train={train_mean_iters:.2f}, mean_iters_val={val_mean_iters:.2f}\"\n        )\n\n    # Append results\n    d = experiment_data[\"label_smoothing\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"mean_iterations\"][\"train\"].append(epoch_train_iters)\n    d[\"mean_iterations\"][\"val\"].append(epoch_val_iters)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device and seeds\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Full list of 16 synthetic ops\nfull_ops = [\n    (\"add\", \"a+b\"),\n    (\"sub\", \"a-b\"),\n    (\"mul\", \"a*b\"),\n    (\"div\", \"a/b\"),\n    (\"mod\", \"a%b\"),\n    (\"pow\", \"a**b\"),\n    (\"bit_and\", \"a&b\"),\n    (\"bit_or\", \"a|b\"),\n    (\"bit_xor\", \"a^b\"),\n    (\"lshift\", \"a<<b\"),\n    (\"rshift\", \"a>>b\"),\n    (\"min\", \"a if a<b else b\"),\n    (\"max\", \"a if a>b else b\"),\n    (\"eq\", \"1 if a==b else 0\"),\n    (\"neq\", \"1 if a!=b else 0\"),\n    (\"gt\", \"1 if a>b else 0\"),\n]\n\n\n# Dataset class\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generation evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list, code_map):\n    pass_count = 0\n    for sid in id_list:\n        expr = code_map[sid]\n        if \"/\" in expr:\n            line = f\"return {expr} if b != 0 else 0\"\n        else:\n            line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation sizes\nablation_sizes = [4, 8, 16]\nnum_train, num_val = 800, 200\nnum_epochs = 5\nlearning_rate = 0.01\nbatch_size = 32\n\n# Main experiment data\nexperiment_data = {\"output_vocab_scaling\": {}}\n\nfor n_ops in ablation_sizes:\n    print(f\"\\n=== Ablation: vocab size = {n_ops} ===\")\n    # Build specs and code_map\n    ops_subset = full_ops[:n_ops]\n    code_map = {i: expr for i, (_, expr) in enumerate(ops_subset)}\n    specs = [name for name, _ in ops_subset]\n    # Create splits\n    train_ids = np.random.choice(n_ops, size=num_train)\n    val_ids = np.random.choice(n_ops, size=num_val)\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    # Model and optimizer\n    model = Classifier(n_ops).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    # Storage per ablation\n    losses_train, losses_val = [], []\n    rates_train, rates_val = [], []\n    all_preds, all_gts = [], []\n    # Training loop\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        tot_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * x.size(0)\n        train_loss = tot_loss / num_train\n        losses_train.append(train_loss)\n        # Validate\n        model.eval()\n        tot_val = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                tot_val += criterion(logits, y).item() * x.size(0)\n        val_loss = tot_val / num_val\n        losses_val.append(val_loss)\n        # Generation metrics\n        tr_rate = evaluate_generation(train_ids.tolist(), code_map)\n        va_rate = evaluate_generation(val_ids.tolist(), code_map)\n        rates_train.append(tr_rate)\n        rates_val.append(va_rate)\n        # Dummy preds & gts\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            expr = code_map[int(sid)]\n            if \"/\" in expr:\n                line = f\"return {expr} if b != 0 else 0\"\n            else:\n                line = f\"return {expr}\"\n            pred = f\"def f(a, b):\\n    {line}\"\n            gt = f\"def f(a, b):\\n    return {expr}\"\n            epoch_preds.append(pred)\n            epoch_gts.append(gt)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n        print(\n            f\"V={n_ops} E={epoch} tr_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n            f\"tr_AICR={tr_rate:.4f} val_AICR={va_rate:.4f}\"\n        )\n    # Record results\n    experiment_data[\"output_vocab_scaling\"][f\"ops_{n_ops}\"] = {\n        \"losses\": {\"train\": losses_train, \"val\": losses_val},\n        \"metrics\": {\"train\": rates_train, \"val\": rates_val},\n        \"predictions\": all_preds,\n        \"ground_truth\": all_gts,\n    }\n\n# Save data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nbase_code = {i: code for i, code in enumerate([\"a+b\", \"a-b\", \"a*b\", \"a/b\"])}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train).tolist()\nval_ids = np.random.choice(len(specs), num_val).tolist()\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    test_pairs = [(i, (i % 3) - 1) for i in range(6)]\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                if b != 0:\n                    ref = a / b\n                else:\n                    ref = 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\nclass FixedEmbeddingClassifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.emb.weight.requires_grad = False\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\ndef get_predictions(model, ids):\n    model.eval()\n    with torch.no_grad():\n        x = torch.tensor(ids, dtype=torch.long).to(device)\n        logits = model(x)\n        return logits.argmax(dim=1).cpu().tolist()\n\n\n# Hyperparameters\nlearning_rates = [0.001, 0.005, 0.01, 0.02]\nnum_epochs = 5\n\n# Experiment data container\nexperiment_data = {\n    \"fixed_random_embedding\": {\n        \"synthetic\": {\n            \"params\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# Ablation run\nfor lr in learning_rates:\n    train_loader = DataLoader(SpecDataset(train_ids), batch_size=32, shuffle=True)\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=32)\n    model = FixedEmbeddingClassifier(len(specs)).to(device)\n    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n\n        # Validation loss\n        model.eval()\n        total_val = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                total_val += criterion(logits, y).item() * x.size(0)\n        val_loss = total_val / len(val_ids)\n        epoch_val_losses.append(val_loss)\n\n        # Evaluate code generation success\n        train_preds = get_predictions(model, train_ids)\n        val_preds = get_predictions(model, val_ids)\n        train_rate = evaluate_generation(train_preds)\n        val_rate = evaluate_generation(val_preds)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n\n        # Record predictions & ground truth on validation set\n        epoch_preds, epoch_gts = [], []\n        for p, t in zip(val_preds, val_ids):\n            expr_p = base_code[p]\n            line_p = (\n                f\"return {expr_p} if b != 0 else 0\"\n                if \"/\" in expr_p\n                else f\"return {expr_p}\"\n            )\n            epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n            epoch_gts.append(f\"def f(a, b):\\n    return {base_code[t]}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"LR={lr} Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    d = experiment_data[\"fixed_random_embedding\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnp.random.seed(0)\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier with optional weight tying\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, tie_weights=False):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.tie = tie_weights\n        if not tie_weights:\n            self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        e = self.emb(x)  # (batch, emb_dim)\n        if self.tie:\n            # logits via tied weights, no bias\n            return e @ self.emb.weight.t()\n        else:\n            return self.fc(e)\n\n\n# Generation evaluator (AICR)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        sid = int(sid)\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Hyperparameters\nlearning_rate = 0.01\nnum_epochs = 5\nbatch_size = 32\n\n# Prepare storage for ablation: untied vs tied\nexperiment_data = {\n    \"weight_tying\": {\n        \"synthetic\": {\n            \"conditions\": [\"untied\", \"tied\"],\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# Run experiments for both settings\nfor tie_flag in [False, True]:\n    setting = \"tied\" if tie_flag else \"untied\"\n    print(f\"\\n=== Running weight\u2010tying = {setting} ===\")\n    # DataLoaders\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    # Model, optimizer, loss\n    model = Classifier(len(specs), emb_dim=16, tie_weights=tie_flag).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    # Epoch records\n    epoch_train_losses, epoch_val_losses = [], []\n    epoch_train_rates, epoch_val_rates = [], []\n    all_preds, all_gts = [], []\n    # Training loop\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        epoch_train_losses.append(train_loss)\n        # Validation loss\n        model.eval()\n        total_val_loss = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                total_val_loss += loss.item() * x.size(0)\n        val_loss = total_val_loss / len(val_ids)\n        epoch_val_losses.append(val_loss)\n        # AICR rates\n        train_rate = evaluate_generation(train_ids)\n        val_rate = evaluate_generation(val_ids)\n        epoch_train_rates.append(train_rate)\n        epoch_val_rates.append(val_rate)\n        # Predictions & ground truth strings for val set\n        epoch_preds, epoch_gts = [], []\n        for sid in val_ids:\n            sid = int(sid)\n            expr = base_code[sid]\n            if \"/\" in expr:\n                line_pred = f\"return {expr} if b != 0 else 0\"\n            else:\n                line_pred = f\"return {expr}\"\n            pred_str = f\"def f(a, b):\\n    {line_pred}\"\n            gt_str = f\"def f(a, b):\\n    return {expr}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n        print(\n            f\"{setting.upper()} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n    # Store results\n    d = experiment_data[\"weight_tying\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(epoch_train_losses)\n    d[\"losses\"][\"val\"].append(epoch_val_losses)\n    d[\"metrics\"][\"train\"].append(epoch_train_rates)\n    d[\"metrics\"][\"val\"].append(epoch_val_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device and seeds\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Full list of synthetic ops\nfull_ops = [\n    (\"add\", \"a+b\"),\n    (\"sub\", \"a-b\"),\n    (\"mul\", \"a*b\"),\n    (\"div\", \"a/b\"),\n    (\"mod\", \"a%b\"),\n    (\"pow\", \"a**b\"),\n    (\"bit_and\", \"a&b\"),\n    (\"bit_or\", \"a|b\"),\n    (\"bit_xor\", \"a^b\"),\n    (\"lshift\", \"a<<b\"),\n    (\"rshift\", \"a>>b\"),\n    (\"min\", \"a if a<b else b\"),\n    (\"max\", \"a if a>b else b\"),\n    (\"eq\", \"1 if a==b else 0\"),\n    (\"neq\", \"1 if a!=b else 0\"),\n    (\"gt\", \"1 if a>b else 0\"),\n]\n\n\n# Dataset class\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Evaluation routine using model predictions\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(model, id_list, code_map):\n    model.eval()\n    with torch.no_grad():\n        ids = torch.tensor(id_list, dtype=torch.long).to(device)\n        logits = model(ids)\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n    pass_count = 0\n    for true_id, pred_id in zip(id_list, preds):\n        expr = code_map[int(pred_id)]\n        # guard division by zero\n        if \"/\" in expr:\n            line = f\"return {expr} if b != 0 else 0\"\n        else:\n            line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation sizes\nablation_sizes = [4, 8, 16]\nnum_train, num_val = 800, 200\nnum_epochs = 5\nlearning_rate = 0.01\nbatch_size = 32\n\n# Main experiment data\nexperiment_data = {\"output_vocab_scaling\": {}}\n\nfor n_ops in ablation_sizes:\n    print(f\"\\n=== Ablation: vocab size = {n_ops} ===\")\n    ops_subset = full_ops[:n_ops]\n    code_map = {i: expr for i, (_, expr) in enumerate(ops_subset)}\n    train_ids = np.random.choice(n_ops, size=num_train)\n    val_ids = np.random.choice(n_ops, size=num_val)\n    train_loader = DataLoader(\n        SpecDataset(train_ids), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    model = Classifier(n_ops).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    losses_train, losses_val = [], []\n    rates_train, rates_val = [], []\n    mitc_train, mitc_val = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        tot_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            tot_loss += loss.item() * x.size(0)\n        train_loss = tot_loss / num_train\n        losses_train.append(train_loss)\n\n        # Validate loss\n        model.eval()\n        tot_val = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                tot_val += criterion(model(x), y).item() * x.size(0)\n        val_loss = tot_val / num_val\n        losses_val.append(val_loss)\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n\n        # Generation metrics and dummy MItC\n        tr_rate = evaluate_generation(model, train_ids.tolist(), code_map)\n        va_rate = evaluate_generation(model, val_ids.tolist(), code_map)\n        rates_train.append(tr_rate)\n        rates_val.append(va_rate)\n        mitc_train.append(1.0)\n        mitc_val.append(1.0)\n        print(\n            f\"V={n_ops} E={epoch} tr_AICR={tr_rate:.4f} val_AICR={va_rate:.4f} tr_MItC={1.0:.2f} val_MItC={1.0:.2f}\"\n        )\n\n        # Record predictions and ground truth on validation for analysis\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            ids = torch.tensor(val_ids, dtype=torch.long).to(device)\n            logits = model(ids)\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n        for true_id, pred_id in zip(val_ids, preds):\n            pred_expr = code_map[int(pred_id)]\n            true_expr = code_map[int(true_id)]\n            if \"/\" in pred_expr:\n                line_pred = f\"return {pred_expr} if b != 0 else 0\"\n            else:\n                line_pred = f\"return {pred_expr}\"\n            epoch_preds.append(f\"def f(a, b):\\n    {line_pred}\")\n            epoch_gts.append(f\"def f(a, b):\\n    return {true_expr}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n    experiment_data[\"output_vocab_scaling\"][f\"ops_{n_ops}\"] = {\n        \"losses\": {\"train\": losses_train, \"val\": losses_val},\n        \"metrics\": {\n            \"AICR\": {\"train\": rates_train, \"val\": rates_val},\n            \"MeanIters\": {\"train\": mitc_train, \"val\": mitc_val},\n        },\n        \"predictions\": all_preds,\n        \"ground_truth\": all_gts,\n    }\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Seed for reproducibility\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\n# Dataset supports separate labels\nclass SpecDataset(Dataset):\n    def __init__(self, ids, labels=None):\n        self.x = torch.tensor(ids, dtype=torch.long)\n        if labels is None:\n            self.y = self.x.clone()\n        else:\n            self.y = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n\n# Simple classifier model\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.fc = nn.Linear(emb_dim, n_ops)\n\n    def forward(self, x):\n        return self.fc(self.emb(x))\n\n\n# Generator evaluator\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation: label noise levels\nnoise_levels = [0.1, 0.2, 0.3]\nlearning_rate = 0.01\nnum_epochs = 5\nbatch_size = 32\n\n# Prepare experiment data structure\nexperiment_data = {\n    \"label_noise\": {\n        \"synthetic\": {\n            \"noise_levels\": [],\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nfor noise in noise_levels:\n    print(f\"\\n=== Noise level = {int(noise*100)}% ===\")\n    experiment_data[\"label_noise\"][\"synthetic\"][\"noise_levels\"].append(noise)\n    # Create noisy labels for training\n    train_labels = train_ids.copy()\n    n_flip = int(noise * len(train_labels))\n    flip_idx = np.random.choice(len(train_labels), n_flip, replace=False)\n    for idx in flip_idx:\n        orig = train_labels[idx]\n        choices = [i for i in range(len(specs)) if i != orig]\n        train_labels[idx] = np.random.choice(choices)\n    # DataLoaders\n    train_loader = DataLoader(\n        SpecDataset(train_ids, train_labels), batch_size=batch_size, shuffle=True\n    )\n    val_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size)\n    # Model, optimizer, criterion\n    model = Classifier(len(specs)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    # Trackers\n    t_losses, v_losses = [], []\n    t_rates, v_rates = [], []\n    all_preds, all_gts = [], []\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        total_loss = 0.0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n        train_loss = total_loss / len(train_ids)\n        t_losses.append(train_loss)\n        # Validate CE loss\n        model.eval()\n        total_vl = 0.0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                total_vl += criterion(logits, y).item() * x.size(0)\n        val_loss = total_vl / len(val_ids)\n        v_losses.append(val_loss)\n        # Predict on train & val for AICR\n        model.eval()\n        train_preds = []\n        with torch.no_grad():\n            for x, _ in train_loader:\n                x = x.to(device)\n                preds = model(x).argmax(dim=1).cpu().tolist()\n                train_preds.extend(preds)\n        val_preds = []\n        with torch.no_grad():\n            for x, _ in val_loader:\n                x = x.to(device)\n                preds = model(x).argmax(dim=1).cpu().tolist()\n                val_preds.extend(preds)\n        train_rate = evaluate_generation(train_preds)\n        val_rate = evaluate_generation(val_preds)\n        t_rates.append(train_rate)\n        v_rates.append(val_rate)\n        # Record predictions & ground truth on validation set\n        epoch_preds, epoch_gts = [], []\n        for pred_id, true_id in zip(val_preds, val_ids):\n            expr_p = base_code[pred_id]\n            line_p = (\n                f\"return {expr_p} if b != 0 else 0\"\n                if \"/\" in expr_p\n                else f\"return {expr_p}\"\n            )\n            pred_str = f\"def f(a, b):\\n    {line_p}\"\n            expr_t = base_code[true_id]\n            gt_str = f\"def f(a, b):\\n    return {expr_t}\"\n            epoch_preds.append(pred_str)\n            epoch_gts.append(gt_str)\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n        print(\n            f\"Noise={int(noise*100)}% Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_AICR={train_rate:.4f}, val_AICR={val_rate:.4f}\"\n        )\n    # Append to experiment_data\n    d = experiment_data[\"label_noise\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(t_losses)\n    d[\"losses\"][\"val\"].append(v_losses)\n    d[\"metrics\"][\"train\"].append(t_rates)\n    d[\"metrics\"][\"val\"].append(v_rates)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier with variable head depth\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, head_depth=1):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.head_depth = head_depth\n        if head_depth == 1:\n            self.fc = nn.Linear(emb_dim, n_ops)\n        elif head_depth == 2:\n            # two-layer MLP head\n            self.fc1 = nn.Linear(emb_dim, emb_dim)\n            self.act = nn.ReLU()\n            self.fc2 = nn.Linear(emb_dim, n_ops)\n        else:\n            raise ValueError(\"Unsupported head depth\")\n\n    def forward(self, x):\n        e = self.emb(x)\n        if self.head_depth == 1:\n            return self.fc(e)\n        else:\n            return self.fc2(self.act(self.fc1(e)))\n\n\n# Generator evaluator (unchanged)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study data container\nexperiment_data = {\n    \"classification_head_depth\": {\n        \"synthetic\": {\n            \"head_depths\": [1, 2],\n            \"losses\": {\"train\": [], \"val\": []},\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"classification_accuracy\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size, shuffle=False)\n\n# Fixed hyperparameters\nlearning_rate = 0.01\nnum_epochs = 5\n\n# Run ablation over head depths\nfor head_depth in [1, 2]:\n    model = Classifier(len(specs), emb_dim=16, head_depth=head_depth).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    train_accs, val_accs = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss, correct, total = 0.0, 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += x.size(0)\n        train_loss = total_loss / len(train_ids)\n        train_acc = correct / total\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n\n        # Validation\n        model.eval()\n        v_loss, v_correct, v_total = 0.0, 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                v_loss += loss.item() * x.size(0)\n                preds = logits.argmax(dim=1)\n                v_correct += (preds == y).sum().item()\n                v_total += x.size(0)\n        val_loss = v_loss / len(val_ids)\n        val_acc = v_correct / v_total\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        # AICR metrics on model's own predictions\n        model.eval()\n        # Train set AICR\n        train_pred_ids = []\n        with torch.no_grad():\n            for x, y in train_loader:\n                x = x.to(device)\n                logits = model(x)\n                train_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        train_rate = evaluate_generation(train_pred_ids)\n        # Val set AICR\n        val_pred_ids = []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x = x.to(device)\n                logits = model(x)\n                val_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        val_rate = evaluate_generation(val_pred_ids)\n        train_rates.append(train_rate)\n        val_rates.append(val_rate)\n\n        # Record predictions & ground truth code strings on validation set\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                pred_ids = logits.argmax(dim=1).cpu().tolist()\n                true_ids = y.cpu().tolist()\n                for sid_p, sid_t in zip(pred_ids, true_ids):\n                    expr_p = base_code[sid_p]\n                    if \"/\" in expr_p:\n                        line_p = f\"return {expr_p} if b != 0 else 0\"\n                    else:\n                        line_p = f\"return {expr_p}\"\n                    epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n                    expr_t = base_code[sid_t]\n                    epoch_gts.append(f\"def f(a, b):\\n    return {expr_t}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"Depth={head_depth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    # Append results for this head depth\n    d = experiment_data[\"classification_head_depth\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(train_losses)\n    d[\"losses\"][\"val\"].append(val_losses)\n    d[\"metrics\"][\"train\"].append(train_rates)\n    d[\"metrics\"][\"val\"].append(val_rates)\n    d[\"classification_accuracy\"][\"train\"].append(train_accs)\n    d[\"classification_accuracy\"][\"val\"].append(val_accs)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier with variable head depth\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, head_depth=1):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.head_depth = head_depth\n        if head_depth == 1:\n            self.fc = nn.Linear(emb_dim, n_ops)\n        elif head_depth == 2:\n            # two-layer MLP head\n            self.fc1 = nn.Linear(emb_dim, emb_dim)\n            self.act = nn.ReLU()\n            self.fc2 = nn.Linear(emb_dim, n_ops)\n        else:\n            raise ValueError(\"Unsupported head depth\")\n\n    def forward(self, x):\n        e = self.emb(x)\n        if self.head_depth == 1:\n            return self.fc(e)\n        else:\n            return self.fc2(self.act(self.fc1(e)))\n\n\n# Generator evaluator (unchanged)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study data container\nexperiment_data = {\n    \"classification_head_depth\": {\n        \"synthetic\": {\n            \"head_depths\": [1, 2],\n            \"losses\": {\"train\": [], \"val\": []},\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"classification_accuracy\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size, shuffle=False)\n\n# Fixed hyperparameters\nlearning_rate = 0.01\nnum_epochs = 5\n\n# Run ablation over head depths\nfor head_depth in [1, 2]:\n    model = Classifier(len(specs), emb_dim=16, head_depth=head_depth).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    train_accs, val_accs = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss, correct, total = 0.0, 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += x.size(0)\n        train_loss = total_loss / len(train_ids)\n        train_acc = correct / total\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n\n        # Validation\n        model.eval()\n        v_loss, v_correct, v_total = 0.0, 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                v_loss += loss.item() * x.size(0)\n                preds = logits.argmax(dim=1)\n                v_correct += (preds == y).sum().item()\n                v_total += x.size(0)\n        val_loss = v_loss / len(val_ids)\n        val_acc = v_correct / v_total\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        # AICR metrics on model's own predictions\n        model.eval()\n        # Train set AICR\n        train_pred_ids = []\n        with torch.no_grad():\n            for x, y in train_loader:\n                x = x.to(device)\n                logits = model(x)\n                train_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        train_rate = evaluate_generation(train_pred_ids)\n        # Val set AICR\n        val_pred_ids = []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x = x.to(device)\n                logits = model(x)\n                val_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        val_rate = evaluate_generation(val_pred_ids)\n        train_rates.append(train_rate)\n        val_rates.append(val_rate)\n\n        # Record predictions & ground truth code strings on validation set\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                pred_ids = logits.argmax(dim=1).cpu().tolist()\n                true_ids = y.cpu().tolist()\n                for sid_p, sid_t in zip(pred_ids, true_ids):\n                    expr_p = base_code[sid_p]\n                    if \"/\" in expr_p:\n                        line_p = f\"return {expr_p} if b != 0 else 0\"\n                    else:\n                        line_p = f\"return {expr_p}\"\n                    epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n                    expr_t = base_code[sid_t]\n                    epoch_gts.append(f\"def f(a, b):\\n    return {expr_t}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"Depth={head_depth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    # Append results for this head depth\n    d = experiment_data[\"classification_head_depth\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(train_losses)\n    d[\"losses\"][\"val\"].append(val_losses)\n    d[\"metrics\"][\"train\"].append(train_rates)\n    d[\"metrics\"][\"val\"].append(val_rates)\n    d[\"classification_accuracy\"][\"train\"].append(train_accs)\n    d[\"classification_accuracy\"][\"val\"].append(val_accs)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n# Synthetic specification dataset\nspecs = [\"add\", \"sub\", \"mul\", \"div\"]\nspec2id = {s: i for i, s in enumerate(specs)}\nbase_code = {\n    0: \"a+b\",\n    1: \"a-b\",\n    2: \"a*b\",\n    3: \"a/b\",\n}\n\n# Generate train/val splits\nnum_train, num_val = 800, 200\ntrain_ids = np.random.choice(len(specs), num_train)\nval_ids = np.random.choice(len(specs), num_val)\n\n\nclass SpecDataset(Dataset):\n    def __init__(self, ids):\n        self.ids = torch.tensor(ids, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        x = self.ids[idx]\n        return x, x\n\n\n# Classifier with variable head depth\nclass Classifier(nn.Module):\n    def __init__(self, n_ops, emb_dim=16, head_depth=1):\n        super().__init__()\n        self.emb = nn.Embedding(n_ops, emb_dim)\n        self.head_depth = head_depth\n        if head_depth == 1:\n            self.fc = nn.Linear(emb_dim, n_ops)\n        elif head_depth == 2:\n            # two-layer MLP head\n            self.fc1 = nn.Linear(emb_dim, emb_dim)\n            self.act = nn.ReLU()\n            self.fc2 = nn.Linear(emb_dim, n_ops)\n        else:\n            raise ValueError(\"Unsupported head depth\")\n\n    def forward(self, x):\n        e = self.emb(x)\n        if self.head_depth == 1:\n            return self.fc(e)\n        else:\n            return self.fc2(self.act(self.fc1(e)))\n\n\n# Generator evaluator (unchanged)\nK = 6\ntest_pairs = [(i, (i % 3) - 1) for i in range(K)]\n\n\ndef evaluate_generation(id_list):\n    pass_count = 0\n    for sid in id_list:\n        expr = base_code[sid]\n        if \"/\" in expr:\n            code_line = f\"return {expr} if b != 0 else 0\"\n        else:\n            code_line = f\"return {expr}\"\n        code_str = f\"def f(a, b):\\n    {code_line}\"\n        ns = {}\n        try:\n            exec(code_str, ns)\n            func = ns[\"f\"]\n        except Exception:\n            continue\n        ok = True\n        for a, b in test_pairs:\n            try:\n                out = func(a, b)\n            except Exception:\n                ok = False\n                break\n            if \"/\" in expr:\n                ref = a / b if b != 0 else 0\n            else:\n                ref = eval(expr)\n            if abs(out - ref) > 1e-6:\n                ok = False\n                break\n        if ok:\n            pass_count += 1\n    return pass_count / len(id_list)\n\n\n# Ablation study data container\nexperiment_data = {\n    \"classification_head_depth\": {\n        \"synthetic\": {\n            \"head_depths\": [1, 2],\n            \"losses\": {\"train\": [], \"val\": []},\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"classification_accuracy\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\n# DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(SpecDataset(train_ids), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(SpecDataset(val_ids), batch_size=batch_size, shuffle=False)\n\n# Fixed hyperparameters\nlearning_rate = 0.01\nnum_epochs = 5\n\n# Run ablation over head depths\nfor head_depth in [1, 2]:\n    model = Classifier(len(specs), emb_dim=16, head_depth=head_depth).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_rates, val_rates = [], []\n    train_accs, val_accs = [], []\n    all_preds, all_gts = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        model.train()\n        total_loss, correct, total = 0.0, 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = criterion(logits, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * x.size(0)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += x.size(0)\n        train_loss = total_loss / len(train_ids)\n        train_acc = correct / total\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n\n        # Validation\n        model.eval()\n        v_loss, v_correct, v_total = 0.0, 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                loss = criterion(logits, y)\n                v_loss += loss.item() * x.size(0)\n                preds = logits.argmax(dim=1)\n                v_correct += (preds == y).sum().item()\n                v_total += x.size(0)\n        val_loss = v_loss / len(val_ids)\n        val_acc = v_correct / v_total\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n\n        # AICR metrics on model's own predictions\n        model.eval()\n        # Train set AICR\n        train_pred_ids = []\n        with torch.no_grad():\n            for x, y in train_loader:\n                x = x.to(device)\n                logits = model(x)\n                train_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        train_rate = evaluate_generation(train_pred_ids)\n        # Val set AICR\n        val_pred_ids = []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x = x.to(device)\n                logits = model(x)\n                val_pred_ids.extend(logits.argmax(dim=1).cpu().tolist())\n        val_rate = evaluate_generation(val_pred_ids)\n        train_rates.append(train_rate)\n        val_rates.append(val_rate)\n\n        # Record predictions & ground truth code strings on validation set\n        epoch_preds, epoch_gts = [], []\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                pred_ids = logits.argmax(dim=1).cpu().tolist()\n                true_ids = y.cpu().tolist()\n                for sid_p, sid_t in zip(pred_ids, true_ids):\n                    expr_p = base_code[sid_p]\n                    if \"/\" in expr_p:\n                        line_p = f\"return {expr_p} if b != 0 else 0\"\n                    else:\n                        line_p = f\"return {expr_p}\"\n                    epoch_preds.append(f\"def f(a, b):\\n    {line_p}\")\n                    expr_t = base_code[sid_t]\n                    epoch_gts.append(f\"def f(a, b):\\n    return {expr_t}\")\n        all_preds.append(epoch_preds)\n        all_gts.append(epoch_gts)\n\n        print(\n            f\"Depth={head_depth} Epoch {epoch}: \"\n            f\"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n            f\"train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, \"\n            f\"train_rate={train_rate:.4f}, val_rate={val_rate:.4f}\"\n        )\n\n    # Append results for this head depth\n    d = experiment_data[\"classification_head_depth\"][\"synthetic\"]\n    d[\"losses\"][\"train\"].append(train_losses)\n    d[\"losses\"][\"val\"].append(val_losses)\n    d[\"metrics\"][\"train\"].append(train_rates)\n    d[\"metrics\"][\"val\"].append(val_rates)\n    d[\"classification_accuracy\"][\"train\"].append(train_accs)\n    d[\"classification_accuracy\"][\"val\"].append(val_accs)\n    d[\"predictions\"].append(all_preds)\n    d[\"ground_truth\"].append(all_gts)\n\n# Save all data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"Saved experiment_data.npy\")\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', '\\n=== Training with learning rate = 0.001 ===',\n'\\n', 'LR=0.001 Epoch 1: train_loss=1.7351, val_loss=1.5176,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'LR=0.001 Epoch 2:\ntrain_loss=1.4149, val_loss=1.2281, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.001 Epoch 3: train_loss=1.1405,\nval_loss=0.9842, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'LR=0.001 Epoch 4: train_loss=0.9105, val_loss=0.7826, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.001 Epoch 5: train_loss=0.7202,\nval_loss=0.6189, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', '\\n===\nTraining with learning rate = 0.005 ===', '\\n', 'LR=0.005 Epoch 1:\ntrain_loss=1.1385, val_loss=0.5728, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.005 Epoch 2: train_loss=0.3246,\nval_loss=0.1601, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'LR=0.005 Epoch 3: train_loss=0.1026, val_loss=0.0642, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.005 Epoch 4: train_loss=0.0479,\nval_loss=0.0357, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'LR=0.005 Epoch 5: train_loss=0.0289, val_loss=0.0233, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Training with learning rate = 0.01 ===',\n'\\n', 'LR=0.01 Epoch 1: train_loss=0.5022, val_loss=0.0736,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'LR=0.01 Epoch 2:\ntrain_loss=0.0330, val_loss=0.0153, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.01 Epoch 3: train_loss=0.0110,\nval_loss=0.0084, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'LR=0.01\nEpoch 4: train_loss=0.0069, val_loss=0.0058, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.01 Epoch 5: train_loss=0.0049,\nval_loss=0.0043, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', '\\n===\nTraining with learning rate = 0.02 ===', '\\n', 'LR=0.02 Epoch 1:\ntrain_loss=0.3286, val_loss=0.0094, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.02 Epoch 2: train_loss=0.0041,\nval_loss=0.0019, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'LR=0.02\nEpoch 3: train_loss=0.0015, val_loss=0.0013, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'LR=0.02 Epoch 4: train_loss=0.0011,\nval_loss=0.0010, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'LR=0.02\nEpoch 5: train_loss=0.0009, val_loss=0.0008, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution\ntime: 3 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Dataset: arithmetic ===', '\\n',\n'Dataset=arithmetic Epoch 1: train_loss=0.4099, val_loss=0.0751,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Dataset=arithmetic Epoch 2:\ntrain_loss=0.0318, val_loss=0.0151, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Dataset=arithmetic Epoch 3: train_loss=0.0103, val_loss=0.0078,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Dataset=arithmetic Epoch 4:\ntrain_loss=0.0062, val_loss=0.0053, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Dataset=arithmetic Epoch 5: train_loss=0.0043, val_loss=0.0039,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Dataset: polynomial ===',\n'\\n', 'Dataset=polynomial Epoch 1: train_loss=0.2943, val_loss=0.0508,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Dataset=polynomial Epoch 2:\ntrain_loss=0.0223, val_loss=0.0089, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Dataset=polynomial Epoch 3: train_loss=0.0061, val_loss=0.0043,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Dataset=polynomial Epoch 4:\ntrain_loss=0.0035, val_loss=0.0028, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Dataset=polynomial Epoch 5: train_loss=0.0023, val_loss=0.0020,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Dataset: bitwise ===', '\\n',\n'Dataset=bitwise Epoch 1: train_loss=0.5751, val_loss=0.1100, train_rate=0.5850,\nval_rate=0.5800', '\\n', 'Dataset=bitwise Epoch 2: train_loss=0.0495,\nval_loss=0.0216, train_rate=0.5850, val_rate=0.5800', '\\n', 'Dataset=bitwise\nEpoch 3: train_loss=0.0151, val_loss=0.0108, train_rate=0.5850,\nval_rate=0.5800', '\\n', 'Dataset=bitwise Epoch 4: train_loss=0.0088,\nval_loss=0.0072, train_rate=0.5850, val_rate=0.5800', '\\n', 'Dataset=bitwise\nEpoch 5: train_loss=0.0061, val_loss=0.0052, train_rate=0.5850,\nval_rate=0.5800', '\\n', '\\n=== Dataset: combined ===', '\\n', 'Dataset=combined\nEpoch 1: train_loss=1.3040, val_loss=0.4744, train_rate=0.8137,\nval_rate=0.8650', '\\n', 'Dataset=combined Epoch 2: train_loss=0.2240,\nval_loss=0.0837, train_rate=0.8137, val_rate=0.8650', '\\n', 'Dataset=combined\nEpoch 3: train_loss=0.0500, val_loss=0.0310, train_rate=0.8137,\nval_rate=0.8650', '\\n', 'Dataset=combined Epoch 4: train_loss=0.0234,\nval_loss=0.0181, train_rate=0.8137, val_rate=0.8650', '\\n', 'Dataset=combined\nEpoch 5: train_loss=0.0148, val_loss=0.0123, train_rate=0.8137,\nval_rate=0.8650', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution time: 3\nseconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with emb_dim = 2 ===', '\\n',\n'emb_dim=2 Epoch 1: train_loss=1.4870, val_loss=1.3275, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=2 Epoch 2: train_loss=1.1508, val_loss=1.0225,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=2 Epoch 3:\ntrain_loss=0.8933, val_loss=0.7726, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=2 Epoch 4: train_loss=0.6516, val_loss=0.5436, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=2 Epoch 5: train_loss=0.4350, val_loss=0.3581,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Training with emb_dim = 4\n===', '\\n', 'emb_dim=4 Epoch 1: train_loss=1.1788, val_loss=0.8601,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=4 Epoch 2:\ntrain_loss=0.6983, val_loss=0.5167, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=4 Epoch 3: train_loss=0.4162, val_loss=0.2856, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=4 Epoch 4: train_loss=0.2151, val_loss=0.1349,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=4 Epoch 5:\ntrain_loss=0.0976, val_loss=0.0645, train_rate=1.0000, val_rate=1.0000', '\\n',\n'\\n=== Training with emb_dim = 8 ===', '\\n', 'emb_dim=8 Epoch 1:\ntrain_loss=1.1909, val_loss=0.5709, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=8 Epoch 2: train_loss=0.3038, val_loss=0.1300, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=8 Epoch 3: train_loss=0.0730, val_loss=0.0414,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=8 Epoch 4:\ntrain_loss=0.0294, val_loss=0.0213, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=8 Epoch 5: train_loss=0.0170, val_loss=0.0136, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Training with emb_dim = 16 ===', '\\n',\n'emb_dim=16 Epoch 1: train_loss=0.4859, val_loss=0.0994, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=16 Epoch 2: train_loss=0.0432, val_loss=0.0189,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=16 Epoch 3:\ntrain_loss=0.0131, val_loss=0.0096, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=16 Epoch 4: train_loss=0.0077, val_loss=0.0064, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=16 Epoch 5: train_loss=0.0054, val_loss=0.0047,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Training with emb_dim = 32\n===', '\\n', 'emb_dim=32 Epoch 1: train_loss=0.2367, val_loss=0.0076,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=32 Epoch 2:\ntrain_loss=0.0038, val_loss=0.0024, train_rate=1.0000, val_rate=1.0000', '\\n',\n'emb_dim=32 Epoch 3: train_loss=0.0019, val_loss=0.0017, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'emb_dim=32 Epoch 4: train_loss=0.0015, val_loss=0.0014,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'emb_dim=32 Epoch 5:\ntrain_loss=0.0012, val_loss=0.0011, train_rate=1.0000, val_rate=1.0000', '\\n',\n'\\nSaved experiment_data.npy', '\\n', 'Execution time: 3 seconds seconds (time\nlimit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with batch size = 8 ===', '\\n',\n'BS=8 Epoch 1: train_loss=0.2311, val_loss=0.0090, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=8 Epoch 2: train_loss=0.0052, val_loss=0.0031,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=8 Epoch 3:\ntrain_loss=0.0022, val_loss=0.0016, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=8 Epoch 4: train_loss=0.0012, val_loss=0.0010,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=8 Epoch 5:\ntrain_loss=0.0008, val_loss=0.0007, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Training with batch size = 16 ===', '\\n',\n'BS=16 Epoch 1: train_loss=0.4219, val_loss=0.0274, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=16 Epoch 2: train_loss=0.0139,\nval_loss=0.0081, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=16\nEpoch 3: train_loss=0.0060, val_loss=0.0044, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=16 Epoch 4: train_loss=0.0035,\nval_loss=0.0028, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=16\nEpoch 5: train_loss=0.0024, val_loss=0.0020, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Training with batch size = 32 ===', '\\n',\n'BS=32 Epoch 1: train_loss=0.5022, val_loss=0.0736, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=32 Epoch 2: train_loss=0.0330,\nval_loss=0.0153, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=32\nEpoch 3: train_loss=0.0110, val_loss=0.0084, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=32 Epoch 4: train_loss=0.0069,\nval_loss=0.0058, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=32\nEpoch 5: train_loss=0.0049, val_loss=0.0043, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Training with batch size = 64 ===', '\\n',\n'BS=64 Epoch 1: train_loss=0.9319, val_loss=0.3959, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=64 Epoch 2: train_loss=0.2056,\nval_loss=0.0868, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=64\nEpoch 3: train_loss=0.0533, val_loss=0.0296, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=64 Epoch 4: train_loss=0.0220,\nval_loss=0.0159, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=64\nEpoch 5: train_loss=0.0131, val_loss=0.0108, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Training with batch size = 128 ===', '\\n',\n'BS=128 Epoch 1: train_loss=1.2194, val_loss=0.8239, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=128 Epoch 2: train_loss=0.5870,\nval_loss=0.3791, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=128\nEpoch 3: train_loss=0.2623, val_loss=0.1709, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'BS=128 Epoch 4: train_loss=0.1200,\nval_loss=0.0841, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'BS=128\nEpoch 5: train_loss=0.0616, val_loss=0.0475, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution\ntime: 3 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Optimizer: Adam ===', '\\n', 'Adam Epoch 1:\ntrain_loss=0.7699, val_loss=0.1406, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'Adam Epoch 2: train_loss=0.0574, val_loss=0.0220, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Adam Epoch 3: train_loss=0.0150, val_loss=0.0108,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'Adam Epoch 4: train_loss=0.0087,\nval_loss=0.0072, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'Adam Epoch 5:\ntrain_loss=0.0061, val_loss=0.0052, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'\\n=== Optimizer: SGD ===', '\\n', 'SGD Epoch 1: train_loss=0.7054,\nval_loss=0.0939, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'SGD Epoch 2:\ntrain_loss=0.0427, val_loss=0.0231, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'SGD Epoch 3: train_loss=0.0185, val_loss=0.0157, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'SGD Epoch 4: train_loss=0.0140, val_loss=0.0126,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'SGD Epoch 5: train_loss=0.0115,\nval_loss=0.0106, train_AICR=1.0000, val_AICR=1.0000', '\\n', '\\n=== Optimizer:\nRMSprop ===', '\\n', 'RMSprop Epoch 1: train_loss=0.1146, val_loss=0.0106,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'RMSprop Epoch 2: train_loss=0.0067,\nval_loss=0.0043, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'RMSprop Epoch 3:\ntrain_loss=0.0032, val_loss=0.0025, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'RMSprop Epoch 4: train_loss=0.0020, val_loss=0.0016, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'RMSprop Epoch 5: train_loss=0.0014, val_loss=0.0012,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\n=== Optimizer: Adagrad ===', '\\n',\n'Adagrad Epoch 1: train_loss=0.9986, val_loss=0.7364, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Adagrad Epoch 2: train_loss=0.5752, val_loss=0.4862,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'Adagrad Epoch 3: train_loss=0.3985,\nval_loss=0.3526, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'Adagrad Epoch 4:\ntrain_loss=0.2977, val_loss=0.2705, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'Adagrad Epoch 5: train_loss=0.2337, val_loss=0.2163, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', '\\nSaved experiment_data.npy in /data/chenhui/AI-Scienti\nst-v2/experiments/2025-06-07_15-26-\n52_abstract_interpretation_guided_generation_attempt_0/0-\nrun/process_ForkProcess-15/working', '\\n', 'Execution time: 3 seconds seconds\n(time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with dropout_rate = 0.0 ===', '\\n',\n'DR=0.0 Epoch 1: train_loss=1.1887, val_loss=0.5835, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.0 Epoch 2: train_loss=0.3398, val_loss=0.1643,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.0 Epoch 3: train_loss=0.1051,\nval_loss=0.0651, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.0 Epoch 4:\ntrain_loss=0.0485, val_loss=0.0360, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.0 Epoch 5: train_loss=0.0292, val_loss=0.0236, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Training with dropout_rate = 0.2 ===', '\\n',\n'DR=0.2 Epoch 1: train_loss=1.1769, val_loss=0.5880, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.2 Epoch 2: train_loss=0.3615, val_loss=0.1700,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.2 Epoch 3: train_loss=0.1399,\nval_loss=0.0661, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.2 Epoch 4:\ntrain_loss=0.0655, val_loss=0.0352, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.2 Epoch 5: train_loss=0.0432, val_loss=0.0218, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Training with dropout_rate = 0.5 ===', '\\n',\n'DR=0.5 Epoch 1: train_loss=0.9714, val_loss=0.3931, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.5 Epoch 2: train_loss=0.3361, val_loss=0.1176,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.5 Epoch 3: train_loss=0.1915,\nval_loss=0.0501, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.5 Epoch 4:\ntrain_loss=0.1287, val_loss=0.0258, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.5 Epoch 5: train_loss=0.0976, val_loss=0.0149, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution time: 2\nseconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with weight_decay = 0 ===', '\\n',\n'WD=0 Epoch 1: train_loss=0.4099, val_loss=0.0751, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'WD=0 Epoch 2: train_loss=0.0318, val_loss=0.0151,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=0 Epoch 3: train_loss=0.0103,\nval_loss=0.0078, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=0 Epoch 4:\ntrain_loss=0.0062, val_loss=0.0053, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'WD=0 Epoch 5: train_loss=0.0043, val_loss=0.0039, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', '\\n=== Training with weight_decay = 1e-05 ===', '\\n',\n'WD=1e-05 Epoch 1: train_loss=0.5883, val_loss=0.1189, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'WD=1e-05 Epoch 2: train_loss=0.0517, val_loss=0.0200,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=1e-05 Epoch 3: train_loss=0.0138,\nval_loss=0.0094, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=1e-05 Epoch 4:\ntrain_loss=0.0078, val_loss=0.0061, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'WD=1e-05 Epoch 5: train_loss=0.0053, val_loss=0.0044, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', '\\n=== Training with weight_decay = 0.0001 ===', '\\n',\n'WD=0.0001 Epoch 1: train_loss=0.5110, val_loss=0.0741, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'WD=0.0001 Epoch 2: train_loss=0.0332, val_loss=0.0150,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=0.0001 Epoch 3:\ntrain_loss=0.0110, val_loss=0.0083, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'WD=0.0001 Epoch 4: train_loss=0.0069, val_loss=0.0058, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'WD=0.0001 Epoch 5: train_loss=0.0050, val_loss=0.0043,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\n=== Training with weight_decay =\n0.001 ===', '\\n', 'WD=0.001 Epoch 1: train_loss=0.7762, val_loss=0.1814,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=0.001 Epoch 2: train_loss=0.0877,\nval_loss=0.0342, train_AICR=1.0000, val_AICR=1.0000', '\\n', 'WD=0.001 Epoch 3:\ntrain_loss=0.0239, val_loss=0.0168, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'WD=0.001 Epoch 4: train_loss=0.0141, val_loss=0.0117, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'WD=0.001 Epoch 5: train_loss=0.0104, val_loss=0.0091,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n',\n'Execution time: 3 seconds seconds (time limit is an hour).']", "['Depth=1 Epoch 1: train_loss=0.4099, val_loss=0.0751, train_acc=0.9487,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 2:\ntrain_loss=0.0321, val_loss=0.0149, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 3: train_loss=0.0102,\nval_loss=0.0079, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=1 Epoch 4: train_loss=0.0062, val_loss=0.0053,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=1 Epoch 5: train_loss=0.0043, val_loss=0.0039, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 1:\ntrain_loss=0.5766, val_loss=0.0509, train_acc=0.8738, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 2: train_loss=0.0115,\nval_loss=0.0016, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=2 Epoch 3: train_loss=0.0011, val_loss=0.0008,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=2 Epoch 4: train_loss=0.0007, val_loss=0.0006, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 5:\ntrain_loss=0.0006, val_loss=0.0005, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with dropout_rate = 0.0 ===', '\\n',\n'DR=0.0 Epoch 1: train_loss=1.1887, val_loss=0.5835, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.0 Epoch 2: train_loss=0.3398, val_loss=0.1643,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.0 Epoch 3: train_loss=0.1051,\nval_loss=0.0651, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.0 Epoch 4:\ntrain_loss=0.0485, val_loss=0.0360, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.0 Epoch 5: train_loss=0.0292, val_loss=0.0236, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Training with dropout_rate = 0.2 ===', '\\n',\n'DR=0.2 Epoch 1: train_loss=1.1779, val_loss=0.5849, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.2 Epoch 2: train_loss=0.3629, val_loss=0.1692,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.2 Epoch 3: train_loss=0.1323,\nval_loss=0.0670, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.2 Epoch 4:\ntrain_loss=0.0729, val_loss=0.0347, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.2 Epoch 5: train_loss=0.0425, val_loss=0.0213, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Training with dropout_rate = 0.5 ===', '\\n',\n'DR=0.5 Epoch 1: train_loss=0.9809, val_loss=0.3964, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'DR=0.5 Epoch 2: train_loss=0.3664, val_loss=0.1210,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.5 Epoch 3: train_loss=0.2021,\nval_loss=0.0527, train_rate=1.0000, val_rate=1.0000', '\\n', 'DR=0.5 Epoch 4:\ntrain_loss=0.1305, val_loss=0.0270, train_rate=1.0000, val_rate=1.0000', '\\n',\n'DR=0.5 Epoch 5: train_loss=0.0834, val_loss=0.0157, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution time: 5\nseconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Training with batch size = 8 ===', '\\n',\n'BS=8 Epoch 1: train_loss=0.2311, val_loss=0.0090, train_rate=1.0000,\nval_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=8 Epoch\n2: train_loss=0.0052, val_loss=0.0031, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=8 Epoch 3:\ntrain_loss=0.0022, val_loss=0.0016, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=8 Epoch 4:\ntrain_loss=0.0012, val_loss=0.0010, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=8 Epoch 5:\ntrain_loss=0.0008, val_loss=0.0007, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', '\\n=== Training with batch\nsize = 16 ===', '\\n', 'BS=16 Epoch 1: train_loss=0.4219, val_loss=0.0274,\ntrain_rate=1.0000, val_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00',\n'\\n', 'BS=16 Epoch 2: train_loss=0.0139, val_loss=0.0081, train_rate=1.0000,\nval_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=16 Epoch\n3: train_loss=0.0060, val_loss=0.0044, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=16 Epoch 4:\ntrain_loss=0.0035, val_loss=0.0028, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=16 Epoch 5:\ntrain_loss=0.0024, val_loss=0.0020, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', '\\n=== Training with batch\nsize = 32 ===', '\\n', 'BS=32 Epoch 1: train_loss=0.5022, val_loss=0.0736,\ntrain_rate=1.0000, val_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00',\n'\\n', 'BS=32 Epoch 2: train_loss=0.0330, val_loss=0.0153, train_rate=1.0000,\nval_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=32 Epoch\n3: train_loss=0.0110, val_loss=0.0084, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=32 Epoch 4:\ntrain_loss=0.0069, val_loss=0.0058, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=32 Epoch 5:\ntrain_loss=0.0049, val_loss=0.0043, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', '\\n=== Training with batch\nsize = 64 ===', '\\n', 'BS=64 Epoch 1: train_loss=0.9319, val_loss=0.3959,\ntrain_rate=1.0000, val_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00',\n'\\n', 'BS=64 Epoch 2: train_loss=0.2056, val_loss=0.0868, train_rate=1.0000,\nval_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=64 Epoch\n3: train_loss=0.0533, val_loss=0.0296, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=64 Epoch 4:\ntrain_loss=0.0220, val_loss=0.0159, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=64 Epoch 5:\ntrain_loss=0.0131, val_loss=0.0108, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', '\\n=== Training with batch\nsize = 128 ===', '\\n', 'BS=128 Epoch 1: train_loss=1.2194, val_loss=0.8239,\ntrain_rate=1.0000, val_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00',\n'\\n', 'BS=128 Epoch 2: train_loss=0.5870, val_loss=0.3791, train_rate=1.0000,\nval_rate=1.0000, mean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=128\nEpoch 3: train_loss=0.2623, val_loss=0.1709, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=128 Epoch 4:\ntrain_loss=0.1200, val_loss=0.0841, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'BS=128 Epoch 5:\ntrain_loss=0.0616, val_loss=0.0475, train_rate=1.0000, val_rate=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', '\\nSaved\nexperiment_data.npy', '\\n', 'Execution time: 7 seconds seconds (time limit is an\nhour).']", "['Using device: cuda', '\\n', '\\n=== Dataset: arithmetic ===', '\\n', 'Epoch 1:\nvalidation_loss = 0.0751', '\\n', 'Dataset=arithmetic Epoch 1: train_loss=0.4099,\nval_loss=0.0751, train_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 2:\nvalidation_loss = 0.0151', '\\n', 'Dataset=arithmetic Epoch 2: train_loss=0.0318,\nval_loss=0.0151, train_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 3:\nvalidation_loss = 0.0078', '\\n', 'Dataset=arithmetic Epoch 3: train_loss=0.0103,\nval_loss=0.0078, train_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 4:\nvalidation_loss = 0.0053', '\\n', 'Dataset=arithmetic Epoch 4: train_loss=0.0062,\nval_loss=0.0053, train_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 5:\nvalidation_loss = 0.0039', '\\n', 'Dataset=arithmetic Epoch 5: train_loss=0.0043,\nval_loss=0.0039, train_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Dataset:\npolynomial ===', '\\n', 'Epoch 1: validation_loss = 0.0508', '\\n',\n'Dataset=polynomial Epoch 1: train_loss=0.2943, val_loss=0.0508,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 2: validation_loss = 0.0089',\n'\\n', 'Dataset=polynomial Epoch 2: train_loss=0.0223, val_loss=0.0089,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 3: validation_loss = 0.0043',\n'\\n', 'Dataset=polynomial Epoch 3: train_loss=0.0061, val_loss=0.0043,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 4: validation_loss = 0.0028',\n'\\n', 'Dataset=polynomial Epoch 4: train_loss=0.0035, val_loss=0.0028,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Epoch 5: validation_loss = 0.0020',\n'\\n', 'Dataset=polynomial Epoch 5: train_loss=0.0023, val_loss=0.0020,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', '\\n=== Dataset: bitwise ===', '\\n',\n'Epoch 1: validation_loss = 0.1100', '\\n', 'Dataset=bitwise Epoch 1:\ntrain_loss=0.5751, val_loss=0.1100, train_rate=0.5850, val_rate=0.5800', '\\n',\n'Epoch 2: validation_loss = 0.0216', '\\n', 'Dataset=bitwise Epoch 2:\ntrain_loss=0.0495, val_loss=0.0216, train_rate=0.5850, val_rate=0.5800', '\\n',\n'Epoch 3: validation_loss = 0.0108', '\\n', 'Dataset=bitwise Epoch 3:\ntrain_loss=0.0151, val_loss=0.0108, train_rate=0.5850, val_rate=0.5800', '\\n',\n'Epoch 4: validation_loss = 0.0072', '\\n', 'Dataset=bitwise Epoch 4:\ntrain_loss=0.0088, val_loss=0.0072, train_rate=0.5850, val_rate=0.5800', '\\n',\n'Epoch 5: validation_loss = 0.0052', '\\n', 'Dataset=bitwise Epoch 5:\ntrain_loss=0.0061, val_loss=0.0052, train_rate=0.5850, val_rate=0.5800', '\\n',\n'\\n=== Dataset: combined ===', '\\n', 'Epoch 1: validation_loss = 0.4744', '\\n',\n'Dataset=combined Epoch 1: train_loss=1.3040, val_loss=0.4744,\ntrain_rate=0.8137, val_rate=0.8650', '\\n', 'Epoch 2: validation_loss = 0.0837',\n'\\n', 'Dataset=combined Epoch 2: train_loss=0.2240, val_loss=0.0837,\ntrain_rate=0.8137, val_rate=0.8650', '\\n', 'Epoch 3: validation_loss = 0.0310',\n'\\n', 'Dataset=combined Epoch 3: train_loss=0.0500, val_loss=0.0310,\ntrain_rate=0.8137, val_rate=0.8650', '\\n', 'Epoch 4: validation_loss = 0.0181',\n'\\n', 'Dataset=combined Epoch 4: train_loss=0.0234, val_loss=0.0181,\ntrain_rate=0.8137, val_rate=0.8650', '\\n', 'Epoch 5: validation_loss = 0.0123',\n'\\n', 'Dataset=combined Epoch 5: train_loss=0.0148, val_loss=0.0123,\ntrain_rate=0.8137, val_rate=0.8650', '\\n', '\\nSaved experiment_data.npy', '\\n',\n'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Optimizer: Adam ===', '\\n', 'Adam Epoch 1:\ntrain_loss=0.7699, val_loss=0.1406, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adam Epoch 2:\ntrain_loss=0.0574, val_loss=0.0220, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adam Epoch 3:\ntrain_loss=0.0150, val_loss=0.0108, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adam Epoch 4:\ntrain_loss=0.0087, val_loss=0.0072, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adam Epoch 5:\ntrain_loss=0.0061, val_loss=0.0052, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', '\\n=== Optimizer: SGD\n===', '\\n', 'SGD Epoch 1: train_loss=0.7054, val_loss=0.0939, train_AICR=1.0000,\nval_AICR=1.0000, mean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'SGD\nEpoch 2: train_loss=0.0427, val_loss=0.0231, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'SGD Epoch 3:\ntrain_loss=0.0185, val_loss=0.0157, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'SGD Epoch 4:\ntrain_loss=0.0140, val_loss=0.0126, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'SGD Epoch 5:\ntrain_loss=0.0115, val_loss=0.0106, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', '\\n=== Optimizer:\nRMSprop ===', '\\n', 'RMSprop Epoch 1: train_loss=0.1146, val_loss=0.0106,\ntrain_AICR=1.0000, val_AICR=1.0000, mean_iters_conv_train=1.0,\nmean_iters_conv_val=1.0', '\\n', 'RMSprop Epoch 2: train_loss=0.0067,\nval_loss=0.0043, train_AICR=1.0000, val_AICR=1.0000, mean_iters_conv_train=1.0,\nmean_iters_conv_val=1.0', '\\n', 'RMSprop Epoch 3: train_loss=0.0032,\nval_loss=0.0025, train_AICR=1.0000, val_AICR=1.0000, mean_iters_conv_train=1.0,\nmean_iters_conv_val=1.0', '\\n', 'RMSprop Epoch 4: train_loss=0.0020,\nval_loss=0.0016, train_AICR=1.0000, val_AICR=1.0000, mean_iters_conv_train=1.0,\nmean_iters_conv_val=1.0', '\\n', 'RMSprop Epoch 5: train_loss=0.0014,\nval_loss=0.0012, train_AICR=1.0000, val_AICR=1.0000, mean_iters_conv_train=1.0,\nmean_iters_conv_val=1.0', '\\n', '\\n=== Optimizer: Adagrad ===', '\\n', 'Adagrad\nEpoch 1: train_loss=0.9986, val_loss=0.7364, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adagrad Epoch 2:\ntrain_loss=0.5752, val_loss=0.4862, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adagrad Epoch 3:\ntrain_loss=0.3985, val_loss=0.3526, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adagrad Epoch 4:\ntrain_loss=0.2977, val_loss=0.2705, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', 'Adagrad Epoch 5:\ntrain_loss=0.2337, val_loss=0.2163, train_AICR=1.0000, val_AICR=1.0000,\nmean_iters_conv_train=1.0, mean_iters_conv_val=1.0', '\\n', '\\nSaved\nexperiment_data.npy in /data/chenhui/AI-Scientist-v2/experiments/2025-06-07_15-\n26-52_abstract_interpretation_guided_generation_attempt_0/0-\nrun/process_ForkProcess-15/working', '\\n', 'Execution time: 6 seconds seconds\n(time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Label smoothing = 0.0 ===', '\\n',\n'smooth=0.0 Epoch 1: train_loss=0.7699, val_loss=0.1406,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.0 Epoch 2:\ntrain_loss=0.0574, val_loss=0.0220, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'smooth=0.0 Epoch 3: train_loss=0.0150,\nval_loss=0.0108, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'smooth=0.0 Epoch 4: train_loss=0.0087, val_loss=0.0072,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.0 Epoch 5:\ntrain_loss=0.0061, val_loss=0.0052, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Label smoothing = 0.1 ===', '\\n',\n'smooth=0.1 Epoch 1: train_loss=0.8501, val_loss=0.3819,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.1 Epoch 2:\ntrain_loss=0.3588, val_loss=0.3560, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'smooth=0.1 Epoch 3: train_loss=0.3524,\nval_loss=0.3496, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'smooth=0.1 Epoch 4: train_loss=0.3491, val_loss=0.3489,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.1 Epoch 5:\ntrain_loss=0.3488, val_loss=0.3488, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\n=== Label smoothing = 0.2 ===', '\\n',\n'smooth=0.2 Epoch 1: train_loss=0.7963, val_loss=0.5990,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.2 Epoch 2:\ntrain_loss=0.5969, val_loss=0.5889, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', 'smooth=0.2 Epoch 3: train_loss=0.5881,\nval_loss=0.5876, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n',\n'smooth=0.2 Epoch 4: train_loss=0.5876, val_loss=0.5875,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000', '\\n', 'smooth=0.2 Epoch 5:\ntrain_loss=0.5875, val_loss=0.5875, train_rate(AICR)=1.0000,\nval_rate(AICR)=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution\ntime: 2 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Label smoothing = 0.0 ===', '\\n', 'Epoch 1:\nvalidation_loss = 0.1406', '\\n', 'smooth=0.0 Epoch 1: train_loss=0.7699,\nval_loss=0.1406, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'Epoch 2: validation_loss =\n0.0220', '\\n', 'smooth=0.0 Epoch 2: train_loss=0.0574, val_loss=0.0220,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 3: validation_loss = 0.0108', '\\n',\n'smooth=0.0 Epoch 3: train_loss=0.0150, val_loss=0.0108,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 4: validation_loss = 0.0072', '\\n',\n'smooth=0.0 Epoch 4: train_loss=0.0087, val_loss=0.0072,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 5: validation_loss = 0.0052', '\\n',\n'smooth=0.0 Epoch 5: train_loss=0.0061, val_loss=0.0052,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', '\\n=== Label smoothing = 0.1 ===', '\\n', 'Epoch 1:\nvalidation_loss = 0.3819', '\\n', 'smooth=0.1 Epoch 1: train_loss=0.8501,\nval_loss=0.3819, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'Epoch 2: validation_loss =\n0.3560', '\\n', 'smooth=0.1 Epoch 2: train_loss=0.3588, val_loss=0.3560,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 3: validation_loss = 0.3496', '\\n',\n'smooth=0.1 Epoch 3: train_loss=0.3524, val_loss=0.3496,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 4: validation_loss = 0.3489', '\\n',\n'smooth=0.1 Epoch 4: train_loss=0.3491, val_loss=0.3489,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 5: validation_loss = 0.3488', '\\n',\n'smooth=0.1 Epoch 5: train_loss=0.3488, val_loss=0.3488,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', '\\n=== Label smoothing = 0.2 ===', '\\n', 'Epoch 1:\nvalidation_loss = 0.5990', '\\n', 'smooth=0.2 Epoch 1: train_loss=0.7963,\nval_loss=0.5990, train_rate(AICR)=1.0000, val_rate(AICR)=1.0000,\nmean_iters_train=1.00, mean_iters_val=1.00', '\\n', 'Epoch 2: validation_loss =\n0.5889', '\\n', 'smooth=0.2 Epoch 2: train_loss=0.5969, val_loss=0.5889,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 3: validation_loss = 0.5876', '\\n',\n'smooth=0.2 Epoch 3: train_loss=0.5881, val_loss=0.5876,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 4: validation_loss = 0.5875', '\\n',\n'smooth=0.2 Epoch 4: train_loss=0.5876, val_loss=0.5875,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', 'Epoch 5: validation_loss = 0.5875', '\\n',\n'smooth=0.2 Epoch 5: train_loss=0.5875, val_loss=0.5875,\ntrain_rate(AICR)=1.0000, val_rate(AICR)=1.0000, mean_iters_train=1.00,\nmean_iters_val=1.00', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution\ntime: 5 seconds seconds (time limit is an hour).']", "['\\n=== Ablation: vocab size = 4 ===', '\\n', 'V=4 E=1 tr_loss=0.4099\nval_loss=0.0751 tr_AICR=1.0000 val_AICR=1.0000', '\\n', 'V=4 E=2 tr_loss=0.0318\nval_loss=0.0151 tr_AICR=1.0000 val_AICR=1.0000', '\\n', 'V=4 E=3 tr_loss=0.0103\nval_loss=0.0078 tr_AICR=1.0000 val_AICR=1.0000', '\\n', 'V=4 E=4 tr_loss=0.0062\nval_loss=0.0053 tr_AICR=1.0000 val_AICR=1.0000', '\\n', 'V=4 E=5 tr_loss=0.0043\nval_loss=0.0039 tr_AICR=1.0000 val_AICR=1.0000', '\\n', '\\n=== Ablation: vocab\nsize = 8 ===', '\\n', 'V=8 E=1 tr_loss=1.3245 val_loss=0.5235 tr_AICR=0.7388\nval_AICR=0.7300', '\\n', 'V=8 E=2 tr_loss=0.2330 val_loss=0.0764 tr_AICR=0.7388\nval_AICR=0.7300', '\\n', 'V=8 E=3 tr_loss=0.0450 val_loss=0.0256 tr_AICR=0.7388\nval_AICR=0.7300', '\\n', 'V=8 E=4 tr_loss=0.0197 val_loss=0.0146 tr_AICR=0.7388\nval_AICR=0.7300', '\\n', 'V=8 E=5 tr_loss=0.0122 val_loss=0.0099 tr_AICR=0.7388\nval_AICR=0.7300', '\\n', '\\n=== Ablation: vocab size = 16 ===', '\\n', 'V=16 E=1\ntr_loss=1.7921 val_loss=0.8207 tr_AICR=0.7450 val_AICR=0.7800', '\\n', 'V=16 E=2\ntr_loss=0.4113 val_loss=0.1552 tr_AICR=0.7450 val_AICR=0.7800', '\\n', 'V=16 E=3\ntr_loss=0.0889 val_loss=0.0494 tr_AICR=0.7450 val_AICR=0.7800', '\\n', 'V=16 E=4\ntr_loss=0.0366 val_loss=0.0266 tr_AICR=0.7450 val_AICR=0.7800', '\\n', 'V=16 E=5\ntr_loss=0.0218 val_loss=0.0175 tr_AICR=0.7450 val_AICR=0.7800', '\\n', '\\nSaved\nexperiment_data.npy', '\\n', 'Execution time: 2 seconds seconds (time limit is an\nhour).']", "['LR=0.001 Epoch 1: train_loss=1.7520, val_loss=1.5508, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'LR=0.001 Epoch 2: train_loss=1.4613, val_loss=1.2867,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.001 Epoch 3: train_loss=1.2100,\nval_loss=1.0625, train_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.001 Epoch 4:\ntrain_loss=0.9986, val_loss=0.8772, train_rate=1.0000, val_rate=1.0000', '\\n',\n'LR=0.001 Epoch 5: train_loss=0.8237, val_loss=0.7264, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'LR=0.005 Epoch 1: train_loss=1.2127, val_loss=0.6970,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.005 Epoch 2: train_loss=0.4513,\nval_loss=0.2763, train_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.005 Epoch 3:\ntrain_loss=0.1994, val_loss=0.1441, train_rate=1.0000, val_rate=1.0000', '\\n',\n'LR=0.005 Epoch 4: train_loss=0.1144, val_loss=0.0919, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'LR=0.005 Epoch 5: train_loss=0.0773, val_loss=0.0657,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.01 Epoch 1: train_loss=0.5752,\nval_loss=0.1330, train_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.01 Epoch 2:\ntrain_loss=0.0697, val_loss=0.0377, train_rate=1.0000, val_rate=1.0000', '\\n',\n'LR=0.01 Epoch 3: train_loss=0.0289, val_loss=0.0225, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'LR=0.01 Epoch 4: train_loss=0.0190, val_loss=0.0161,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.01 Epoch 5: train_loss=0.0141,\nval_loss=0.0123, train_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.02 Epoch 1:\ntrain_loss=0.3801, val_loss=0.0310, train_rate=1.0000, val_rate=1.0000', '\\n',\n'LR=0.02 Epoch 2: train_loss=0.0164, val_loss=0.0095, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'LR=0.02 Epoch 3: train_loss=0.0077, val_loss=0.0066,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.02 Epoch 4: train_loss=0.0058,\nval_loss=0.0053, train_rate=1.0000, val_rate=1.0000', '\\n', 'LR=0.02 Epoch 5:\ntrain_loss=0.0046, val_loss=0.0043, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Saved experiment_data.npy', '\\n', 'Execution time: 2 seconds seconds (time\nlimit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Running weight\u2010tying = untied ===', '\\n',\n'UNTIED Epoch 1: train_loss=0.7699, val_loss=0.1406, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'UNTIED Epoch 2: train_loss=0.0574, val_loss=0.0220,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'UNTIED Epoch 3: train_loss=0.0150,\nval_loss=0.0108, train_rate=1.0000, val_rate=1.0000', '\\n', 'UNTIED Epoch 4:\ntrain_loss=0.0087, val_loss=0.0072, train_rate=1.0000, val_rate=1.0000', '\\n',\n'UNTIED Epoch 5: train_loss=0.0061, val_loss=0.0052, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\n=== Running weight\u2010tying = tied ===', '\\n', 'TIED\nEpoch 1: train_loss=0.0001, val_loss=0.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'TIED Epoch 2: train_loss=0.0000, val_loss=0.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'TIED Epoch 3: train_loss=0.0000,\nval_loss=0.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'TIED Epoch 4:\ntrain_loss=0.0000, val_loss=0.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'TIED Epoch 5: train_loss=0.0000, val_loss=0.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n', 'Execution time: 2\nseconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Ablation: vocab size = 4 ===', '\\n', 'Epoch\n1: validation_loss = 0.0751', '\\n', 'V=4 E=1 tr_AICR=1.0000 val_AICR=1.0000\ntr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 2: validation_loss = 0.0151', '\\n',\n'V=4 E=2 tr_AICR=1.0000 val_AICR=1.0000 tr_MItC=1.00 val_MItC=1.00', '\\n',\n'Epoch 3: validation_loss = 0.0078', '\\n', 'V=4 E=3 tr_AICR=1.0000\nval_AICR=1.0000 tr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 4: validation_loss =\n0.0053', '\\n', 'V=4 E=4 tr_AICR=1.0000 val_AICR=1.0000 tr_MItC=1.00\nval_MItC=1.00', '\\n', 'Epoch 5: validation_loss = 0.0039', '\\n', 'V=4 E=5\ntr_AICR=1.0000 val_AICR=1.0000 tr_MItC=1.00 val_MItC=1.00', '\\n', '\\n===\nAblation: vocab size = 8 ===', '\\n', 'Epoch 1: validation_loss = 0.5235', '\\n',\n'V=8 E=1 tr_AICR=0.7388 val_AICR=0.7300 tr_MItC=1.00 val_MItC=1.00', '\\n',\n'Epoch 2: validation_loss = 0.0764', '\\n', 'V=8 E=2 tr_AICR=0.7388\nval_AICR=0.7300 tr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 3: validation_loss =\n0.0256', '\\n', 'V=8 E=3 tr_AICR=0.7388 val_AICR=0.7300 tr_MItC=1.00\nval_MItC=1.00', '\\n', 'Epoch 4: validation_loss = 0.0146', '\\n', 'V=8 E=4\ntr_AICR=0.7388 val_AICR=0.7300 tr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 5:\nvalidation_loss = 0.0099', '\\n', 'V=8 E=5 tr_AICR=0.7388 val_AICR=0.7300\ntr_MItC=1.00 val_MItC=1.00', '\\n', '\\n=== Ablation: vocab size = 16 ===', '\\n',\n'Epoch 1: validation_loss = 0.8207', '\\n', 'V=16 E=1 tr_AICR=0.7450\nval_AICR=0.7800 tr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 2: validation_loss =\n0.1552', '\\n', 'V=16 E=2 tr_AICR=0.7450 val_AICR=0.7800 tr_MItC=1.00\nval_MItC=1.00', '\\n', 'Epoch 3: validation_loss = 0.0494', '\\n', 'V=16 E=3\ntr_AICR=0.7450 val_AICR=0.7800 tr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 4:\nvalidation_loss = 0.0266', '\\n', 'V=16 E=4 tr_AICR=0.7450 val_AICR=0.7800\ntr_MItC=1.00 val_MItC=1.00', '\\n', 'Epoch 5: validation_loss = 0.0175', '\\n',\n'V=16 E=5 tr_AICR=0.7450 val_AICR=0.7800 tr_MItC=1.00 val_MItC=1.00', '\\n',\n'\\nSaved experiment_data.npy', '\\n', 'Execution time: 2 seconds seconds (time\nlimit is an hour).']", "['Using device: cuda', '\\n', '\\n=== Noise level = 10% ===', '\\n', 'Noise=10%\nEpoch 1: train_loss=0.6597, val_loss=0.1151, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=10% Epoch 2: train_loss=0.4447, val_loss=0.0908,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'Noise=10% Epoch 3:\ntrain_loss=0.4382, val_loss=0.1104, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'Noise=10% Epoch 4: train_loss=0.4378, val_loss=0.1120, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=10% Epoch 5: train_loss=0.4362, val_loss=0.0994,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\n=== Noise level = 20% ===', '\\n',\n'Noise=20% Epoch 1: train_loss=0.9163, val_loss=0.2118, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=20% Epoch 2: train_loss=0.7294, val_loss=0.2059,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'Noise=20% Epoch 3:\ntrain_loss=0.7207, val_loss=0.2228, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'Noise=20% Epoch 4: train_loss=0.7204, val_loss=0.2203, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=20% Epoch 5: train_loss=0.7231, val_loss=0.2169,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\n=== Noise level = 30% ===', '\\n',\n'Noise=30% Epoch 1: train_loss=1.0625, val_loss=0.3135, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=30% Epoch 2: train_loss=0.9575, val_loss=0.3357,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', 'Noise=30% Epoch 3:\ntrain_loss=0.9485, val_loss=0.3614, train_AICR=1.0000, val_AICR=1.0000', '\\n',\n'Noise=30% Epoch 4: train_loss=0.9509, val_loss=0.3288, train_AICR=1.0000,\nval_AICR=1.0000', '\\n', 'Noise=30% Epoch 5: train_loss=0.9517, val_loss=0.3653,\ntrain_AICR=1.0000, val_AICR=1.0000', '\\n', '\\nSaved experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is an hour).']", "['Depth=1 Epoch 1: train_loss=0.4099, val_loss=0.0751, train_acc=0.9487,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 2:\ntrain_loss=0.0321, val_loss=0.0149, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 3: train_loss=0.0102,\nval_loss=0.0079, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=1 Epoch 4: train_loss=0.0062, val_loss=0.0053,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=1 Epoch 5: train_loss=0.0043, val_loss=0.0039, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 1:\ntrain_loss=0.5766, val_loss=0.0509, train_acc=0.8738, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 2: train_loss=0.0115,\nval_loss=0.0016, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=2 Epoch 3: train_loss=0.0011, val_loss=0.0008,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=2 Epoch 4: train_loss=0.0007, val_loss=0.0006, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 5:\ntrain_loss=0.0006, val_loss=0.0005, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is an hour).']", "['Depth=1 Epoch 1: train_loss=0.4099, val_loss=0.0751, train_acc=0.9487,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 2:\ntrain_loss=0.0321, val_loss=0.0149, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 3: train_loss=0.0102,\nval_loss=0.0079, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=1 Epoch 4: train_loss=0.0062, val_loss=0.0053,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=1 Epoch 5: train_loss=0.0043, val_loss=0.0039, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 1:\ntrain_loss=0.5766, val_loss=0.0509, train_acc=0.8738, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 2: train_loss=0.0115,\nval_loss=0.0016, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=2 Epoch 3: train_loss=0.0011, val_loss=0.0008,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=2 Epoch 4: train_loss=0.0007, val_loss=0.0006, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 5:\ntrain_loss=0.0006, val_loss=0.0005, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is an hour).']", "['Depth=1 Epoch 1: train_loss=0.4099, val_loss=0.0751, train_acc=0.9487,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 2:\ntrain_loss=0.0321, val_loss=0.0149, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=1 Epoch 3: train_loss=0.0102,\nval_loss=0.0079, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=1 Epoch 4: train_loss=0.0062, val_loss=0.0053,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=1 Epoch 5: train_loss=0.0043, val_loss=0.0039, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 1:\ntrain_loss=0.5766, val_loss=0.0509, train_acc=0.8738, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 2: train_loss=0.0115,\nval_loss=0.0016, train_acc=1.0000, val_acc=1.0000, train_rate=1.0000,\nval_rate=1.0000', '\\n', 'Depth=2 Epoch 3: train_loss=0.0011, val_loss=0.0008,\ntrain_acc=1.0000, val_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n',\n'Depth=2 Epoch 4: train_loss=0.0007, val_loss=0.0006, train_acc=1.0000,\nval_acc=1.0000, train_rate=1.0000, val_rate=1.0000', '\\n', 'Depth=2 Epoch 5:\ntrain_loss=0.0006, val_loss=0.0005, train_acc=1.0000, val_acc=1.0000,\ntrain_rate=1.0000, val_rate=1.0000', '\\n', 'Saved experiment_data.npy', '\\n',\n'Execution time: 2 seconds seconds (time limit is an hour).']", ""], "analysis": ["", "The generation evaluation loop is flawed: it always uses the ground-truth\nbase_code and the fixed sid lists rather than the model\u2019s predictions, so\ntrain/val pass rates remain constant across epochs and predictions saved are\nidentical to the ground truth. As a result, the evaluation doesn\u2019t reflect model\nlearning. To fix, have evaluate_generation receive and execute code synthesized\nfrom the model\u2019s outputs (e.g., sampled token sequences or predicted op IDs)\ninstead of always using base_code, and update the predictions stored\naccordingly. Additionally, bitwise tests fail for negative shift counts\u2014either\nrestrict test b values to non-negative or guard against negative shifts in the\ngenerated code.", "", "The evaluation routine is flawed: evaluate_generation always uses the\nground\u2010truth base_code mapping (and never the model\u2019s predictions) to generate\nthe function under test, so AICR metrics are always 100% regardless of the\nlearned model. This gives no insight into the effect of batch size or model\nbehavior. To fix this, pass the trained model (or its argmax predictions) into\nevaluate_generation, generate code based on the model\u2019s predicted operation ID,\nand then measure correctness. Additionally, remove the duplicate \u201cseconds\nseconds\u201d in the final log printout.", "The script executed successfully without runtime errors, but there is a logical\nbug in the evaluation metric. The evaluate_generation function uses the ground-\ntruth IDs (train_ids and val_ids) to generate and test code, rather than using\nthe model\u2019s predicted classes. As a result, the code correctness rate (AICR) is\nalways 1.0 regardless of model performance. To fix this, evaluate_generation\nshould accept and run on the model\u2019s predicted IDs (e.g., based on logits.argmax\noutputs) instead of the true labels, so that the AICR metric accurately reflects\nthe model\u2019s generation quality.", "The script runs without runtime errors and losses converge as expected, but the\ngeneration evaluation is flawed: evaluate_generation is always called on the\ntrue id_list instead of the model\u2019s predictions, and the recorded\npredictions/ground truth also ignore the model output. As a result, train_rate\nand val_rate are trivially 1.0 regardless of the model.  Proposed fix: Change\nevaluate_generation to accept a list of predicted operation IDs (from\nmodel.argmax) rather than the ground truth IDs. In each epoch, collect model\npredictions for the train/val splits, pass those predictions into\nevaluate_generation, and similarly record generated code strings based on the\npredicted IDs rather than the static val_ids.", "", "", "", "", "", "", "The evaluation logic is flawed: evaluate_generation() and prediction collection\nignore the trained model entirely, using the static base_code mapping instead.\nThis yields a constant 100% pass rate and identical code stubs across all\nsmoothing settings, making the ablation meaningless.\\nProposed fix: have\nevaluate_generation accept the trained model, use model(x) \u2192 predicted_id via\nargmax, and then generate code from that predicted_id. Also update the\npredictions recording to reflect model outputs instead of the static base_code\noutputs.", "", "The generation\u2010evaluation step is flawed: evaluate_generation always uses the\nstatic ground\u2010truth code_map instead of the model\u2019s predicted operators. As a\nresult, the reported tr_AICR and val_AICR stay constant across epochs and do not\nreflect any learning. To fix this, have evaluate_generation take the model (or\nits predictions) as input\u2014e.g., run the model on the id_list, use argmax on the\nlogits to get predicted op IDs, and then evaluate those predicted expressions\ninstead of code_map[sid].", "", "The script ran without runtime errors, but the evaluation logic has a critical\nflaw: `evaluate_generation` and the prediction logging bypass the trained model\nentirely and instead use the static `base_code` mapping, yielding perfect\n\u201ctrain_rate\u201d and \u201cval_rate\u201d regardless of model performance. To fix this, update\n`evaluate_generation` to use the model\u2019s argmax predictions for each spec ID\nwhen generating code, and modify the prediction/ground-truth logging to reflect\nactual model outputs rather than the hardcoded mapping.", "", "The evaluate_generation function is flawed: it compares each generated\nfunction\u2019s output against a reference computed from its own predicted spec (sid)\nrather than the true spec. As a result, it always reports 100% correctness\n(train_AICR and val_AICR = 1.0) regardless of noise level. To fix this,\nevaluate_generation should accept both predicted_ids and true_ids, generate code\nfrom predicted_ids, but compute the reference outputs using the true spec\n(base_code[true_id]) when checking correctness. Alternatively, pass the true\nspec into evaluate_generation so that the guard and ref computations use the\nground-truth operation, not the prediction.", "The training script ran to completion with no runtime errors, but the\nevaluate_generation function is logically flawed: it tests each generated code\nsnippet against its own reference output rather than comparing it to the ground-\ntruth specification. This causes the generation pass rate to always be 100%,\nmaking the metric meaningless. To fix this, modify evaluate_generation to take\nboth predicted and true spec IDs (or code) and compare the output of the\ngenerated code against the reference output of the ground-truth code.", "The script runs without errors but the generative correctness metric\n(evaluate_generation) is flawed. It uses a fixed, small set of 6 test pairs for\nevery predicted spec and tests the generated code only against itself, so it\nalways returns a pass rate of 1.0. This masks any differences between head\ndepths and makes the ablation useless.\\nProposed fix: For each predicted spec,\nsample or define a diverse, spec-specific set of (a,b) test inputs and compute\nthe reference output from the true spec rather than from the predicted code.\nThen compare the generated code\u2019s output against that reference. This will\nproduce meaningful generative metrics. Additionally, remove or unify the\nduplicate random seed calls (np.random.seed(1) vs np.random.seed(0)) to ensure\nconsistent reproducibility.", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss", "data": [{"dataset_name": "synthetic (lr=0.001)", "final_value": 0.7202, "best_value": 0.7202}, {"dataset_name": "synthetic (lr=0.005)", "final_value": 0.0289, "best_value": 0.0289}, {"dataset_name": "synthetic (lr=0.01)", "final_value": 0.0049, "best_value": 0.0049}, {"dataset_name": "synthetic (lr=0.02)", "final_value": 0.0009, "best_value": 0.0009}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss", "data": [{"dataset_name": "synthetic (lr=0.001)", "final_value": 0.6189, "best_value": 0.6189}, {"dataset_name": "synthetic (lr=0.005)", "final_value": 0.0233, "best_value": 0.0233}, {"dataset_name": "synthetic (lr=0.01)", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "synthetic (lr=0.02)", "final_value": 0.0008, "best_value": 0.0008}]}, {"metric_name": "training generation success rate (AICR)", "lower_is_better": false, "description": "Final training generation success rate", "data": [{"dataset_name": "synthetic (lr=0.001)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.005)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.01)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.02)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation success rate (AICR)", "lower_is_better": false, "description": "Final validation generation success rate", "data": [{"dataset_name": "synthetic (lr=0.001)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.005)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.01)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (lr=0.02)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy on the training set", "data": [{"dataset_name": "arithmetic", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "polynomial", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "bitwise", "final_value": 0.585, "best_value": 0.585}, {"dataset_name": "combined", "final_value": 0.8137, "best_value": 0.8137}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation set", "data": [{"dataset_name": "arithmetic", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "polynomial", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "bitwise", "final_value": 0.58, "best_value": 0.58}, {"dataset_name": "combined", "final_value": 0.865, "best_value": 0.865}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training set", "data": [{"dataset_name": "arithmetic", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "polynomial", "final_value": 0.0023, "best_value": 0.0023}, {"dataset_name": "bitwise", "final_value": 0.0061, "best_value": 0.0061}, {"dataset_name": "combined", "final_value": 0.0148, "best_value": 0.0148}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation set", "data": [{"dataset_name": "arithmetic", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "polynomial", "final_value": 0.002, "best_value": 0.002}, {"dataset_name": "bitwise", "final_value": 0.0052, "best_value": 0.0052}, {"dataset_name": "combined", "final_value": 0.0123, "best_value": 0.0123}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy on the training dataset for each synthetic embedding_dim variant", "data": [{"dataset_name": "synthetic (embedding_dim = 2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 4)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 32)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation dataset for each synthetic embedding_dim variant", "data": [{"dataset_name": "synthetic (embedding_dim = 2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 4)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (embedding_dim = 32)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss on the training dataset for each synthetic embedding_dim variant", "data": [{"dataset_name": "synthetic (embedding_dim = 2)", "final_value": 0.435, "best_value": 0.435}, {"dataset_name": "synthetic (embedding_dim = 4)", "final_value": 0.0976, "best_value": 0.0976}, {"dataset_name": "synthetic (embedding_dim = 8)", "final_value": 0.017, "best_value": 0.017}, {"dataset_name": "synthetic (embedding_dim = 16)", "final_value": 0.0054, "best_value": 0.0054}, {"dataset_name": "synthetic (embedding_dim = 32)", "final_value": 0.0012, "best_value": 0.0012}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset for each synthetic embedding_dim variant", "data": [{"dataset_name": "synthetic (embedding_dim = 2)", "final_value": 0.3581, "best_value": 0.3581}, {"dataset_name": "synthetic (embedding_dim = 4)", "final_value": 0.0645, "best_value": 0.0645}, {"dataset_name": "synthetic (embedding_dim = 8)", "final_value": 0.0136, "best_value": 0.0136}, {"dataset_name": "synthetic (embedding_dim = 16)", "final_value": 0.0047, "best_value": 0.0047}, {"dataset_name": "synthetic (embedding_dim = 32)", "final_value": 0.0011, "best_value": 0.0011}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training set", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 0.0008, "best_value": 0.0008}, {"dataset_name": "synthetic (batch size 16)", "final_value": 0.0024, "best_value": 0.0024}, {"dataset_name": "synthetic (batch size 32)", "final_value": 0.0049, "best_value": 0.0049}, {"dataset_name": "synthetic (batch size 64)", "final_value": 0.0131, "best_value": 0.0131}, {"dataset_name": "synthetic (batch size 128)", "final_value": 0.0616, "best_value": 0.0616}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation set", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 0.0007, "best_value": 0.0007}, {"dataset_name": "synthetic (batch size 16)", "final_value": 0.002, "best_value": 0.002}, {"dataset_name": "synthetic (batch size 32)", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "synthetic (batch size 64)", "final_value": 0.0108, "best_value": 0.0108}, {"dataset_name": "synthetic (batch size 128)", "final_value": 0.0475, "best_value": 0.0475}]}, {"metric_name": "training accuracy", "lower_is_better": false, "description": "Accuracy on the training set", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation set", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Training accuracy on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Validation accuracy on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Training loss on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.2337, "best_value": 0.0014}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.2163, "best_value": 0.0012}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss at last epoch", "data": [{"dataset_name": "Synthetic (dropout 0.0)", "final_value": 0.0292, "best_value": 0.0292}, {"dataset_name": "Synthetic (dropout 0.2)", "final_value": 0.0432, "best_value": 0.0432}, {"dataset_name": "Synthetic (dropout 0.5)", "final_value": 0.0976, "best_value": 0.0976}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss at last epoch", "data": [{"dataset_name": "Synthetic (dropout 0.0)", "final_value": 0.0236, "best_value": 0.0236}, {"dataset_name": "Synthetic (dropout 0.2)", "final_value": 0.0218, "best_value": 0.0218}, {"dataset_name": "Synthetic (dropout 0.5)", "final_value": 0.0149, "best_value": 0.0149}]}, {"metric_name": "train generation pass rate", "lower_is_better": false, "description": "Final training generation pass rate at last epoch", "data": [{"dataset_name": "Synthetic (dropout 0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Synthetic (dropout 0.2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Synthetic (dropout 0.5)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate", "lower_is_better": false, "description": "Final validation generation pass rate at last epoch", "data": [{"dataset_name": "Synthetic (dropout 0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Synthetic (dropout 0.2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "Synthetic (dropout 0.5)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Average loss on the training split of the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0104, "best_value": 0.0043}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Average loss on the validation split of the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0091, "best_value": 0.0039}]}, {"metric_name": "training correctness rate", "lower_is_better": false, "description": "Proportion of correct predictions on the training split of the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation correctness rate", "lower_is_better": false, "description": "Proportion of correct predictions on the validation split of the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "head depth 1 train loss", "lower_is_better": true, "description": "Training loss for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 0.0043, "best_value": 0.0043}]}, {"metric_name": "head depth 1 validation loss", "lower_is_better": true, "description": "Validation loss for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 0.0039, "best_value": 0.0039}]}, {"metric_name": "head depth 1 train accuracy", "lower_is_better": false, "description": "Training accuracy for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 1 validation accuracy", "lower_is_better": false, "description": "Validation accuracy for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 1 train generation pass rate", "lower_is_better": false, "description": "Training generation pass rate for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 1 validation generation pass rate", "lower_is_better": false, "description": "Validation generation pass rate for head depth 1", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 2 train loss", "lower_is_better": true, "description": "Training loss for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "head depth 2 validation loss", "lower_is_better": true, "description": "Validation loss for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "head depth 2 train accuracy", "lower_is_better": false, "description": "Training accuracy for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 2 validation accuracy", "lower_is_better": false, "description": "Validation accuracy for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 2 train generation pass rate", "lower_is_better": false, "description": "Training generation pass rate for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "head depth 2 validation generation pass rate", "lower_is_better": false, "description": "Validation generation pass rate for head depth 2", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training accuracy", "lower_is_better": false, "description": "Final training accuracy", "data": [{"dataset_name": "synthetic (dropout=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (dropout=0.2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (dropout=0.5)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Final validation accuracy", "data": [{"dataset_name": "synthetic (dropout=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (dropout=0.2)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (dropout=0.5)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss", "data": [{"dataset_name": "synthetic (dropout=0.0)", "final_value": 0.0292, "best_value": 0.0292}, {"dataset_name": "synthetic (dropout=0.2)", "final_value": 0.0425, "best_value": 0.0425}, {"dataset_name": "synthetic (dropout=0.5)", "final_value": 0.0834, "best_value": 0.0834}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss", "data": [{"dataset_name": "synthetic (dropout=0.0)", "final_value": 0.0236, "best_value": 0.0236}, {"dataset_name": "synthetic (dropout=0.2)", "final_value": 0.0213, "best_value": 0.0213}, {"dataset_name": "synthetic (dropout=0.5)", "final_value": 0.0157, "best_value": 0.0157}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 0.0008, "best_value": 0.0008}, {"dataset_name": "synthetic (batch size 16)", "final_value": 0.0024, "best_value": 0.0024}, {"dataset_name": "synthetic (batch size 32)", "final_value": 0.0049, "best_value": 0.0049}, {"dataset_name": "synthetic (batch size 64)", "final_value": 0.0131, "best_value": 0.0131}, {"dataset_name": "synthetic (batch size 128)", "final_value": 0.0616, "best_value": 0.0616}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 0.0007, "best_value": 0.0007}, {"dataset_name": "synthetic (batch size 16)", "final_value": 0.002, "best_value": 0.002}, {"dataset_name": "synthetic (batch size 32)", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "synthetic (batch size 64)", "final_value": 0.0108, "best_value": 0.0108}, {"dataset_name": "synthetic (batch size 128)", "final_value": 0.0475, "best_value": 0.0475}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "Final training accuracy.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Final validation accuracy.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "mean training iterations", "lower_is_better": true, "description": "Final mean training iterations.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "mean validation iterations", "lower_is_better": true, "description": "Final mean validation iterations.", "data": [{"dataset_name": "synthetic (batch size 8)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 16)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 32)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 64)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (batch size 128)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Accuracy on the training dataset", "data": [{"dataset_name": "arithmetic", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "polynomial", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "bitwise", "final_value": 0.585, "best_value": 0.585}, {"dataset_name": "combined", "final_value": 0.8137, "best_value": 0.8137}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Accuracy on the validation dataset", "data": [{"dataset_name": "arithmetic", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "polynomial", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "bitwise", "final_value": 0.58, "best_value": 0.58}, {"dataset_name": "combined", "final_value": 0.865, "best_value": 0.865}]}, {"metric_name": "train loss", "lower_is_better": true, "description": "Loss on the training dataset", "data": [{"dataset_name": "arithmetic", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "polynomial", "final_value": 0.0023, "best_value": 0.0023}, {"dataset_name": "bitwise", "final_value": 0.0061, "best_value": 0.0061}, {"dataset_name": "combined", "final_value": 0.0148, "best_value": 0.0148}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset", "data": [{"dataset_name": "arithmetic", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "polynomial", "final_value": 0.002, "best_value": 0.002}, {"dataset_name": "bitwise", "final_value": 0.0052, "best_value": 0.0052}, {"dataset_name": "combined", "final_value": 0.0123, "best_value": 0.0123}]}]}, {"metric_names": [{"metric_name": "Adam training loss", "lower_is_better": true, "description": "Training loss on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0061, "best_value": 0.0061}]}, {"metric_name": "Adam validation loss", "lower_is_better": true, "description": "Validation loss on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0052, "best_value": 0.0052}]}, {"metric_name": "Adam training accuracy", "lower_is_better": false, "description": "Training accuracy on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adam validation accuracy", "lower_is_better": false, "description": "Validation accuracy on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adam mean iterations to convergence (training)", "lower_is_better": true, "description": "Mean iterations to convergence during training on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adam mean iterations to convergence (validation)", "lower_is_better": true, "description": "Mean iterations to convergence during validation on synthetic dataset using Adam optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "SGD training loss", "lower_is_better": true, "description": "Training loss on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0115, "best_value": 0.0115}]}, {"metric_name": "SGD validation loss", "lower_is_better": true, "description": "Validation loss on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0106, "best_value": 0.0106}]}, {"metric_name": "SGD training accuracy", "lower_is_better": false, "description": "Training accuracy on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "SGD validation accuracy", "lower_is_better": false, "description": "Validation accuracy on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "SGD mean iterations to convergence (training)", "lower_is_better": true, "description": "Mean iterations to convergence during training on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "SGD mean iterations to convergence (validation)", "lower_is_better": true, "description": "Mean iterations to convergence during validation on synthetic dataset using SGD optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "RMSprop training loss", "lower_is_better": true, "description": "Training loss on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0014, "best_value": 0.0014}]}, {"metric_name": "RMSprop validation loss", "lower_is_better": true, "description": "Validation loss on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.0012, "best_value": 0.0012}]}, {"metric_name": "RMSprop training accuracy", "lower_is_better": false, "description": "Training accuracy on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "RMSprop validation accuracy", "lower_is_better": false, "description": "Validation accuracy on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "RMSprop mean iterations to convergence (training)", "lower_is_better": true, "description": "Mean iterations to convergence during training on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "RMSprop mean iterations to convergence (validation)", "lower_is_better": true, "description": "Mean iterations to convergence during validation on synthetic dataset using RMSprop optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adagrad training loss", "lower_is_better": true, "description": "Training loss on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.2337, "best_value": 0.2337}]}, {"metric_name": "Adagrad validation loss", "lower_is_better": true, "description": "Validation loss on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 0.2163, "best_value": 0.2163}]}, {"metric_name": "Adagrad training accuracy", "lower_is_better": false, "description": "Training accuracy on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adagrad validation accuracy", "lower_is_better": false, "description": "Validation accuracy on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adagrad mean iterations to convergence (training)", "lower_is_better": true, "description": "Mean iterations to convergence during training on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Adagrad mean iterations to convergence (validation)", "lower_is_better": true, "description": "Mean iterations to convergence during validation on synthetic dataset using Adagrad optimizer.", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss", "data": [{"dataset_name": "synthetic (label smoothing = 0.0)", "final_value": 0.0061, "best_value": 0.0061}, {"dataset_name": "synthetic (label smoothing = 0.1)", "final_value": 0.3488, "best_value": 0.3488}, {"dataset_name": "synthetic (label smoothing = 0.2)", "final_value": 0.5875, "best_value": 0.5875}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss", "data": [{"dataset_name": "synthetic (label smoothing = 0.0)", "final_value": 0.0052, "best_value": 0.0052}, {"dataset_name": "synthetic (label smoothing = 0.1)", "final_value": 0.3488, "best_value": 0.3488}, {"dataset_name": "synthetic (label smoothing = 0.2)", "final_value": 0.5875, "best_value": 0.5875}]}, {"metric_name": "training generation pass rate", "lower_is_better": false, "description": "Final training generation pass rate", "data": [{"dataset_name": "synthetic (label smoothing = 0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing = 0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing = 0.2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate", "lower_is_better": false, "description": "Final validation generation pass rate", "data": [{"dataset_name": "synthetic (label smoothing = 0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing = 0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing = 0.2)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training pass rate", "lower_is_better": false, "description": "Proportion of examples correctly classified in training.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation pass rate", "lower_is_better": false, "description": "Proportion of examples correctly classified in validation.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training set.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 0.0061, "best_value": 0.0061}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 0.3488, "best_value": 0.3488}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 0.5875, "best_value": 0.5875}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation set.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 0.0052, "best_value": 0.0052}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 0.3488, "best_value": 0.3488}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 0.5875, "best_value": 0.5875}]}, {"metric_name": "mean training iterations", "lower_is_better": true, "description": "Average number of iterations per training example.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "mean validation iterations", "lower_is_better": true, "description": "Average number of iterations per validation example.", "data": [{"dataset_name": "synthetic (label smoothing=0.0)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (label smoothing=0.2)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Training loss", "data": [{"dataset_name": "ops_4", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "ops_8", "final_value": 0.0122, "best_value": 0.0122}, {"dataset_name": "ops_16", "final_value": 0.0218, "best_value": 0.0218}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss", "data": [{"dataset_name": "ops_4", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "ops_8", "final_value": 0.0099, "best_value": 0.0099}, {"dataset_name": "ops_16", "final_value": 0.0175, "best_value": 0.0175}]}, {"metric_name": "training generation pass rate", "lower_is_better": false, "description": "Training generation pass rate", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 0.7388, "best_value": 0.7388}, {"dataset_name": "ops_16", "final_value": 0.745, "best_value": 0.745}]}, {"metric_name": "validation generation pass rate", "lower_is_better": false, "description": "Validation generation pass rate", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 0.73, "best_value": 0.73}, {"dataset_name": "ops_16", "final_value": 0.78, "best_value": 0.78}]}]}, {"metric_names": [{"metric_name": "train accuracy", "lower_is_better": false, "description": "Training accuracy score", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Validation accuracy score", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "untied train AICR pass rate", "lower_is_better": false, "description": "AICR pass rate on training set for untied model", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "untied validation AICR pass rate", "lower_is_better": false, "description": "AICR pass rate on validation set for untied model", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "untied train loss", "lower_is_better": true, "description": "Loss on training set for untied model", "data": [{"dataset_name": "synthetic", "final_value": 0.0061, "best_value": 0.0061}]}, {"metric_name": "untied validation loss", "lower_is_better": true, "description": "Loss on validation set for untied model", "data": [{"dataset_name": "synthetic", "final_value": 0.0052, "best_value": 0.0052}]}, {"metric_name": "tied train AICR pass rate", "lower_is_better": false, "description": "AICR pass rate on training set for tied model", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "tied validation AICR pass rate", "lower_is_better": false, "description": "AICR pass rate on validation set for tied model", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "tied train loss", "lower_is_better": true, "description": "Loss on training set for tied model", "data": [{"dataset_name": "synthetic", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "tied validation loss", "lower_is_better": true, "description": "Loss on validation set for tied model", "data": [{"dataset_name": "synthetic", "final_value": 0.0, "best_value": 0.0}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Final training loss", "data": [{"dataset_name": "ops_4", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "ops_8", "final_value": 0.0122, "best_value": 0.0122}, {"dataset_name": "ops_16", "final_value": 0.0218, "best_value": 0.0218}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss", "data": [{"dataset_name": "ops_4", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "ops_8", "final_value": 0.0099, "best_value": 0.0099}, {"dataset_name": "ops_16", "final_value": 0.0175, "best_value": 0.0175}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "Final training accuracy", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 0.7388, "best_value": 0.7388}, {"dataset_name": "ops_16", "final_value": 0.745, "best_value": 0.745}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Final validation accuracy", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 0.73, "best_value": 0.73}, {"dataset_name": "ops_16", "final_value": 0.78, "best_value": 0.78}]}, {"metric_name": "train mean iterations", "lower_is_better": true, "description": "Average number of training iterations", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_16", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation mean iterations", "lower_is_better": true, "description": "Average number of validation iterations", "data": [{"dataset_name": "ops_4", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_8", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "ops_16", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "Train Accuracy", "lower_is_better": false, "description": "Accuracy on training set", "data": [{"dataset_name": "synthetic (Noise level: 10%)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (Noise level: 20%)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (Noise level: 30%)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Validation Accuracy", "lower_is_better": false, "description": "Accuracy on validation set", "data": [{"dataset_name": "synthetic (Noise level: 10%)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (Noise level: 20%)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (Noise level: 30%)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "Train Loss", "lower_is_better": true, "description": "Loss on training set", "data": [{"dataset_name": "synthetic (Noise level: 10%)", "final_value": 0.4362, "best_value": 0.4362}, {"dataset_name": "synthetic (Noise level: 20%)", "final_value": 0.7231, "best_value": 0.7231}, {"dataset_name": "synthetic (Noise level: 30%)", "final_value": 0.9517, "best_value": 0.9517}]}, {"metric_name": "Validation Loss", "lower_is_better": true, "description": "Loss on validation set", "data": [{"dataset_name": "synthetic (Noise level: 10%)", "final_value": 0.0994, "best_value": 0.0994}, {"dataset_name": "synthetic (Noise level: 20%)", "final_value": 0.2169, "best_value": 0.2169}, {"dataset_name": "synthetic (Noise level: 30%)", "final_value": 0.3653, "best_value": 0.3653}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Training loss for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "synthetic (head depth 2)", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "synthetic (head depth 2)", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "Training accuracy for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (head depth 2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Validation accuracy for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (head depth 2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train generation pass rate", "lower_is_better": false, "description": "Training generation pass rate for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (head depth 2)", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate", "lower_is_better": false, "description": "Validation generation pass rate for the synthetic dataset at each head depth", "data": [{"dataset_name": "synthetic (head depth 1)", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic (head depth 2)", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train loss (Head depth 1)", "lower_is_better": true, "description": "Final training loss for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0043, "best_value": 0.0043}]}, {"metric_name": "validation loss (Head depth 1)", "lower_is_better": true, "description": "Final validation loss for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0039, "best_value": 0.0039}]}, {"metric_name": "train accuracy (Head depth 1)", "lower_is_better": false, "description": "Final training accuracy for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy (Head depth 1)", "lower_is_better": false, "description": "Final validation accuracy for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train generation pass rate (Head depth 1)", "lower_is_better": false, "description": "Final training generation pass rate for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate (Head depth 1)", "lower_is_better": false, "description": "Final validation generation pass rate for model with head depth 1 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train loss (Head depth 2)", "lower_is_better": true, "description": "Final training loss for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "validation loss (Head depth 2)", "lower_is_better": true, "description": "Final validation loss for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "train accuracy (Head depth 2)", "lower_is_better": false, "description": "Final training accuracy for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy (Head depth 2)", "lower_is_better": false, "description": "Final validation accuracy for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train generation pass rate (Head depth 2)", "lower_is_better": false, "description": "Final training generation pass rate for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate (Head depth 2)", "lower_is_better": false, "description": "Final validation generation pass rate for model with head depth 2 on the synthetic dataset", "data": [{"dataset_name": "synthetic", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Training loss", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 0.0043, "best_value": 0.0043}, {"dataset_name": "synthetic head depth 2", "final_value": 0.0006, "best_value": 0.0006}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 0.0039, "best_value": 0.0039}, {"dataset_name": "synthetic head depth 2", "final_value": 0.0005, "best_value": 0.0005}]}, {"metric_name": "train accuracy", "lower_is_better": false, "description": "Training accuracy", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic head depth 2", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Validation accuracy", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic head depth 2", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "train generation pass rate", "lower_is_better": false, "description": "Training generation pass rate", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic head depth 2", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation generation pass rate", "lower_is_better": false, "description": "Validation generation pass rate", "data": [{"dataset_name": "synthetic head depth 1", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "synthetic head depth 2", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_AICR_curves.png", "../../logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_loss_curves.png"], [], ["../../logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_accuracy_rates.png"], [], [], [], ["../../logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_AICR_curves.png", "../../logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_final_val_AICR.png"], ["../../logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_aicr_metrics.png", "../../logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_classification_accuracy.png"], ["../../logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_generation_rates.png", "../../logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_loss_curves.png"], ["../../logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_pass_rates.png", "../../logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_mean_iterations.png"], ["../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_loss_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_loss_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_accuracy_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_loss_curve.png", "../../logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_loss_curve.png"], ["../../logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_AICR_curves.png", "../../logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_loss_curves.png"], [], ["../../logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_loss_ablation.png", "../../logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_mean_iterations_ablation.png", "../../logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_pass_rate_ablation.png"], [], ["../../logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_generation_success_rates.png"], [], ["../../logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_loss.png", "../../logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_MeanIters.png", "../../logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_AICR.png"], [], [], [], ["../../logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_aicr_metrics.png", "../../logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_classification_accuracy.png"], []], "plot_paths": [["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_AICR_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_loss_curves.png"], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_accuracy_rates.png"], [], [], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_AICR_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_final_val_AICR.png"], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_aicr_metrics.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_classification_accuracy.png"], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_generation_rates.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_loss_curves.png"], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_pass_rates.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_mean_iterations.png"], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_loss_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_accuracy_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_accuracy_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_accuracy_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_loss_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_accuracy_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_loss_curve.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_loss_curve.png"], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_AICR_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_loss_curves.png"], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_loss_ablation.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_mean_iterations_ablation.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_pass_rate_ablation.png"], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_generation_success_rates.png"], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_loss.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_MeanIters.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_AICR.png"], [], [], [], ["experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_aicr_metrics.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_loss_curves.png", "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_classification_accuracy.png"], []], "plot_analyses": [[{"analysis": "AICR curves remain flat at exactly 1.0 for all learning rates and epochs on both training and validation, suggesting that under the current metric implementation the model achieves perfect abstract-interpretation\u2010based correction ratio immediately and shows no sensitivity to learning rate changes or further training. This saturation could indicate (a) an issue in the AICR computation or logging (e.g., output always clamped to 1), (b) the synthetic dataset and task are too trivial for the model under these settings, or (c) the abstract interpreter is automatically eliminating all detectable errors from the very first generation. In any case, the lack of variation means AICR is not currently a discriminative signal for hyperparameter selection in this stage.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_AICR_curves.png"}, {"analysis": "Training loss curves show: LR=0.001 starts high (~1.7) and decreases steadily but remains around 0.7 by epoch\u20095, indicating slow convergence. LR=0.005 drops from ~1.15 to ~0.03 by epoch\u20095, giving a good balance of speed and stability. LR=0.01 and 0.02 collapse very quickly\u2014both reach near-zero training loss by epoch\u20092\u2014potentially overfitting or reflecting an overly aggressive optimization that may harm generalization on more complex data. Validation loss curves mirror these trends: LR=0.001 improves slowly (from ~1.5 to 0.6), LR=0.005 converges to ~0.02, while LR=0.01/0.02 reach near-zero by epoch\u20092. The very low validation loss at high LRs on this synthetic task suggests the model overfits or that the validation split is too similar to training. For robustness and generalization, LR=0.005 is the sweet spot in this stage.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_f9213b4ae464430eac366ef28c91a9e1_proc_75765/synthetic_loss_curves.png"}], [], [{"analysis": "Loss values steadily decrease across epochs for both training and validation splits at all model dimensions. Higher-dimensional models (dim=16, 32) start with much lower initial losses and converge to near-zero by epoch 2, indicating faster learning capacity. Medium dimensions (dim=8) achieve moderate loss reduction by epoch 3, while lower dimensions (dim=2, 4) require all five epochs to reach comparable loss levels. Validation curves closely track training curves with no obvious overfitting, showing the lightweight abstract interpretation\u2013guided generation loop scales well with capacity and generalizes effectively even at higher dimensions.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_loss_curves.png"}, {"analysis": "All reported generation accuracy rates on both training and validation remain flat at 100% for every dimension and epoch. This saturation suggests the synthetic dataset is too easy under the current evaluation metric, offering no discriminative power to reveal differences in generation correctness across the ablated components or model sizes. The constant perfect accuracy despite varying loss trajectories indicates that loss improvements do not translate into measurable gains in correct-by-construction code generation under this synthetic benchmark.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_36c43541e45e4d679c083af3288ccb05_proc_87823/synthetic_accuracy_rates.png"}], [], [], [], [{"analysis": "AICR curves on synthetic dataset for both train and validation remain constant at 1.0 across all epochs and weight decay settings, indicating that weight decay has no measurable impact on this metric and that the abstract interpretation guided code generation consistency is perfect or saturated for this synthetic dataset.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_AICR_curves.png"}, {"analysis": "Loss curves show rapid convergence: initial loss at epoch 1 increases with weight decay magnitude, but by epoch 2 all training losses drop to near 0.05 and by epoch 3\u20135 converge to near-zero, with validation losses always lower than training. Weight decay slows down early training but does not affect final convergence or introduce overfitting on the synthetic dataset.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_loss_curves.png"}, {"analysis": "Final validation AICR is exactly 1.0 for all weight decay values, confirming that weight decay has no influence on the AICR metric and suggesting that in this synthetic setting the proposed AIGG method achieves perfect consistency regardless of regularization strength.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_aa96c69c87bd4476825267de89318133_proc_87823/synthetic_final_val_AICR.png"}], [{"analysis": "AICR metrics on the synthetic dataset remain effectively at perfect or near-perfect levels for both abstract-interpretation depths throughout all epochs. Validation AICR is flat at 1.0, indicating that no constraint violations are detected on held-out data. Training AICR for depth 2 starts slightly below depth 1 but converges quickly, narrowing the gap by epoch 2 and reaching the same plateau. This uniform saturation suggests that the synthetic task is too simple to distinguish the impact of depth in the abstract\u2010interpretation loop.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_aicr_metrics.png"}, {"analysis": "Loss curves for both depths plummet rapidly within the first two epochs and then flatten near zero, with negligible training-validation gaps. Depth 1 shows a slightly lower initial training loss at epoch 1 and converges marginally faster, but depth 2 catches up by epoch 2. Validation loss follows the same trajectory, confirming minimal overfitting. Overall, both configurations achieve essentially zero loss almost immediately, signaling a trivial learning task.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_loss_curves.png"}, {"analysis": "Classification accuracy starts high for both depths and reaches 100% by epoch 2. Depth 1 attains 95% train accuracy at epoch 1, while depth 2 begins at ~87%, but both reach perfect training and validation accuracy by epoch 2 and maintain it afterwards. The validation curve is flat at 100%, again pointing to an overly easy dataset that does not stress the differences between abstraction depths.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_25b3437207fd4f4c8b325bcaad9504f8_proc_87824/synthetic_classification_accuracy.png"}], [{"analysis": "Generation pass rates for all dropout configurations (0.0, 0.2, 0.5) remain at 100% across epochs on both train and validation splits. No divergence appears between dropout settings or splits. This complete saturation suggests the synthetic task is too trivial to reveal differences in correctness yield when using abstract-interpretation\u2013guided generation (AIGG) under varying regularization strengths.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_generation_rates.png"}, {"analysis": "Loss curves show rapid convergence in all cases. With no dropout, training loss falls from ~1.20 to near zero by epoch 5; validation follows from ~0.58 to ~0.02. Dropout 0.2 and 0.5 slow this drop modestly: final training losses are ~0.04 and ~0.08, and validation losses ~0.03 and ~0.09, respectively. Higher dropout slightly hampers convergence and increases final loss, but yields no generalization gains on this synthetic dataset.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_d8f2b2b327c444e3bc97f049067141ee_proc_87822/synthetic_loss_curves.png"}], [{"analysis": "Synthetic dataset pass rates remain flat at 100% across all epochs (1\u20135) for every batch size (8 to 128) in both training and validation. This lack of variance suggests that either the dataset is too trivial or the abstract interpretation check is always passing (or never being applied), preventing us from observing any refinement impact from the AIGG loop.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_pass_rates.png"}, {"analysis": "Training loss curves show that smaller batch sizes (8, 16, 32) start with lower initial loss and converge to near zero by epoch 2. Medium batch size (64) takes until epoch 3 to approach minimal loss, while the largest batch (128) converges most slowly, still above 0.05 at epoch 5. Validation loss tracks the same pattern without a noticeable generalization gap. These trends align with typical large-batch training dynamics rather than any AIGG-specific behavior.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_loss_curves.png"}, {"analysis": "Mean iteration counts per sample are constant at exactly 1.0 across all epochs and batch sizes for both training and validation. This indicates the abstract interpretation\u2013guided regeneration loop never triggers additional iterations, implying that invariant violations are not being detected or that constraint injection is not invoked on this synthetic task.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_e2bb3c93776b451592dba41cdadca69f_proc_87823/synthetic_mean_iterations.png"}], [{"analysis": "Loss Curve for bitwise shows a steep drop in train loss from ~0.57 at epoch 1 to ~0.05 by epoch 3, then plateauing near zero by epoch 5. Validation loss follows the same trajectory, starting at ~0.11 and reaching near-zero by epoch 5. The tight tracking of train and val curves suggests minimal overfitting and stable convergence, though the initial loss is moderate compared to arithmetic and polynomial benchmarks.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_loss_curve.png"}, {"analysis": "Accuracy Curve for polynomial is flat at 1.00 for both train and validation across all epochs. This indicates immediate perfect performance on polynomial tasks, with no further improvements possible, and demonstrates that the model quickly masters this subdomain under the current AIGG setup.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_accuracy_curve.png"}, {"analysis": "Accuracy Curve for arithmetic similarly sits at 1.00 for train and validation at every epoch. The model achieves perfect pass rates on arithmetic tasks from the first epoch, matching the behavior on polynomial tasks and suggesting that arithmetic invariants are fully captured by the abstract interpreter hints and prompt refinement.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_accuracy_curve.png"}, {"analysis": "Accuracy Curve for combined tasks shows train pass rate steady at ~0.813 and validation at ~0.865 with no change across epochs. The higher validation rate relative to training hints at sampling variability or dataset imbalance, but overall combined performance remains substantially below the perfect rates seen in polynomial and arithmetic, pointing to added difficulty when blending multiple task types.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_accuracy_curve.png"}, {"analysis": "Loss Curve for arithmetic drops sharply from ~0.41 at epoch 1 to ~0.03 by epoch 2, then nearing zero by epoch 3. Validation loss mirrors this, falling from ~0.08 to ~0.02 by epoch 2 and to ~0.005 by epoch 5. The rapid convergence underscores that arithmetic code generation benefits strongly from the inserted invariant constraints.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/arithmetic_loss_curve.png"}, {"analysis": "Accuracy Curve for bitwise is flat at ~0.585 train and ~0.580 validation across epochs. The modest pass rates reveal that the model struggles with bitwise tasks despite the same AIGG pipeline. Unlike arithmetic and polynomial, bitwise operations likely require more precise invariants or domain-specific reasoning that the current abstract interpreter does not provide.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/bitwise_accuracy_curve.png"}, {"analysis": "Loss Curve for combined tasks begins at a higher train loss (~1.30) and validation (~0.48) compared to individual subdomains. It then falls to ~0.22/0.08 by epoch 2 and continues decreasing to ~0.01/0.01 by epoch 5. The larger initial loss and still strong convergence suggest added complexity in mixed tasks, but the model nevertheless fits the training set well without severe overfitting.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/combined_loss_curve.png"}, {"analysis": "Loss Curve for polynomial shows train loss decreasing from ~0.29 at epoch 1 to ~0.02 by epoch 2 and to near-zero by epoch 3, with validation loss following from ~0.05 to ~0.01 and also converging to zero. This pattern matches arithmetic\u2019s dynamics, reaffirming that AIGG effectively resolves logical issues in these simpler numeric benchmarks.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_6c1a411d49aa47298b3a710c13b0abef_proc_87823/polynomial_loss_curve.png"}], [{"analysis": "All four optimizers produce identical AICR values of 1.00 across all epochs for both training and validation. There is no distinction between Adam, SGD, RMSprop, or Adagrad in this metric on the synthetic dataset, and no epoch-to-epoch variation. This suggests either the AICR metric has saturated in this setting or the synthetic task is too trivial for the abstract interpretation loop to exhibit any measurable impact.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_AICR_curves.png"}, {"analysis": "Training and validation loss curves reveal clear differences in convergence speed and final loss. RMSprop starts with the lowest initial loss (~0.12 training, ~0.01 validation) and continues to achieve the fastest convergence and lowest final losses by epoch 5. Adam and SGD show very similar behavior: moderate initial losses (~0.78/0.68 training, ~0.14/0.09 validation) that rapidly drop by epoch 2 and plateau near zero. Adagrad consistently lags: highest initial loss (~1.0 training, ~0.75 validation), slower decrease across epochs, and remains well above the others by the end. These patterns indicate that RMSprop offers the best stability and generalization on this synthetic task, Adam and SGD are comparable, and Adagrad underperforms.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_5e9407b14c5b417a94909f871ce5f8b0_proc_87824/synthetic_loss_curves.png"}], [], [{"analysis": "Synthetic Dataset Loss vs Epoch \u2013 Label Smoothing Ablation: Training and validation losses both worsen as the smoothing parameter increases. Without smoothing (smooth=0.0), the model converges rapidly to near-zero training loss by epoch 5 and similarly low validation loss. Moderate smoothing (smooth=0.1) yields higher residual losses (~0.35 training, ~0.347 validation at epoch 5), while heavy smoothing (smooth=0.2) plateaus around 0.59 on both splits. This indicates that label smoothing here impedes the model\u2019s ability to fit even the synthetic data, slowing convergence and raising final loss.", "": "", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_loss_ablation.png"}, {"analysis": "Synthetic Dataset Mean Iterations vs Epoch \u2013 Label Smoothing Ablation: Mean iterations per example remain constant at 1.0 for all smoothing levels and across all epochs on both training and validation\u2013no visible effect from label smoothing. The invariant iteration count suggests that this metric is saturated or uninformative on this synthetic dataset under the current experimental setup.", "": "", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_mean_iterations_ablation.png"}, {"analysis": "Synthetic Dataset Pass Rate vs Epoch \u2013 Label Smoothing Ablation: Pass rate holds at 100% across every epoch and smoothing setting on both training and validation. This flat result indicates the task is too trivial for pass rate to discriminate between different smoothing values, or the metric is already maxed out from the start.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c0ae1426f82e45508991abe39856c938_proc_87822/synthetic_pass_rate_ablation.png"}], [], [{"analysis": "All learning rates exhibit strictly decreasing training and validation losses across epochs. The smallest rate (0.001) shows a gentle, steady descent: training loss falls from ~1.75 to ~0.80, validation from ~1.55 to ~0.72 by epoch 5, indicating stable but slow convergence. The intermediate rate (0.005) reduces losses more rapidly, reaching training ~0.08 and validation ~0.07 by epoch 5; however, initial drops are steeper, suggesting faster learning with some risk of premature plateau. The rate of 0.01 yields nearly zero losses by epoch 2 on both splits and remains flat thereafter, implying very fast convergence but potential overfitting or loss underflow (values approach machine precision). The highest rate (0.02) achieves sub-0.05 losses by epoch 2 but produces slightly noisier validation curves (loss hovers around zero), hinting at potential instability or divergence if run longer. In summary, 0.01 and 0.02 converge fastest but risk numerical artifacts, while 0.005 offers a balanced trade-off between speed and stability.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_loss_curves.png"}, {"analysis": "Success rates are at or extremely close to 100% for both training and validation across all epochs and learning rates. There is no differentiation between rates at any stage\u2014every experiment yields perfect or nearly perfect generation success from the outset. This ceiling effect suggests that the synthetic dataset and evaluation metric may be too easy or saturated, preventing meaningful distinctions in generation performance under different hyperparameter settings.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_8c4e8faf60cf4c30af8e2e9f9013c1a1_proc_87824/synthetic_generation_success_rates.png"}], [], [{"analysis": "Loss curves for output_vocab_scaling show that models with higher ops values start with significantly larger training and validation losses. However, all configurations rapidly decrease loss within the first two epochs and converge to near-zero by epoch 3. This indicates that scaling the output vocabulary size affects initial convergence speed but not final performance. The narrow gap between training and validation losses across ops values implies no severe overfitting due to vocabulary scaling.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_loss.png"}, {"analysis": "MeanIters curves remain constant at exactly 1.0 across all epochs, datasets, and ops values. This suggests that the number of iteration steps or mean interactions the model performs is unaffected by the chosen output vocabulary scaling parameter.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_MeanIters.png"}, {"analysis": "AICR curves are flat over epochs for both training and validation splits across all ops values. Training AICR is 1.0 for all configurations, indicating perfect agreement in reconstruction, while validation AICR varies slightly with ops_8 and ops_16 around 0.73\u20130.78. The lack of change over time suggests the metric is insensitive to training dynamics under output_vocab_scaling.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_c9cf6b09603d4f3396f251a384aa70f6_proc_87822/output_vocab_scaling_AICR.png"}], [], [], [], [{"analysis": "AICR Metrics on the synthetic dataset converge to perfect constraint rates by the second epoch for both abstract\u2010interpretation depths. Depth-1 begins slightly below unity and depth-2 slightly above on the training curve but both reach and maintain a rate of 1.0 thereafter. Validation AICR is flat at 1.0 across all epochs and both depths, indicating no divergence between training and validation in terms of abstract\u2010interpretation consistency.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_aicr_metrics.png"}, {"analysis": "Training and validation losses for both depths drop sharply in the first two epochs and then plateau near zero. Depth-1 starts with a lower initial training loss (~0.41) than depth-2 (~0.58), while depth-2 has a marginally lower initial validation loss (~0.05 vs. ~0.08). Both configurations achieve near\u2010zero loss by epoch\u20092 on training and validation sets and show no signs of overfitting.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_loss_curves.png"}, {"analysis": "Classification accuracies for both depths reach perfect scores on training and validation by epoch\u20092. Depth-1 begins at ~95% train accuracy and depth-2 at ~87%, but both achieve 100% on both splits by the second epoch. Validation accuracy is 100% from epoch\u20091 onward for both depths.", "plot_path": "experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/synthetic_classification_accuracy.png"}], []], "vlm_feedback_summary": ["Training and validation AICR saturates at 1.0 for all hyperparameters, so it is\nnot helpful for selecting the best learning rate. Loss-based metrics show\nLR=0.005 as the best compromise between convergence speed and stability, while\nhigher learning rates converge too quickly and risk overfitting and lower rates\nconverge too slowly.", "[]", "Loss ablation shows capacity-driven improvements in optimization speed and final\nloss, but AICR remains saturated at 100%. The synthetic task fails to\ndifferentiate component effects on functional correctness, so future studies\nshould incorporate more challenging code examples or finer-grained logical-error\nmetrics to expose the impact of abstract-interpretation constraints.", "[]", "[]", "[]", "Weight decay does not affect the AICR metric and only minimally impacts early\ntraining dynamics in terms of convergence speed on the synthetic dataset. The\nAICR measure is saturated, offering no discrimination between configurations,\nand the final losses are uniformly near-zero across all setups.", "All metrics (AICR, loss, accuracy) saturate almost immediately to perfect\nperformance for both abstraction depths, making the synthetic dataset too simple\nto reveal the contributions of each component. Depth 2 shows only marginally\nslower initial convergence, but by epoch 2 both depths produce identical\nresults. Suggest moving to a more challenging synthetic task or introducing more\nnuanced constraints to tease apart the effects of abstract\u2010interpretation depth.", "Dropout has negligible effect on code generation pass rates (all at ceiling) and\nonly slows convergence, increasing final losses. The synthetic benchmark is too\neasy to differentiate AIGG components; a more challenging dataset or error types\nis needed for meaningful ablation.", "On the synthetic dataset, pass rates and iteration counts show no variability,\nsignaling a misconfiguration or trivial data such that the AIGG loop never\nrefines code. Loss curves follow expected batch-size convergence patterns\nwithout evidence of AIGG\u2019s corrective influence. Next steps include verifying\nabstract interpreter integration, ensuring invariant violations generate prompt\nconstraints, and evaluating on nontrivial cases to exercise the refinement loop.", "All subdomains converge quickly with low loss and stable generalization.\nArithmetic and polynomial tasks reach perfect accuracy immediately, whereas\nbitwise tasks lag at ~58% pass rate. Combined tasks show intermediate\nperformance (~81% train, ~86% val) and higher initial loss due to task\nheterogeneity. Results indicate that while abstract interpretation hints\neffectively eliminate range-based and arithmetic errors, they fall short on\nbitwise semantics, suggesting the need for richer domains or specialized\nguidance for bitwise operations.", "AICR curves remain flat at the maximum for all optimizers, implying no\nsensitivity in this metric on the synthetic dataset. In contrast, loss curves\nclearly differentiate optimizers: RMSprop is most effective, Adam and SGD tie\nfor second, and Adagrad trails. To better evaluate the abstract interpretation\nguidance, a more challenging dataset or a more sensitive correctness metric may\nbe required.", "[]", "Label smoothing consistently degrades performance on this synthetic task,\nelevating both training and validation loss without affecting convergence\niterations or pass rate. In this controlled setting, smoothing is unnecessary\nand even harmful; further experiments should either remove or tune it and shift\nfocus to more complex benchmarks where regularization might yield benefits.", "[]", "Loss analysis shows a classical trade-off: low rates converge stably but slowly;\nintermediate (0.005) is fast yet stable; high rates (0.01, 0.02) converge almost\ninstantly but risk numerical issues. Success rates saturate at 100%, indicating\nan overly easy benchmark. Suggest using a harder dataset or more discriminative\nmetrics for generation success.", "[]", "Output vocabulary scaling impacts initial convergence rates but has no effect on\nfinal loss, iteration counts, or AICR metrics. All ablation settings rapidly\nconverge and yield consistent behaviour after two epochs, implying that this\ncomponent contributes little beyond affecting early training dynamics.", "[]", "[]", "[]", "On this toy synthetic dataset, both AIGG configurations converge rapidly to\nperfect abstract\u2010interpretation correctness, zero loss, and full accuracy with\nminimal differences. Depth-1 shows slightly faster initial convergence in loss\nand accuracy, while depth-2 has a marginal early advantage in AICR. Overall, the\nsynthetic data is too simplistic to differentiate the impact of\nabstract\u2010interpretation depth; both reach saturation by epoch 2.", "[]"], "exec_time": [3.0392379760742188, 3.0806093215942383, 3.4136886596679688, 3.704037666320801, 3.053346872329712, 2.7275264263153076, 3.0720374584198, 2.6555683612823486, 5.348296165466309, 7.8122735023498535, 3.562405586242676, 6.4856719970703125, 2.944096565246582, 5.264931678771973, 2.743847131729126, 2.9846112728118896, 2.432011365890503, 2.749113082885742, 2.9514124393463135, 2.812887668609619, 2.780914545059204, 2.7774059772491455, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["['synthetic']"], [], [""], [], [], [], ["['synthetic']"], ["[]"], ["[]"], ["[]"], ["[polynomial", "arithmetic]"], [""], [], ["['synthetic']"], [], [""], [], ["['output_vocab_scaling']"], [], [], [], ["['synthetic']"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\nd = experiment_data.get(\"learning_rate\", {}).get(\"synthetic\", {})\nparams = d.get(\"params\", [])\nloss_train = np.array(d.get(\"losses\", {}).get(\"train\", []))\nloss_val = np.array(d.get(\"losses\", {}).get(\"val\", []))\nmetrics_train = np.array(d.get(\"metrics\", {}).get(\"train\", []))\nmetrics_val = np.array(d.get(\"metrics\", {}).get(\"val\", []))\nepochs = np.arange(1, loss_train.shape[1] + 1) if loss_train.ndim == 2 else np.array([])\n\n# Plot Loss Curves\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    for i, lr in enumerate(params):\n        axes[0].plot(epochs, loss_train[i], label=f\"{lr}\")\n        axes[1].plot(epochs, loss_val[i], label=f\"{lr}\")\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[0].legend(title=\"LR\")\n    axes[1].legend(title=\"LR\")\n    fig.suptitle(\n        \"Synthetic dataset Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    fig.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close(fig)\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# Plot AICR Curves\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    for i, lr in enumerate(params):\n        axes[0].plot(epochs, metrics_train[i], label=f\"{lr}\")\n        axes[1].plot(epochs, metrics_val[i], label=f\"{lr}\")\n    axes[0].set_title(\"Training AICR\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"AICR\")\n    axes[1].set_title(\"Validation AICR\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"AICR\")\n    axes[0].legend(title=\"LR\")\n    axes[1].legend(title=\"LR\")\n    fig.suptitle(\n        \"Synthetic dataset AICR Curves\\nLeft: Training AICR, Right: Validation AICR\"\n    )\n    fig.savefig(os.path.join(working_dir, \"synthetic_AICR_curves.png\"))\n    plt.close(fig)\nexcept Exception as e:\n    print(f\"Error creating AICR curves plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndata = experiment_data.get(\"embedding_dim\", {}).get(\"synthetic\", {})\nparams = data.get(\"params\", [])\nloss_train = data.get(\"losses\", {}).get(\"train\", [])\nloss_val = data.get(\"losses\", {}).get(\"val\", [])\nmetric_train = data.get(\"metrics\", {}).get(\"train\", [])\nmetric_val = data.get(\"metrics\", {}).get(\"val\", [])\nepochs = range(1, len(loss_train[0]) + 1) if loss_train else []\n\ntry:\n    plt.figure()\n    for i, emb in enumerate(params):\n        plt.plot(epochs, loss_train[i], label=f\"train dim={emb}\")\n        plt.plot(epochs, loss_val[i], \"--\", label=f\"val dim={emb}\")\n    plt.title(\"Loss curves on synthetic dataset\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"synthetic_loss_curves.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for i, emb in enumerate(params):\n        plt.plot(epochs, metric_train[i], label=f\"train dim={emb}\")\n        plt.plot(epochs, metric_val[i], \"--\", label=f\"val dim={emb}\")\n    plt.title(\"Generation accuracy rates on synthetic dataset\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    fname = os.path.join(working_dir, \"synthetic_accuracy_rates.png\")\n    plt.savefig(fname)\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy rates plot: {e}\")\n    plt.close()\n", null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    syn = exp[\"weight_decay\"][\"synthetic\"]\n    params = syn[\"params\"]\n    train_losses, val_losses = syn[\"losses\"][\"train\"], syn[\"losses\"][\"val\"]\n    train_metrics, val_metrics = syn[\"metrics\"][\"train\"], syn[\"metrics\"][\"val\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# Plot 1: Loss curves\ntry:\n    plt.figure()\n    for w, tr, va in zip(params, train_losses, val_losses):\n        epochs = range(1, len(tr) + 1)\n        plt.plot(epochs, tr, label=f\"Train wd={w}\")\n        plt.plot(epochs, va, \"--\", label=f\"Val wd={w}\")\n    plt.title(\"Loss Curves - Synthetic Dataset (Train vs Val)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# Plot 2: AICR curves\ntry:\n    plt.figure()\n    for w, tr, va in zip(params, train_metrics, val_metrics):\n        epochs = range(1, len(tr) + 1)\n        plt.plot(epochs, tr, label=f\"Train AICR wd={w}\")\n        plt.plot(epochs, va, \"--\", label=f\"Val AICR wd={w}\")\n    plt.title(\"AICR Curves - Synthetic Dataset (Train vs Val)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_AICR_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating AICR curves plot: {e}\")\n    plt.close()\n\n# Plot 3: Final validation AICR bar chart\ntry:\n    final_val = [vm[-1] for vm in val_metrics]\n    plt.figure()\n    plt.bar([str(w) for w in params], final_val)\n    plt.title(\"Final Validation AICR - Synthetic Dataset\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Final Val AICR\")\n    plt.savefig(os.path.join(working_dir, \"synthetic_final_val_AICR.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final AICR bar chart: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nd = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = d[\"head_depths\"]\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"losses\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"losses\"][\"train\"][idx], label=f\"Train Loss Depth {hd}\")\n        plt.plot(epochs, d[\"losses\"][\"val\"][idx], label=f\"Val Loss Depth {hd}\")\n    plt.suptitle(\"Loss Curves: Synthetic Dataset\")\n    plt.title(\"Left: Train Loss, Right: Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"metrics\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"metrics\"][\"train\"][idx], label=f\"Train AICR Depth {hd}\")\n        plt.plot(epochs, d[\"metrics\"][\"val\"][idx], label=f\"Val AICR Depth {hd}\")\n    plt.suptitle(\"AICR Metrics: Synthetic Dataset\")\n    plt.title(\"Left: Train Rate, Right: Validation Rate\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_aicr_metrics.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"classification_accuracy\"][\"train\"][idx]) + 1)\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"train\"][idx],\n            label=f\"Train Acc Depth {hd}\",\n        )\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"val\"][idx],\n            label=f\"Val Acc Depth {hd}\",\n        )\n    plt.suptitle(\"Classification Accuracy: Synthetic Dataset\")\n    plt.title(\"Left: Train Accuracy, Right: Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_classification_accuracy.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot3: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    exp_path = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# Extract synthetic ablation results\ndata = experiment_data.get(\"dropout_ablation\", {}).get(\"synthetic\", {})\ndropouts = data.get(\"params\", [])\ntrain_losses = data.get(\"losses\", {}).get(\"train\", [])\nval_losses = data.get(\"losses\", {}).get(\"val\", [])\ntrain_rates = data.get(\"metrics\", {}).get(\"train\", [])\nval_rates = data.get(\"metrics\", {}).get(\"val\", [])\n\n# Plot loss curves\ntry:\n    plt.figure()\n    for dr, tloss, vloss in zip(dropouts, train_losses, val_losses):\n        epochs = range(1, len(tloss) + 1)\n        plt.plot(epochs, tloss, \"-o\", label=f\"Train dr={dr}\")\n        plt.plot(epochs, vloss, \"-x\", label=f\"Val dr={dr}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss Curves (Train vs Val) - Synthetic dataset\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# Plot generation pass rate curves\ntry:\n    plt.figure()\n    for dr, trate, vrate in zip(dropouts, train_rates, val_rates):\n        epochs = range(1, len(trate) + 1)\n        plt.plot(epochs, trate, \"-o\", label=f\"Train dr={dr}\")\n        plt.plot(epochs, vrate, \"-x\", label=f\"Val dr={dr}\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Pass Rate\")\n    plt.title(\"Generation Pass Rates (Train vs Val) - Synthetic dataset\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_generation_rates.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating generation rates plot: {e}\")\n    plt.close()\n\n# Print final validation metrics\ntry:\n    for dr, rates in zip(dropouts, val_rates):\n        print(\n            f\"Synthetic dataset - dropout {dr}: final val pass rate = {rates[-1]:.4f}\"\n        )\nexcept Exception as e:\n    print(f\"Error printing evaluation metrics: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\n# Extract synthetic results for batch_size experiment\nd = data.get(\"batch_size\", {}).get(\"synthetic\", {})\nbs = d.get(\"params\", [])\n# Determine number of epochs\nepochs = len(d.get(\"losses\", {}).get(\"train\", [[]])[0])\n\n# Plot Loss Curves\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for i, b in enumerate(bs):\n        axes[0].plot(range(1, epochs + 1), d[\"losses\"][\"train\"][i], label=f\"BS={b}\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].set_title(\"Synthetic Dataset - Training Loss\")\n    axes[0].legend()\n    for i, b in enumerate(bs):\n        axes[1].plot(range(1, epochs + 1), d[\"losses\"][\"val\"][i], label=f\"BS={b}\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].set_title(\"Synthetic Dataset - Validation Loss\")\n    axes[1].legend()\n    fig.suptitle(\"Synthetic Dataset Loss Curves\\nLeft: Training, Right: Validation\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# Plot Pass Rates\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for i, b in enumerate(bs):\n        axes[0].plot(range(1, epochs + 1), d[\"metrics\"][\"train\"][i], label=f\"BS={b}\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Pass Rate\")\n    axes[0].set_title(\"Synthetic Dataset - Training Pass Rate\")\n    axes[0].legend()\n    for i, b in enumerate(bs):\n        axes[1].plot(range(1, epochs + 1), d[\"metrics\"][\"val\"][i], label=f\"BS={b}\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Pass Rate\")\n    axes[1].set_title(\"Synthetic Dataset - Validation Pass Rate\")\n    axes[1].legend()\n    fig.suptitle(\"Synthetic Dataset Pass Rates\\nLeft: Training, Right: Validation\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"synthetic_pass_rates.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating pass-rate plot: {e}\")\n    plt.close()\n\n# Plot Mean Iterations\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for i, b in enumerate(bs):\n        axes[0].plot(range(1, epochs + 1), d[\"iterations\"][\"train\"][i], label=f\"BS={b}\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Iterations\")\n    axes[0].set_title(\"Synthetic Dataset - Training Iterations\")\n    axes[0].legend()\n    for i, b in enumerate(bs):\n        axes[1].plot(range(1, epochs + 1), d[\"iterations\"][\"val\"][i], label=f\"BS={b}\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Iterations\")\n    axes[1].set_title(\"Synthetic Dataset - Validation Iterations\")\n    axes[1].legend()\n    fig.suptitle(\"Synthetic Dataset Mean Iterations\\nLeft: Training, Right: Validation\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(working_dir, \"synthetic_mean_iterations.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating iterations plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# Iterate datasets\nfor ds, entry in experiment_data.get(\n    \"multi_domain_synthetic_specification\", {}\n).items():\n    losses = entry.get(\"losses\", {})\n    rates = entry.get(\"metrics\", {})\n    # Print final metrics\n    try:\n        print(\n            f'Dataset={ds}: Final train rate={rates[\"train\"][-1]:.4f}, final val rate={rates[\"val\"][-1]:.4f}'\n        )\n    except Exception:\n        pass\n\n    # Loss curve\n    try:\n        plt.figure()\n        plt.plot(\n            range(1, len(losses.get(\"train\", [])) + 1),\n            losses.get(\"train\", []),\n            label=\"Train Loss\",\n        )\n        plt.plot(\n            range(1, len(losses.get(\"val\", [])) + 1),\n            losses.get(\"val\", []),\n            label=\"Val Loss\",\n        )\n        plt.suptitle(f\"Loss Curve for {ds}\")\n        plt.title(\"Left: Train Loss, Right: Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{ds}_loss_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curve for {ds}: {e}\")\n        plt.close()\n\n    # Accuracy curve\n    try:\n        plt.figure()\n        plt.plot(\n            range(1, len(rates.get(\"train\", [])) + 1),\n            rates.get(\"train\", []),\n            label=\"Train Rate\",\n        )\n        plt.plot(\n            range(1, len(rates.get(\"val\", [])) + 1),\n            rates.get(\"val\", []),\n            label=\"Val Rate\",\n        )\n        plt.suptitle(f\"Accuracy Curve for {ds}\")\n        plt.title(\"Left: Train Rate, Right: Val Rate\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Pass Rate\")\n        plt.legend()\n        fname = os.path.join(working_dir, f\"{ds}_accuracy_curve.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy curve for {ds}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    exp_file = os.path.join(working_dir, \"experiment_data.npy\")\n    experiment_data = np.load(exp_file, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# Extract synthetic optimizer results\ndata = experiment_data[\"optimizer\"][\"synthetic\"]\nnames = data[\"optim_names\"]\nmetrics = data[\"metrics\"]\ntrain_loss = metrics[\"train_loss\"]\nval_loss = metrics[\"val_loss\"]\ntrain_AICR = metrics[\"train_AICR\"]\nval_AICR = metrics[\"val_AICR\"]\n\n# Plot loss curves\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    epochs = np.arange(1, len(train_loss[0]) + 1)\n    for i, name in enumerate(names):\n        axes[0].plot(epochs, train_loss[i], label=name)\n        axes[1].plot(epochs, val_loss[i], label=name)\n    axes[0].set_title(\"Training Loss\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[0].legend()\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# Plot AICR curves\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    epochs = np.arange(1, len(train_AICR[0]) + 1)\n    for i, name in enumerate(names):\n        axes[0].plot(epochs, train_AICR[i], label=name)\n        axes[1].plot(epochs, val_AICR[i], label=name)\n    axes[0].set_title(\"Training AICR\")\n    axes[1].set_title(\"Validation AICR\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"AICR\")\n    axes[1].set_ylabel(\"AICR\")\n    axes[0].legend()\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset AICR Curves\\nLeft: Training AICR, Right: Validation AICR\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_AICR_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating AICR plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\nelse:\n    ds = data[\"label_smoothing\"][\"synthetic\"]\n    factors = ds[\"params\"]\n    train_losses = ds[\"losses\"][\"train\"]\n    val_losses = ds[\"losses\"][\"val\"]\n    train_rates = ds[\"metrics\"][\"train\"]\n    val_rates = ds[\"metrics\"][\"val\"]\n    train_iters = ds[\"mean_iterations\"][\"train\"]\n    val_iters = ds[\"mean_iterations\"][\"val\"]\n    epochs = range(1, len(train_losses[0]) + 1)\n\n    # Plot losses\n    try:\n        fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n        for l, s in zip(train_losses, factors):\n            axs[0].plot(epochs, l, label=f\"smooth={s}\")\n        for l, s in zip(val_losses, factors):\n            axs[1].plot(epochs, l, label=f\"smooth={s}\")\n        axs[0].set_title(\"Left: Training Loss\")\n        axs[1].set_title(\"Right: Validation Loss\")\n        axs[0].set_xlabel(\"Epoch\")\n        axs[1].set_xlabel(\"Epoch\")\n        axs[0].set_ylabel(\"Loss\")\n        axs[1].set_ylabel(\"Loss\")\n        axs[1].legend()\n        fig.suptitle(\"Synthetic Dataset Loss vs Epoch - Label Smoothing Ablation\")\n        plt.savefig(os.path.join(working_dir, \"synthetic_loss_ablation.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot: {e}\")\n        plt.close()\n\n    # Plot pass rates\n    try:\n        fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n        for r, s in zip(train_rates, factors):\n            axs[0].plot(epochs, r, label=f\"smooth={s}\")\n        for r, s in zip(val_rates, factors):\n            axs[1].plot(epochs, r, label=f\"smooth={s}\")\n        axs[0].set_title(\"Left: Training Pass Rate\")\n        axs[1].set_title(\"Right: Validation Pass Rate\")\n        axs[0].set_xlabel(\"Epoch\")\n        axs[1].set_xlabel(\"Epoch\")\n        axs[0].set_ylabel(\"Pass Rate\")\n        axs[1].set_ylabel(\"Pass Rate\")\n        axs[1].legend()\n        fig.suptitle(\"Synthetic Dataset Pass Rate vs Epoch - Label Smoothing Ablation\")\n        plt.savefig(os.path.join(working_dir, \"synthetic_pass_rate_ablation.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating pass rate plot: {e}\")\n        plt.close()\n\n    # Plot mean iterations\n    try:\n        fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n        for it, s in zip(train_iters, factors):\n            axs[0].plot(epochs, it, label=f\"smooth={s}\")\n        for it, s in zip(val_iters, factors):\n            axs[1].plot(epochs, it, label=f\"smooth={s}\")\n        axs[0].set_title(\"Left: Training Mean Iterations\")\n        axs[1].set_title(\"Right: Validation Mean Iterations\")\n        axs[0].set_xlabel(\"Epoch\")\n        axs[1].set_xlabel(\"Epoch\")\n        axs[0].set_ylabel(\"Mean Iters\")\n        axs[1].set_ylabel(\"Mean Iters\")\n        axs[1].legend()\n        fig.suptitle(\n            \"Synthetic Dataset Mean Iterations vs Epoch - Label Smoothing Ablation\"\n        )\n        plt.savefig(os.path.join(working_dir, \"synthetic_mean_iterations_ablation.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating mean iterations plot: {e}\")\n        plt.close()\n\n    # Print summary of final validation performance\n    print(\"Summary of final validation performance:\")\n    for s, losses, rates in zip(factors, val_losses, val_rates):\n        print(\n            f\"Label smoothing {s}: Final Val Loss={losses[-1]:.4f}, Final Val Pass Rate={rates[-1]:.4f}\"\n        )\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\nelse:\n    data = experiment_data[\"fixed_random_embedding\"][\"synthetic\"]\n    lrs = data[\"params\"]\n    train_losses = data[\"losses\"][\"train\"]\n    val_losses = data[\"losses\"][\"val\"]\n    epochs = range(1, len(train_losses[0]) + 1)\n    # Plot loss curves\n    try:\n        plt.figure()\n        for lr, tr, va in zip(lrs, train_losses, val_losses):\n            plt.plot(epochs, tr, label=f\"Train LR={lr}\")\n            plt.plot(epochs, va, \"--\", label=f\"Val LR={lr}\")\n        plt.title(\"Loss Curves on synthetic dataset\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curves: {e}\")\n        plt.close()\n    # Plot generation success rates\n    try:\n        metrics_train = data[\"metrics\"][\"train\"]\n        metrics_val = data[\"metrics\"][\"val\"]\n        plt.figure()\n        for lr, tr, va in zip(lrs, metrics_train, metrics_val):\n            plt.plot(epochs, tr, label=f\"Train SR LR={lr}\")\n            plt.plot(epochs, va, \"--\", label=f\"Val SR LR={lr}\")\n        plt.title(\"Generation Success Rates on synthetic dataset\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Success Rate\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"synthetic_generation_success_rates.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating success rate plot: {e}\")\n        plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\n    ev = data[\"output_vocab_scaling\"]\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    ev = {}\n\n# Loss curves\ntry:\n    plt.figure()\n    for key, v in ev.items():\n        epochs = np.arange(1, len(v[\"losses\"][\"train\"]) + 1)\n        plt.plot(epochs, v[\"losses\"][\"train\"], label=f\"{key} train\")\n        plt.plot(epochs, v[\"losses\"][\"val\"], \"--\", label=f\"{key} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss Curves for output_vocab_scaling\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"output_vocab_scaling_loss.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# AICR curves\ntry:\n    plt.figure()\n    for key, v in ev.items():\n        epochs = np.arange(1, len(v[\"metrics\"][\"AICR\"][\"train\"]) + 1)\n        plt.plot(epochs, v[\"metrics\"][\"AICR\"][\"train\"], label=f\"{key} train\")\n        plt.plot(epochs, v[\"metrics\"][\"AICR\"][\"val\"], \"--\", label=f\"{key} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR\")\n    plt.title(\"AICR Curves for output_vocab_scaling\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"output_vocab_scaling_AICR.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating AICR plot: {e}\")\n    plt.close()\n\n# MeanIters curves\ntry:\n    plt.figure()\n    for key, v in ev.items():\n        epochs = np.arange(1, len(v[\"metrics\"][\"MeanIters\"][\"train\"]) + 1)\n        plt.plot(epochs, v[\"metrics\"][\"MeanIters\"][\"train\"], label=f\"{key} train\")\n        plt.plot(epochs, v[\"metrics\"][\"MeanIters\"][\"val\"], \"--\", label=f\"{key} val\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"MeanIters\")\n    plt.title(\"MeanIters Curves for output_vocab_scaling\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"output_vocab_scaling_MeanIters.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MeanIters plot: {e}\")\n    plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nd = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = d[\"head_depths\"]\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"losses\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"losses\"][\"train\"][idx], label=f\"Train Loss Depth {hd}\")\n        plt.plot(epochs, d[\"losses\"][\"val\"][idx], label=f\"Val Loss Depth {hd}\")\n    plt.suptitle(\"Loss Curves: Synthetic Dataset\")\n    plt.title(\"Left: Train Loss, Right: Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"metrics\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"metrics\"][\"train\"][idx], label=f\"Train AICR Depth {hd}\")\n        plt.plot(epochs, d[\"metrics\"][\"val\"][idx], label=f\"Val AICR Depth {hd}\")\n    plt.suptitle(\"AICR Metrics: Synthetic Dataset\")\n    plt.title(\"Left: Train Rate, Right: Validation Rate\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_aicr_metrics.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"classification_accuracy\"][\"train\"][idx]) + 1)\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"train\"][idx],\n            label=f\"Train Acc Depth {hd}\",\n        )\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"val\"][idx],\n            label=f\"Val Acc Depth {hd}\",\n        )\n    plt.suptitle(\"Classification Accuracy: Synthetic Dataset\")\n    plt.title(\"Left: Train Accuracy, Right: Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_classification_accuracy.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot3: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nd = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = d[\"head_depths\"]\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"losses\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"losses\"][\"train\"][idx], label=f\"Train Loss Depth {hd}\")\n        plt.plot(epochs, d[\"losses\"][\"val\"][idx], label=f\"Val Loss Depth {hd}\")\n    plt.suptitle(\"Loss Curves: Synthetic Dataset\")\n    plt.title(\"Left: Train Loss, Right: Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"metrics\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"metrics\"][\"train\"][idx], label=f\"Train AICR Depth {hd}\")\n        plt.plot(epochs, d[\"metrics\"][\"val\"][idx], label=f\"Val AICR Depth {hd}\")\n    plt.suptitle(\"AICR Metrics: Synthetic Dataset\")\n    plt.title(\"Left: Train Rate, Right: Validation Rate\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_aicr_metrics.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"classification_accuracy\"][\"train\"][idx]) + 1)\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"train\"][idx],\n            label=f\"Train Acc Depth {hd}\",\n        )\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"val\"][idx],\n            label=f\"Val Acc Depth {hd}\",\n        )\n    plt.suptitle(\"Classification Accuracy: Synthetic Dataset\")\n    plt.title(\"Left: Train Accuracy, Right: Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_classification_accuracy.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot3: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nd = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = d[\"head_depths\"]\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"losses\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"losses\"][\"train\"][idx], label=f\"Train Loss Depth {hd}\")\n        plt.plot(epochs, d[\"losses\"][\"val\"][idx], label=f\"Val Loss Depth {hd}\")\n    plt.suptitle(\"Loss Curves: Synthetic Dataset\")\n    plt.title(\"Left: Train Loss, Right: Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"metrics\"][\"train\"][idx]) + 1)\n        plt.plot(epochs, d[\"metrics\"][\"train\"][idx], label=f\"Train AICR Depth {hd}\")\n        plt.plot(epochs, d[\"metrics\"][\"val\"][idx], label=f\"Val AICR Depth {hd}\")\n    plt.suptitle(\"AICR Metrics: Synthetic Dataset\")\n    plt.title(\"Left: Train Rate, Right: Validation Rate\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_aicr_metrics.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        epochs = range(1, len(d[\"classification_accuracy\"][\"train\"][idx]) + 1)\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"train\"][idx],\n            label=f\"Train Acc Depth {hd}\",\n        )\n        plt.plot(\n            epochs,\n            d[\"classification_accuracy\"][\"val\"][idx],\n            label=f\"Val Acc Depth {hd}\",\n        )\n    plt.suptitle(\"Classification Accuracy: Synthetic Dataset\")\n    plt.title(\"Left: Train Accuracy, Right: Validation Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_classification_accuracy.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot3: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data_path_list = [\n        \"None/experiment_data.npy\",\n        \"None/experiment_data.npy\",\n        \"experiments/2025-06-07_15-26-52_abstract_interpretation_guided_generation_attempt_0/logs/0-run/experiment_results/experiment_2160233ef98d4359bd56051df6737eb2_proc_87822/experiment_data.npy\",\n    ]\n    all_experiment_data = []\n    for experiment_data_path in experiment_data_path_list:\n        exp = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\"), experiment_data_path),\n            allow_pickle=True,\n        ).item()\n        all_experiment_data.append(exp)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\ntry:\n    d_list = [\n        exp[\"classification_head_depth\"][\"synthetic\"] for exp in all_experiment_data\n    ]\n    head_depths = d_list[0][\"head_depths\"]\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        train_arrs = [d[\"losses\"][\"train\"][idx] for d in d_list]\n        val_arrs = [d[\"losses\"][\"val\"][idx] for d in d_list]\n        min_epochs = min(arr.shape[0] for arr in train_arrs + val_arrs)\n        train_stack = np.vstack([arr[:min_epochs] for arr in train_arrs])\n        val_stack = np.vstack([arr[:min_epochs] for arr in val_arrs])\n        epochs = np.arange(1, min_epochs + 1)\n        train_mean = train_stack.mean(axis=0)\n        train_sem = train_stack.std(axis=0, ddof=1) / np.sqrt(train_stack.shape[0])\n        val_mean = val_stack.mean(axis=0)\n        val_sem = val_stack.std(axis=0, ddof=1) / np.sqrt(val_stack.shape[0])\n        plt.plot(epochs, train_mean, label=f\"Train Loss Depth {hd}\", linestyle=\"-\")\n        plt.fill_between(\n            epochs, train_mean - train_sem, train_mean + train_sem, alpha=0.2\n        )\n        plt.plot(epochs, val_mean, label=f\"Val Loss Depth {hd}\", linestyle=\"--\")\n        plt.fill_between(epochs, val_mean - val_sem, val_mean + val_sem, alpha=0.2)\n    plt.suptitle(\"Aggregated Loss Curves: Synthetic Dataset\")\n    plt.title(\"Mean \u00b1 SEM across experiments for Train (solid) and Val (dashed)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_aggregated.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    for idx, hd in enumerate(head_depths):\n        train_arrs = [d[\"metrics\"][\"train\"][idx] for d in d_list]\n        val_arrs = [d[\"metrics\"][\"val\"][idx] for d in d_list]\n        min_epochs = min(arr.shape[0] for arr in train_arrs + val_arrs)\n        train_stack = np.vstack([arr[:min_epochs] for arr in train_arrs])\n        val_stack = np.vstack([arr[:min_epochs] for arr in val_arrs])\n        epochs = np.arange(1, min_epochs + 1)\n        train_mean = train_stack.mean(axis=0)\n        train_sem = train_stack.std(axis=0, ddof=1) / np.sqrt(train_stack.shape[0])\n        val_mean = val_stack.mean(axis=0)\n        val_sem = val_stack.std(axis=0, ddof=1) / np.sqrt(val_stack.shape[0])\n        plt.plot(epochs, train_mean, label=f\"Train AICR Depth {hd}\", linestyle=\"-\")\n        plt.fill_between(\n            epochs, train_mean - train_sem, train_mean + train_sem, alpha=0.2\n        )\n        plt.plot(epochs, val_mean, label=f\"Val AICR Depth {hd}\", linestyle=\"--\")\n        plt.fill_between(epochs, val_mean - val_sem, val_mean + val_sem, alpha=0.2)\n    plt.suptitle(\"Aggregated AICR Metrics: Synthetic Dataset\")\n    plt.title(\"Mean \u00b1 SEM across experiments for Train (solid) and Val (dashed)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"AICR Rate\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_aicr_aggregated.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated AICR plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    val_final_means = []\n    val_final_sems = []\n    for idx, hd in enumerate(head_depths):\n        train_arrs = [d[\"classification_accuracy\"][\"train\"][idx] for d in d_list]\n        val_arrs = [d[\"classification_accuracy\"][\"val\"][idx] for d in d_list]\n        min_epochs = min(arr.shape[0] for arr in train_arrs + val_arrs)\n        train_stack = np.vstack([arr[:min_epochs] for arr in train_arrs])\n        val_stack = np.vstack([arr[:min_epochs] for arr in val_arrs])\n        epochs = np.arange(1, min_epochs + 1)\n        train_mean = train_stack.mean(axis=0)\n        train_sem = train_stack.std(axis=0, ddof=1) / np.sqrt(train_stack.shape[0])\n        val_mean = val_stack.mean(axis=0)\n        val_sem = val_stack.std(axis=0, ddof=1) / np.sqrt(val_stack.shape[0])\n        val_final_means.append(val_mean[-1])\n        val_final_sems.append(val_sem[-1])\n        plt.plot(epochs, train_mean, label=f\"Train Acc Depth {hd}\", linestyle=\"-\")\n        plt.fill_between(\n            epochs, train_mean - train_sem, train_mean + train_sem, alpha=0.2\n        )\n        plt.plot(epochs, val_mean, label=f\"Val Acc Depth {hd}\", linestyle=\"--\")\n        plt.fill_between(epochs, val_mean - val_sem, val_mean + val_sem, alpha=0.2)\n    plt.suptitle(\"Aggregated Classification Accuracy: Synthetic Dataset\")\n    plt.title(\"Mean \u00b1 SEM across experiments for Train (solid) and Val (dashed)\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_accuracy_aggregated.png\"))\n    plt.close()\n    for hd, fm, fs in zip(head_depths, val_final_means, val_final_sems):\n        print(f\"Synthetic Depth {hd}: Final Val Acc = {fm:.3f} \u00b1 {fs:.3f}\")\nexcept Exception as e:\n    print(f\"Error creating aggregated classification accuracy plot: {e}\")\n    plt.close()\n"], "plot_plan": ["I will load the experiment_data.npy from the working directory and extract the synthetic dataset's parameter sweep, training and validation losses, and AICR metrics. I convert the nested lists into numpy arrays for easier indexing over learning rates and epochs. I then create two separate figures, each enclosed in its own try-except block: one for loss curves and one for AICR curves. In each figure I use a pair of subplots to plot training and validation curves side-by-side, labeling axes, adding subplot titles 'Training Loss'/'Validation Loss' or 'Training AICR'/'Validation AICR', and a main suptitle 'Synthetic dataset Loss Curves' or 'Synthetic dataset AICR Curves' with subtitles indicating the left/right panels. Learning rates are distinguished by different line styles and included in a legend. Figures are saved with descriptive filenames into working_dir and closed after saving, with exceptions caught and a message printed if any plot fails. This adheres to plotting only existing experiment data, uses basic matplotlib, and limits to two clear and standard visualizations.", null, "We load the saved experiment data from the working directory and extract the synthetic dataset losses and generation accuracy metrics for each embedding dimension. We prepare two separate plots: one showing training and validation loss curves over epochs, and another showing corresponding AICR rates. Each plot is drawn for all embedding dimensions on the same axes, with distinguishable line styles and a legend. We wrap each figure creation in its own try-except block to catch any errors and ensure that figures are always closed. Axes are labeled and titles clearly indicate the synthetic dataset and plot type. Finally, each figure is saved to the working directory with descriptive filenames that include the dataset name and plot type.", null, null, null, "We start by loading the saved experiment_data.npy from the working directory and extracting the synthetic dataset\u2019s weight_decay parameters, loss histories, and AICR metrics for train and validation.  We then create three separate plots in their own try-except blocks, each closed after saving to avoid resource leaks.  The first plot overlays training and validation loss curves across epochs for each weight_decay value with a clear title indicating the synthetic dataset and train vs val curves.  The second plot similarly overlays AICR (accuracy of generated code) curves for training and validation across epochs.  The third plot is a bar chart comparing the final epoch\u2019s validation AICR across the different weight_decay settings.  Each figure is saved to the working directory with a descriptive filename that includes the dataset name and plot type.  Any errors during loading or plotting are caught and printed, ensuring the script runs robustly.  Basic Matplotlib calls are used without custom styles as required.", "We begin by loading the saved experiment_data dictionary containing training/validation losses, AICR metrics, and classification accuracies for head depths 1 and 2 on the synthetic dataset. We then extract the head_depths list and the corresponding metric arrays. Using matplotlib, we produce three separate figures: loss curves, AICR rate curves, and classification accuracy curves. Each figure is wrapped in a try-except block that reports errors, ensures the figure is always closed, and saves the PNG to working_dir with descriptive filenames. We include a suptitle specifying the dataset and a subtitle indicating \u201cLeft: Train vs Right: Validation\u201d for clarity. Epoch numbers are plotted on the x-axis, with the metric on the y-axis and legends distinguishing head depths and splits. Finally, all figures are closed after saving to manage resources.", "First, I load the saved experiment data from the working directory and extract the synthetic ablation study results. Next, I pull out the dropout rates, per-epoch training/validation losses, and generation pass rates. I then generate two separate figures inside try-except blocks: one for training/validation loss curves and one for generation pass rate curves. Each curve is labeled by its dropout parameter and axes are titled for clarity. I save each plot to the working directory with descriptive filenames containing the dataset and plot type. After each plot, I close the figure to free resources. Finally, I print the final validation pass rate for each dropout rate as the evaluation metric summary. Any errors in loading or plotting are caught and logged without halting the script.", "We load the saved experiment data and extract the synthetic dataset results for each batch size. We then derive the number of epochs from the loss arrays. For each of losses, pass\u2010rate metrics, and mean iterations, we create a two\u2010panel figure where the left panel shows training curves and the right panel shows validation curves across epochs for all batch sizes. Each figure is wrapped in its own try\u2010except block so that errors in one plot don\u2019t stop the others. We add a suptitle specifying dataset type and a clear subtitle indicating the left/right panels, plus axis titles, legends, and figure\u2010specific descriptive filenames. All figures are saved into the working directory and closed properly in both normal and exception flows.", "I will load the saved experiment data from the working directory, extract per\u2010dataset training and validation losses and pass rates, and then produce loss and accuracy curves for each domain. Each plot is wrapped in its own try\u2010except block to ensure robustness and always closes the figure. I will include a suptitle indicating the plot type and dataset, plus a subtitle clarifying left and right curves. Filenames will be descriptive, containing both the dataset name and plot type. I will also print out the final training and validation pass rates for each domain. The code uses only existing data and adheres to basic matplotlib usage.", "We load the saved experiment data and pull out the synthetic\u2010dataset measurements for each optimizer.  In two separate try/exceptions we produce: (1) a 1\u00d72 subplot of training vs validation loss curves across epochs for all optimizers, and (2) a similar 1\u00d72 subplot of training vs validation AICR rates.  Each subplot is titled and labeled, and the overall figure carries a clear subtitle denoting the synthetic dataset and which side is training vs validation.  We save each plot to the working directory with a descriptive name, always closing figures and printing any errors encountered.", null, "We will load the saved experiment_data.npy from the working directory, extract the label\u2010smoothing ablation results for the synthetic dataset, and then plot three standard metrics: training/validation losses, pass rates, and mean iteration counts over epochs. Each plot is generated in its own try\u2010except block, with two subplots showing \"Left: Training\" and \"Right: Validation\" curves. We iterate over each smoothing factor to plot its curve and add a legend, titles, and subtitles. Figures are saved to working_dir with descriptive names and always closed to free resources. Finally, we print a summary of final validation loss and pass rate for each smoothing factor.", null, "I will load the experiment data from the working directory and extract the synthetic dataset results. Then I will prepare two combined plots: one for training and validation loss curves across all learning rates, and another for training and validation generation success rates. Each plot will be wrapped in its own try-except block to catch any errors during plotting. Figures will include clear titles specifying the dataset and plot type, and axes will be labeled appropriately. After saving each figure with descriptive filenames into the working directory, I will ensure the figure is closed to free resources. This approach yields two standard visualizations, staying within the limit of five plots.", null, "We load the saved experiment_data from the working directory and extract the \u201coutput_vocab_scaling\u201d section. We identify the different ablation keys (e.g., \u201cops_4\u201d, \u201cops_8\u201d, \u201cops_16\u201d) to iterate over. For each of the three metrics\u2014losses, AICR, and MeanIters\u2014we gather the training and validation curves across epochs for each vocabulary size. We create three separate figures, each wrapped in its own try-except block to handle errors and ensure figures are closed. In each plot, curves are distinguished by ablation size and split (train vs val), and we include axis labels, a legend, and a descriptive title mentioning the dataset name. We save each figure as a PNG in the working_dir using clear filenames like \u201coutput_vocab_scaling_loss.png\u201d, \u201coutput_vocab_scaling_AICR.png\u201d, and \u201coutput_vocab_scaling_MeanIters.png\u201d. Any plotting errors are caught and printed without interrupting the workflow.", null, null, null, null, null], "ablation_name": [null, "Multi-Domain Synthetic Specification Ablation", "Embedding Dimensionality Ablation", "Batch Size Ablation", "Optimization Algorithm Ablation", "Dropout Regularization Ablation", "Weight Decay (L2 Regularization) Ablation", "CLASSIFICATION_HEAD_DEPTH ABLATION", null, null, null, null, "Label Smoothing Ablation", null, "Output Vocabulary Scaling Ablation", "Fixed Random Embedding Ablation", "Weight Tying Ablation", null, "Label Noise Ablation", null, null, null, null], "hyperparam_name": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["I will load the saved experiment data using NumPy with pickle support, then\niterate over the learning\u2010rate hyperparameter sweep for each dataset (here\n\u201csynthetic\u201d). For each learning rate, the script prints the dataset name and the\nfinal epoch\u2019s metrics: training loss, validation loss, training generation\nsuccess rate (AICR), and validation generation success rate (AICR), with fully\nspecified metric names. The code lives at global scope and will run immediately\nwhen the script is executed.", "Below is a script that immediately loads the saved numpy file from the working\ndirectory, iterates over each dataset in the multi\u2010domain specification, and\nprints the final epoch\u2019s training and validation accuracy and loss with clear\nlabels.", "Here\u2019s a simple script that immediately loads the saved NumPy data, iterates\nover the synthetic dataset\u2019s embedding\u2010dimension experiments, and prints out the\nfinal epoch\u2019s train accuracy, validation accuracy, train loss, and validation\nloss for each embedding size. It constructs precise metric labels and clearly\nindicates which dataset and embedding dimension each set of metrics refers to.", "I will load the saved numpy dictionary from the \u201cworking\u201d directory, then\niterate through each ablation key and its contained datasets. For every dataset\n(here \u201csynthetic\u201d), I print the dataset name before gathering its parameter\nlist, training/validation loss lists, and training/validation accuracy lists. I\nloop over each batch size, extract the final epoch value for each metric, and\nprint them with precise metric labels. The code runs immediately at global scope\nwithout any special entry point.", "I will load the saved NumPy experiment data with allow_pickle, then iterate over\neach dataset under the \"optimizer\" key (here just \"synthetic\"). For each\noptimizer, I'll extract the final training and validation accuracy from the\nmetrics, as well as the final training and validation loss, and print them with\nclear labels. The dataset name is printed before any metrics, and no __main__\nguard or plotting code is included\u2014everything runs at the global scope upon\nexecution.", "I will load the saved numpy file using `allow_pickle=True`, retrieve the nested\ndata structure under `\"dropout_ablation\"` \u2192 `\"synthetic\"`, and then for each\ndropout rate print the dataset name followed by the final epoch values of\ntraining loss, validation loss, train generation pass rate, and validation\ngeneration pass rate with clear labels. The script executes immediately at\nimport time without any `__main__` guard.", "The following script immediately loads the saved NumPy results from the working\ndirectory and parses the weight\u2010decay ablation for the synthetic dataset.  For\neach weight\u2010decay value it prints the dataset name followed by the final epoch\u2019s\ntraining loss, validation loss, training correctness rate, and validation\ncorrectness rate.  All metric labels are fully spelled out and no plots are\ngenerated.", "Below is a script that loads the saved NumPy file, retrieves the \u201csynthetic\u201d\ndataset results under the classification head\u2010depth ablation, and then prints\nout the final (last\u2010epoch) values of training loss, validation loss, training\naccuracy, validation accuracy, and the corresponding generation pass rates for\neach head depth:", "The code below loads the saved experiment data from the NumPy file in the\nworking directory, then iterates through each ablation experiment and dataset\n(e.g., \u201csynthetic\u201d). For each dropout rate, it extracts the per-epoch training\nand validation accuracies and losses, selects the final epoch\u2019s values, and\nprints them with clear labels. The script runs immediately at the global scope\nwithout any `if __name__ == \"__main__\":` guard and produces no plots.", "The script loads the NumPy file from the \u201cworking\u201d directory into a Python dict\nand then iterates over each parameter sweep (in this case `batch_size`) and its\nassociated datasets. For each dataset and batch\u2010size setting, it pulls out the\nfinal epoch metrics for training loss, validation loss, training accuracy,\nvalidation accuracy, and mean iterations, and prints them with explicit labels.\nThe code executes immediately at the global scope and uses only descriptive\nmetric names without any `if __name__ == \"__main__\":` guard.", "The script starts by constructing the path to the `experiment_data.npy` file in\nthe `working` directory and loading it using NumPy with `allow_pickle=True`. It\nthen drills into the `\"multi_domain_synthetic_specification\"` field to access\neach dataset's recorded metrics and losses. For each dataset, it selects the\nfinal epoch\u2019s train and validation accuracy (from `metrics`) and train and\nvalidation loss (from `losses`), and prints them with clear labels. This runs\nimmediately upon execution without any extra entry-point boilerplate.", "I will load the saved NumPy file from the `working` directory, extract the\nnested metrics under the `\"optimizer\"` key (e.g., the `\"synthetic\"` dataset),\nand then iterate through each optimizer to print the final epoch results. Each\nmetric is labeled clearly (e.g., \"training loss\", \"validation accuracy\") and\nonly the last value for each curve is displayed. The script executes immediately\nat the global scope without any special entry point.", "I will load the `experiment_data.npy` file from the working directory and parse\nthe nested dictionary for the label smoothing ablation results. For each\nsmoothing factor under the synthetic dataset, I will extract the final epoch\ntraining and validation losses as well as the final generation pass rates. The\nscript will print the dataset name followed by each specific metric name and its\nfinal value, clearly labeling \u201ctraining\u201d or \u201cvalidation.\u201d The code runs\nimmediately at the global scope with no plots or special entry points.", "I will load the experiment_data.npy file from the working directory and extract\nthe 'synthetic' metrics under the 'label_smoothing' key. Then I will iterate\nthrough each smoothing factor to obtain the final epoch\u2019s training and\nvalidation pass rates, losses, and mean iteration counts. The script prints the\ndataset name first, then each parameter value with clearly labeled metric names.\nThe code runs immediately at the global scope without any entry\u2010point guard.", "Below is a script that loads the saved numpy experiment data, iterates over each\nvocabulary size dataset, and prints out the final training and validation losses\nas well as the final generation pass rates with clear labels.", "I will load the NumPy file from the working directory, extract the nested\nstructure under each model and dataset, and then iterate over the list of\nlearning rates. For each learning rate, I will grab the final epoch\u2019s train and\nvalidation accuracy from the stored metrics and print them with clear labels.\nThe script runs immediately at global scope and does not rely on an entry\u2010point\nblock. All paths use `os.getcwd()` joined with `\"working\"` to locate the saved\nfile.", "I will import `os` and `numpy`, construct the path to\n`working/experiment_data.npy`, and load it with pickle enabled. Then I iterate\nover the experiments and datasets, printing each dataset\u2019s name followed by the\nfinal train/validation AICR pass rates and losses for each condition (\u2018untied\u2019\nand \u2018tied\u2019) with clear, descriptive metric labels. All code is at the global\nlevel and executes immediately upon running.", "I will load the saved `experiment_data.npy` file from the working directory,\nthen iterate over each sub-dataset under `\"output_vocab_scaling\"`. For each\ndataset I will extract the final epoch values of training loss, validation loss,\ntraining accuracy, validation accuracy, training mean iterations, and validation\nmean iterations. I will print the dataset name first, followed by clearly\nlabeled metric names and their values. The script executes at global scope and\ndoes not require any special entry point.", "The script below immediately loads the saved NumPy file from the working\ndirectory, drills into the `synthetic` dataset under `label_noise`, and then for\neach noise level prints the dataset name and noise fraction along with the final\nepoch\u2019s training accuracy, validation accuracy, training loss, and validation\nloss. No `if __name__ == \"__main__\":` guard is used so that the code runs as\nsoon as it is executed.", "Below is a script that loads the saved NumPy file, retrieves the \u201csynthetic\u201d\ndataset results under the classification head\u2010depth ablation, and then prints\nout the final (last\u2010epoch) values of training loss, validation loss, training\naccuracy, validation accuracy, and the corresponding generation pass rates for\neach head depth:", "Below is a script that loads the saved NumPy file, retrieves the \u201csynthetic\u201d\ndataset results under the classification head\u2010depth ablation, and then prints\nout the final (last\u2010epoch) values of training loss, validation loss, training\naccuracy, validation accuracy, and the corresponding generation pass rates for\neach head depth:", "Below is a script that loads the saved NumPy file, retrieves the \u201csynthetic\u201d\ndataset results under the classification head\u2010depth ablation, and then prints\nout the final (last\u2010epoch) values of training loss, validation loss, training\naccuracy, validation accuracy, and the corresponding generation pass rates for\neach head depth:", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# Locate working directory and load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate over the hyperparameter sweep (learning_rate) and datasets\nsweep_data = experiment_data.get(\"learning_rate\", {})\nfor dataset_name, dataset_data in sweep_data.items():\n    params = dataset_data[\"params\"]\n    losses = dataset_data[\"losses\"]\n    metrics = dataset_data[\"metrics\"]\n    # Print final metrics for each learning rate\n    for idx, lr in enumerate(params):\n        final_train_loss = losses[\"train\"][idx][-1]\n        final_val_loss = losses[\"val\"][idx][-1]\n        final_train_rate = metrics[\"train\"][idx][-1]\n        final_val_rate = metrics[\"val\"][idx][-1]\n        print(f\"Dataset: {dataset_name} (learning rate = {lr})\")\n        print(f\"Final training loss: {final_train_loss:.4f}\")\n        print(f\"Final validation loss: {final_val_loss:.4f}\")\n        print(f\"Final training generation success rate (AICR): {final_train_rate:.4f}\")\n        print(\n            f\"Final validation generation success rate (AICR): {final_val_rate:.4f}\\n\"\n        )\n", "import os\nimport numpy as np\n\n# Load the experiment data from the working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract and print final metrics for each dataset\nfor dataset_name, dataset_entry in experiment_data[\n    \"multi_domain_synthetic_specification\"\n].items():\n    train_acc = dataset_entry[\"metrics\"][\"train\"][-1]\n    val_acc = dataset_entry[\"metrics\"][\"val\"][-1]\n    train_loss = dataset_entry[\"losses\"][\"train\"][-1]\n    val_loss = dataset_entry[\"losses\"][\"val\"][-1]\n\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"train accuracy: {train_acc:.4f}\")\n    print(f\"validation accuracy: {val_acc:.4f}\")\n    print(f\"training loss: {train_loss:.4f}\")\n    print(f\"validation loss: {val_loss:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under embedding_dim experiments\nemb_exp = experiment_data[\"embedding_dim\"][\"synthetic\"]\nemb_dims = emb_exp[\"params\"]\ntrain_rates = emb_exp[\"metrics\"][\"train\"]\nval_rates = emb_exp[\"metrics\"][\"val\"]\ntrain_losses = emb_exp[\"losses\"][\"train\"]\nval_losses = emb_exp[\"losses\"][\"val\"]\n\n# Print final metrics for each embedding dimension\nfor dim, tr_accs, val_accs, tr_ls, val_ls in zip(\n    emb_dims, train_rates, val_rates, train_losses, val_losses\n):\n    final_train_acc = tr_accs[-1]\n    final_val_acc = val_accs[-1]\n    final_train_loss = tr_ls[-1]\n    final_val_loss = val_ls[-1]\n\n    print(f\"Dataset: synthetic (embedding_dim = {dim})\")\n    print(f\"  train accuracy: {final_train_acc:.4f}\")\n    print(f\"  validation accuracy: {final_val_acc:.4f}\")\n    print(f\"  train loss: {final_train_loss:.4f}\")\n    print(f\"  validation loss: {final_val_loss:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate over ablation settings and datasets\nfor ablation_name, ablation_data in experiment_data.items():\n    for dataset_name, dataset_results in ablation_data.items():\n        print(f\"Dataset: {dataset_name}\")\n        params = dataset_results[\"params\"]\n        train_losses = dataset_results[\"losses\"][\"train\"]\n        val_losses = dataset_results[\"losses\"][\"val\"]\n        train_accuracies = dataset_results[\"metrics\"][\"train\"]\n        val_accuracies = dataset_results[\"metrics\"][\"val\"]\n\n        # Print final epoch values per batch size\n        for bs, tr_loss_list, vl_loss_list, tr_acc_list, vl_acc_list in zip(\n            params, train_losses, val_losses, train_accuracies, val_accuracies\n        ):\n            final_tr_loss = tr_loss_list[-1]\n            final_vl_loss = vl_loss_list[-1]\n            final_tr_acc = tr_acc_list[-1]\n            final_vl_acc = vl_acc_list[-1]\n\n            print(f\"Batch size: {bs}\")\n            print(f\"  Final training loss: {final_tr_loss:.4f}\")\n            print(f\"  Final validation loss: {final_vl_loss:.4f}\")\n            print(f\"  Final train accuracy: {final_tr_acc:.4f}\")\n            print(f\"  Final validation accuracy: {final_vl_acc:.4f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate through each dataset in the optimizer experiments\nfor dataset_name, dataset_info in experiment_data[\"optimizer\"].items():\n    print(f\"{dataset_name} dataset:\")\n    optim_names = dataset_info[\"optim_names\"]\n    train_metrics = dataset_info[\"metrics\"][\"train\"]\n    val_metrics = dataset_info[\"metrics\"][\"val\"]\n    train_losses = dataset_info[\"losses\"][\"train\"]\n    val_losses = dataset_info[\"losses\"][\"val\"]\n\n    # Print the final (last epoch) values for each optimizer\n    for name, tr_accs, vl_accs, tr_ls, vl_ls in zip(\n        optim_names, train_metrics, val_metrics, train_losses, val_losses\n    ):\n        final_train_acc = tr_accs[-1]\n        final_val_acc = vl_accs[-1]\n        final_train_loss = tr_ls[-1]\n        final_val_loss = vl_ls[-1]\n\n        print(f\"  Optimizer: {name}\")\n        print(f\"    train accuracy: {final_train_acc:.4f}\")\n        print(f\"    validation accuracy: {final_val_acc:.4f}\")\n        print(f\"    train loss: {final_train_loss:.4f}\")\n        print(f\"    validation loss: {final_val_loss:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract synthetic ablation results\nsynthetic = experiment_data[\"dropout_ablation\"][\"synthetic\"]\ndropout_rates = synthetic[\"params\"]\ntrain_losses = synthetic[\"losses\"][\"train\"]\nval_losses = synthetic[\"losses\"][\"val\"]\ntrain_rates = synthetic[\"metrics\"][\"train\"]\nval_rates = synthetic[\"metrics\"][\"val\"]\n\n# Print metrics for the synthetic dataset\nprint(\"Dataset: Synthetic\")\nfor dr, t_losses, v_losses, t_rates, v_rates in zip(\n    dropout_rates, train_losses, val_losses, train_rates, val_rates\n):\n    final_train_loss = t_losses[-1]\n    final_val_loss = v_losses[-1]\n    final_train_rate = t_rates[-1]\n    final_val_rate = v_rates[-1]\n    print(f\"\\nDropout rate: {dr}\")\n    print(f\"  training loss (final epoch): {final_train_loss:.4f}\")\n    print(f\"  validation loss (final epoch): {final_val_loss:.4f}\")\n    print(f\"  train generation pass rate (final epoch): {final_train_rate:.4f}\")\n    print(f\"  validation generation pass rate (final epoch): {final_val_rate:.4f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset metrics under weight_decay ablation\nwd_data = experiment_data[\"weight_decay\"][\"synthetic\"]\nweight_decays = wd_data[\"params\"]\ntrain_losses = wd_data[\"losses\"][\"train\"]\nvalidation_losses = wd_data[\"losses\"][\"val\"]\ntraining_rates = wd_data[\"metrics\"][\"train\"]\nvalidation_rates = wd_data[\"metrics\"][\"val\"]\n\n# Print final metrics for each weight_decay value\nfor wd, tl_list, vl_list, tr_list, vr_list in zip(\n    weight_decays, train_losses, validation_losses, training_rates, validation_rates\n):\n    final_train_loss = tl_list[-1]\n    final_validation_loss = vl_list[-1]\n    final_training_rate = tr_list[-1]\n    final_validation_rate = vr_list[-1]\n\n    print(f\"Weight decay = {wd}\")\n    print(\"Dataset: synthetic\")\n    print(f\"Training loss: {final_train_loss:.4f}\")\n    print(f\"Validation loss: {final_validation_loss:.4f}\")\n    print(f\"Training correctness rate: {final_training_rate:.4f}\")\n    print(f\"Validation correctness rate: {final_validation_rate:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under classification_head_depth\nsynthetic = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = synthetic[\"head_depths\"]\ntrain_losses = synthetic[\"losses\"][\"train\"]\nval_losses = synthetic[\"losses\"][\"val\"]\ntrain_accs = synthetic[\"classification_accuracy\"][\"train\"]\nval_accs = synthetic[\"classification_accuracy\"][\"val\"]\ntrain_rates = synthetic[\"metrics\"][\"train\"]\nval_rates = synthetic[\"metrics\"][\"val\"]\n\n# Print the final metrics\nprint(\"Dataset: synthetic\")\nfor idx, depth in enumerate(head_depths):\n    print(f\"\\nHead depth {depth}:\")\n    print(f\"train loss: {train_losses[idx][-1]:.4f}\")\n    print(f\"validation loss: {val_losses[idx][-1]:.4f}\")\n    print(f\"train accuracy: {train_accs[idx][-1]:.4f}\")\n    print(f\"validation accuracy: {val_accs[idx][-1]:.4f}\")\n    print(f\"train generation pass rate: {train_rates[idx][-1]:.4f}\")\n    print(f\"validation generation pass rate: {val_rates[idx][-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each ablation study and dataset\nfor ablation_name, ablation_data in experiment_data.items():\n    for dataset_name, dataset_data in ablation_data.items():\n        print(f\"Dataset: {dataset_name}\")\n        # Get hyperparameter settings and metrics\n        dropout_rates = dataset_data.get(\"params\", [])\n        train_accs = dataset_data[\"metrics\"][\"train\"]\n        val_accs = dataset_data[\"metrics\"][\"val\"]\n        train_losses = dataset_data[\"losses\"][\"train\"]\n        val_losses = dataset_data[\"losses\"][\"val\"]\n\n        # Print final epoch values for each dropout rate\n        for dr, tr_acc_list, vl_acc_list, tr_loss_list, vl_loss_list in zip(\n            dropout_rates, train_accs, val_accs, train_losses, val_losses\n        ):\n            final_train_acc = tr_acc_list[-1]\n            final_val_acc = vl_acc_list[-1]\n            final_train_loss = tr_loss_list[-1]\n            final_val_loss = vl_loss_list[-1]\n\n            print(f\"Dropout rate: {dr}\")\n            print(f\"  Final training accuracy: {final_train_acc:.4f}\")\n            print(f\"  Final validation accuracy: {final_val_acc:.4f}\")\n            print(f\"  Final training loss: {final_train_loss:.4f}\")\n            print(f\"  Final validation loss: {final_val_loss:.4f}\")\n        print()\n", "import os\nimport numpy as np\n\n# Load the experiment data from the working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate through each hyperparameter type and its datasets\nfor param_type, datasets in experiment_data.items():\n    for dataset_name, data in datasets.items():\n        print(f\"Dataset: {dataset_name}\")\n        params = data.get(\"params\", [])\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n        train_accs = data.get(\"metrics\", {}).get(\"train\", [])\n        val_accs = data.get(\"metrics\", {}).get(\"val\", [])\n        train_iters = data.get(\"iterations\", {}).get(\"train\", [])\n        val_iters = data.get(\"iterations\", {}).get(\"val\", [])\n\n        # For each parameter value (e.g., each batch size), print final metrics\n        for idx, p in enumerate(params):\n            # Print parameter setting\n            pretty_param = param_type.replace(\"_\", \" \").capitalize()\n            print(f\"{pretty_param}: {p}\")\n\n            # Extract final epoch values\n            final_train_loss = train_losses[idx][-1]\n            final_val_loss = val_losses[idx][-1]\n            final_train_acc = train_accs[idx][-1]\n            final_val_acc = val_accs[idx][-1]\n            final_train_iter = train_iters[idx][-1]\n            final_val_iter = val_iters[idx][-1]\n\n            # Print each metric with clear labels\n            print(f\"  final training loss: {final_train_loss:.4f}\")\n            print(f\"  final validation loss: {final_val_loss:.4f}\")\n            print(f\"  final train accuracy: {final_train_acc:.4f}\")\n            print(f\"  final validation accuracy: {final_val_acc:.4f}\")\n            print(f\"  final mean training iterations: {final_train_iter:.2f}\")\n            print(f\"  final mean validation iterations: {final_val_iter:.2f}\")\n        print()\n", "import os\nimport numpy as np\n\n# Load the experiment data\nfile_path = os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Navigate to the multi-domain specification results\nspec_results = experiment_data[\"multi_domain_synthetic_specification\"]\n\n# Print final values of metrics and losses for each dataset\nfor dataset_name, results in spec_results.items():\n    final_train_acc = results[\"metrics\"][\"train\"][-1]\n    final_val_acc = results[\"metrics\"][\"val\"][-1]\n    final_train_loss = results[\"losses\"][\"train\"][-1]\n    final_val_loss = results[\"losses\"][\"val\"][-1]\n\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Train accuracy: {final_train_acc:.4f}\")\n    print(f\"Validation accuracy: {final_val_acc:.4f}\")\n    print(f\"Train loss: {final_train_loss:.4f}\")\n    print(f\"Validation loss: {final_val_loss:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Mapping from metric keys to human-readable labels\nlabel_map = {\n    \"train_loss\": \"Training loss\",\n    \"val_loss\": \"Validation loss\",\n    \"train_AICR\": \"Training accuracy\",\n    \"val_AICR\": \"Validation accuracy\",\n    \"mean_iters_to_convergence_train\": \"Mean iterations to convergence (training)\",\n    \"mean_iters_to_convergence_val\": \"Mean iterations to convergence (validation)\",\n}\n\n# Iterate over each dataset under \"optimizer\"\nfor dataset_name, dataset in experiment_data.get(\"optimizer\", {}).items():\n    print(f\"Dataset: {dataset_name}\")\n    optim_names = dataset.get(\"optim_names\", [])\n    metrics = dataset.get(\"metrics\", {})\n\n    # Define the order of metrics to print\n    metric_keys = [\n        \"train_loss\",\n        \"val_loss\",\n        \"train_AICR\",\n        \"val_AICR\",\n        \"mean_iters_to_convergence_train\",\n        \"mean_iters_to_convergence_val\",\n    ]\n\n    # For each optimizer, print the final value of each metric\n    for idx, opt_name in enumerate(optim_names):\n        print(f\"Optimizer: {opt_name}\")\n        for key in metric_keys:\n            values_list = metrics.get(key, [])\n            if idx < len(values_list):\n                epoch_values = values_list[idx]\n                # Determine final value (last epoch)\n                try:\n                    final_value = epoch_values[-1]\n                except Exception:\n                    final_value = epoch_values\n                # Format numeric output\n                if isinstance(final_value, (float, np.floating)):\n                    print(f\"{label_map.get(key, key)}: {final_value:.4f}\")\n                else:\n                    print(f\"{label_map.get(key, key)}: {final_value}\")\n        print()\n", "import os\nimport numpy as np\n\n# Load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through the label smoothing experiments\nfor group_name, datasets in experiment_data.items():\n    for dataset_name, d in datasets.items():\n        params = d[\"params\"]\n        train_losses = d[\"losses\"][\"train\"]\n        val_losses = d[\"losses\"][\"val\"]\n        train_rates = d[\"metrics\"][\"train\"]\n        val_rates = d[\"metrics\"][\"val\"]\n        # Print final metrics for each smoothing factor\n        for idx, smooth in enumerate(params):\n            print(f\"Dataset: {dataset_name} (label smoothing = {smooth})\")\n            print(f\"Final training loss: {train_losses[idx][-1]:.4f}\")\n            print(f\"Final validation loss: {val_losses[idx][-1]:.4f}\")\n            print(f\"Final training generation pass rate: {train_rates[idx][-1]:.4f}\")\n            print(f\"Final validation generation pass rate: {val_rates[idx][-1]:.4f}\")\n            print()\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under label_smoothing\ndataset_name = \"synthetic\"\nds = experiment_data[\"label_smoothing\"][dataset_name]\nparams = ds[\"params\"]\ntrain_rates = ds[\"metrics\"][\"train\"]\nval_rates = ds[\"metrics\"][\"val\"]\ntrain_losses = ds[\"losses\"][\"train\"]\nval_losses = ds[\"losses\"][\"val\"]\ntrain_iters = ds[\"mean_iterations\"][\"train\"]\nval_iters = ds[\"mean_iterations\"][\"val\"]\n\n# Print dataset and final metrics for each smoothing factor\nprint(f\"Dataset: {dataset_name}\")\nfor p, tr, vr, tl, vl, ti, vi in zip(\n    params, train_rates, val_rates, train_losses, val_losses, train_iters, val_iters\n):\n    final_train_rate = tr[-1]\n    final_val_rate = vr[-1]\n    final_train_loss = tl[-1]\n    final_val_loss = vl[-1]\n    final_train_iter = ti[-1]\n    final_val_iter = vi[-1]\n\n    print(f\"\\nLabel smoothing = {p}\")\n    print(f\"Final training pass rate: {final_train_rate:.4f}\")\n    print(f\"Final validation pass rate: {final_val_rate:.4f}\")\n    print(f\"Final training loss: {final_train_loss:.4f}\")\n    print(f\"Final validation loss: {final_val_loss:.4f}\")\n    print(f\"Final mean training iterations: {final_train_iter:.2f}\")\n    print(f\"Final mean validation iterations: {final_val_iter:.2f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract and print metrics for each ablation dataset\nfor dataset_name, dataset_info in experiment_data[\"output_vocab_scaling\"].items():\n    print(f\"Dataset: {dataset_name}\")\n    # Losses\n    train_losses = dataset_info[\"losses\"][\"train\"]\n    val_losses = dataset_info[\"losses\"][\"val\"]\n    final_train_loss = train_losses[-1]\n    final_val_loss = val_losses[-1]\n    print(f\"training loss: {final_train_loss:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\")\n    # Generation pass rates\n    train_rates = dataset_info[\"metrics\"][\"train\"]\n    val_rates = dataset_info[\"metrics\"][\"val\"]\n    final_train_rate = train_rates[-1]\n    final_val_rate = val_rates[-1]\n    print(f\"training generation pass rate: {final_train_rate:.4f}\")\n    print(f\"validation generation pass rate: {final_val_rate:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Load the experiment data from the working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Iterate through the stored results\nfor model_name, model_data in experiment_data.items():\n    for dataset_name, dataset_data in model_data.items():\n        print(f\"Dataset: {dataset_name}\")\n        params = dataset_data[\"params\"]\n        train_metrics = dataset_data[\"metrics\"][\"train\"]\n        val_metrics = dataset_data[\"metrics\"][\"val\"]\n\n        # Print final epoch metrics for each learning rate\n        for lr, train_list, val_list in zip(params, train_metrics, val_metrics):\n            final_train = train_list[-1]\n            final_val = val_list[-1]\n            print(f\"Learning rate: {lr}\")\n            print(f\"Train accuracy: {final_train:.4f}\")\n            print(f\"Validation accuracy: {final_val:.4f}\")\n", "import os\nimport numpy as np\n\n# Load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through experiments and datasets\nfor exp_name, exp_dict in experiment_data.items():\n    for dataset_name, data in exp_dict.items():\n        print(f\"Dataset: {dataset_name}\")\n        conditions = data[\"conditions\"]\n        train_rates_list = data[\"metrics\"][\"train\"]\n        val_rates_list = data[\"metrics\"][\"val\"]\n        train_losses_list = data[\"losses\"][\"train\"]\n        val_losses_list = data[\"losses\"][\"val\"]\n\n        # Print final metrics for each condition\n        for condition, train_rates, val_rates, train_losses, val_losses in zip(\n            conditions,\n            train_rates_list,\n            val_rates_list,\n            train_losses_list,\n            val_losses_list,\n        ):\n            final_train_rate = train_rates[-1]\n            final_val_rate = val_rates[-1]\n            final_train_loss = train_losses[-1]\n            final_val_loss = val_losses[-1]\n\n            print(f\"{condition} train AICR pass rate: {final_train_rate:.4f}\")\n            print(f\"{condition} validation AICR pass rate: {final_val_rate:.4f}\")\n            print(f\"{condition} train loss: {final_train_loss:.4f}\")\n            print(f\"{condition} validation loss: {final_val_loss:.4f}\")\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Extract and print final metrics for each dataset\nfor dataset_name, dataset_info in experiment_data[\"output_vocab_scaling\"].items():\n    print(f\"Dataset: {dataset_name}\")\n    # Losses\n    final_train_loss = dataset_info[\"losses\"][\"train\"][-1]\n    final_validation_loss = dataset_info[\"losses\"][\"val\"][-1]\n    # AICR as accuracy\n    final_train_accuracy = dataset_info[\"metrics\"][\"AICR\"][\"train\"][-1]\n    final_validation_accuracy = dataset_info[\"metrics\"][\"AICR\"][\"val\"][-1]\n    # Mean iterations\n    final_train_mean_iterations = dataset_info[\"metrics\"][\"MeanIters\"][\"train\"][-1]\n    final_validation_mean_iterations = dataset_info[\"metrics\"][\"MeanIters\"][\"val\"][-1]\n\n    print(f\"final training loss: {final_train_loss:.4f}\")\n    print(f\"final validation loss: {final_validation_loss:.4f}\")\n    print(f\"train accuracy: {final_train_accuracy:.4f}\")\n    print(f\"validation accuracy: {final_validation_accuracy:.4f}\")\n    print(f\"train mean iterations: {final_train_mean_iterations:.4f}\")\n    print(f\"validation mean iterations: {final_validation_mean_iterations:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Locate the working directory and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract the synthetic label noise results\nsyn_data = experiment_data[\"label_noise\"][\"synthetic\"]\nnoise_levels = syn_data[\"noise_levels\"]\ntrain_losses_all = syn_data[\"losses\"][\"train\"]\nval_losses_all = syn_data[\"losses\"][\"val\"]\ntrain_accs_all = syn_data[\"metrics\"][\"train\"]\nval_accs_all = syn_data[\"metrics\"][\"val\"]\n\n# Print final metrics for each noise level\nfor idx, noise in enumerate(noise_levels):\n    dataset_name = \"synthetic\"\n    final_train_acc = train_accs_all[idx][-1]\n    final_val_acc = val_accs_all[idx][-1]\n    final_train_loss = train_losses_all[idx][-1]\n    final_val_loss = val_losses_all[idx][-1]\n\n    print(f\"Dataset: {dataset_name} (Noise level: {int(noise * 100)}%)\")\n    print(f\"Final train accuracy: {final_train_acc:.4f}\")\n    print(f\"Final validation accuracy: {final_val_acc:.4f}\")\n    print(f\"Final train loss: {final_train_loss:.4f}\")\n    print(f\"Final validation loss: {final_val_loss:.4f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under classification_head_depth\nsynthetic = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = synthetic[\"head_depths\"]\ntrain_losses = synthetic[\"losses\"][\"train\"]\nval_losses = synthetic[\"losses\"][\"val\"]\ntrain_accs = synthetic[\"classification_accuracy\"][\"train\"]\nval_accs = synthetic[\"classification_accuracy\"][\"val\"]\ntrain_rates = synthetic[\"metrics\"][\"train\"]\nval_rates = synthetic[\"metrics\"][\"val\"]\n\n# Print the final metrics\nprint(\"Dataset: synthetic\")\nfor idx, depth in enumerate(head_depths):\n    print(f\"\\nHead depth {depth}:\")\n    print(f\"train loss: {train_losses[idx][-1]:.4f}\")\n    print(f\"validation loss: {val_losses[idx][-1]:.4f}\")\n    print(f\"train accuracy: {train_accs[idx][-1]:.4f}\")\n    print(f\"validation accuracy: {val_accs[idx][-1]:.4f}\")\n    print(f\"train generation pass rate: {train_rates[idx][-1]:.4f}\")\n    print(f\"validation generation pass rate: {val_rates[idx][-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under classification_head_depth\nsynthetic = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = synthetic[\"head_depths\"]\ntrain_losses = synthetic[\"losses\"][\"train\"]\nval_losses = synthetic[\"losses\"][\"val\"]\ntrain_accs = synthetic[\"classification_accuracy\"][\"train\"]\nval_accs = synthetic[\"classification_accuracy\"][\"val\"]\ntrain_rates = synthetic[\"metrics\"][\"train\"]\nval_rates = synthetic[\"metrics\"][\"val\"]\n\n# Print the final metrics\nprint(\"Dataset: synthetic\")\nfor idx, depth in enumerate(head_depths):\n    print(f\"\\nHead depth {depth}:\")\n    print(f\"train loss: {train_losses[idx][-1]:.4f}\")\n    print(f\"validation loss: {val_losses[idx][-1]:.4f}\")\n    print(f\"train accuracy: {train_accs[idx][-1]:.4f}\")\n    print(f\"validation accuracy: {val_accs[idx][-1]:.4f}\")\n    print(f\"train generation pass rate: {train_rates[idx][-1]:.4f}\")\n    print(f\"validation generation pass rate: {val_rates[idx][-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Locate and load the saved experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Extract the synthetic dataset under classification_head_depth\nsynthetic = experiment_data[\"classification_head_depth\"][\"synthetic\"]\nhead_depths = synthetic[\"head_depths\"]\ntrain_losses = synthetic[\"losses\"][\"train\"]\nval_losses = synthetic[\"losses\"][\"val\"]\ntrain_accs = synthetic[\"classification_accuracy\"][\"train\"]\nval_accs = synthetic[\"classification_accuracy\"][\"val\"]\ntrain_rates = synthetic[\"metrics\"][\"train\"]\nval_rates = synthetic[\"metrics\"][\"val\"]\n\n# Print the final metrics\nprint(\"Dataset: synthetic\")\nfor idx, depth in enumerate(head_depths):\n    print(f\"\\nHead depth {depth}:\")\n    print(f\"train loss: {train_losses[idx][-1]:.4f}\")\n    print(f\"validation loss: {val_losses[idx][-1]:.4f}\")\n    print(f\"train accuracy: {train_accs[idx][-1]:.4f}\")\n    print(f\"validation accuracy: {val_accs[idx][-1]:.4f}\")\n    print(f\"train generation pass rate: {train_rates[idx][-1]:.4f}\")\n    print(f\"validation generation pass rate: {val_rates[idx][-1]:.4f}\")\n", ""], "parse_term_out": ["['Dataset: synthetic (learning rate = 0.001)', '\\n', 'Final training loss:\n0.7202', '\\n', 'Final validation loss: 0.6189', '\\n', 'Final training generation\nsuccess rate (AICR): 1.0000', '\\n', 'Final validation generation success rate\n(AICR): 1.0000\\n', '\\n', 'Dataset: synthetic (learning rate = 0.005)', '\\n',\n'Final training loss: 0.0289', '\\n', 'Final validation loss: 0.0233', '\\n',\n'Final training generation success rate (AICR): 1.0000', '\\n', 'Final validation\ngeneration success rate (AICR): 1.0000\\n', '\\n', 'Dataset: synthetic (learning\nrate = 0.01)', '\\n', 'Final training loss: 0.0049', '\\n', 'Final validation\nloss: 0.0043', '\\n', 'Final training generation success rate (AICR): 1.0000',\n'\\n', 'Final validation generation success rate (AICR): 1.0000\\n', '\\n',\n'Dataset: synthetic (learning rate = 0.02)', '\\n', 'Final training loss:\n0.0009', '\\n', 'Final validation loss: 0.0008', '\\n', 'Final training generation\nsuccess rate (AICR): 1.0000', '\\n', 'Final validation generation success rate\n(AICR): 1.0000\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Dataset: arithmetic', '\\n', 'train accuracy: 1.0000', '\\n', 'validation\naccuracy: 1.0000', '\\n', 'training loss: 0.0043', '\\n', 'validation loss:\n0.0039\\n', '\\n', 'Dataset: polynomial', '\\n', 'train accuracy: 1.0000', '\\n',\n'validation accuracy: 1.0000', '\\n', 'training loss: 0.0023', '\\n', 'validation\nloss: 0.0020\\n', '\\n', 'Dataset: bitwise', '\\n', 'train accuracy: 0.5850', '\\n',\n'validation accuracy: 0.5800', '\\n', 'training loss: 0.0061', '\\n', 'validation\nloss: 0.0052\\n', '\\n', 'Dataset: combined', '\\n', 'train accuracy: 0.8137',\n'\\n', 'validation accuracy: 0.8650', '\\n', 'training loss: 0.0148', '\\n',\n'validation loss: 0.0123\\n', '\\n', 'Execution time: a moment seconds (time limit\nis an hour).']", "['Dataset: synthetic (embedding_dim = 2)', '\\n', '  train accuracy: 1.0000',\n'\\n', '  validation accuracy: 1.0000', '\\n', '  train loss: 0.4350', '\\n', '\nvalidation loss: 0.3581', '\\n', '\\n', 'Dataset: synthetic (embedding_dim = 4)',\n'\\n', '  train accuracy: 1.0000', '\\n', '  validation accuracy: 1.0000', '\\n', '\ntrain loss: 0.0976', '\\n', '  validation loss: 0.0645', '\\n', '\\n', 'Dataset:\nsynthetic (embedding_dim = 8)', '\\n', '  train accuracy: 1.0000', '\\n', '\nvalidation accuracy: 1.0000', '\\n', '  train loss: 0.0170', '\\n', '  validation\nloss: 0.0136', '\\n', '\\n', 'Dataset: synthetic (embedding_dim = 16)', '\\n', '\ntrain accuracy: 1.0000', '\\n', '  validation accuracy: 1.0000', '\\n', '  train\nloss: 0.0054', '\\n', '  validation loss: 0.0047', '\\n', '\\n', 'Dataset:\nsynthetic (embedding_dim = 32)', '\\n', '  train accuracy: 1.0000', '\\n', '\nvalidation accuracy: 1.0000', '\\n', '  train loss: 0.0012', '\\n', '  validation\nloss: 0.0011', '\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Dataset: synthetic', '\\n', 'Batch size: 8', '\\n', '  Final training loss:\n0.0008', '\\n', '  Final validation loss: 0.0007', '\\n', '  Final train accuracy:\n1.0000', '\\n', '  Final validation accuracy: 1.0000', '\\n', 'Batch size: 16',\n'\\n', '  Final training loss: 0.0024', '\\n', '  Final validation loss: 0.0020',\n'\\n', '  Final train accuracy: 1.0000', '\\n', '  Final validation accuracy:\n1.0000', '\\n', 'Batch size: 32', '\\n', '  Final training loss: 0.0049', '\\n', '\nFinal validation loss: 0.0043', '\\n', '  Final train accuracy: 1.0000', '\\n', '\nFinal validation accuracy: 1.0000', '\\n', 'Batch size: 64', '\\n', '  Final\ntraining loss: 0.0131', '\\n', '  Final validation loss: 0.0108', '\\n', '  Final\ntrain accuracy: 1.0000', '\\n', '  Final validation accuracy: 1.0000', '\\n',\n'Batch size: 128', '\\n', '  Final training loss: 0.0616', '\\n', '  Final\nvalidation loss: 0.0475', '\\n', '  Final train accuracy: 1.0000', '\\n', '  Final\nvalidation accuracy: 1.0000', '\\n', 'Execution time: a moment seconds (time\nlimit is an hour).']", "['synthetic dataset:', '\\n', '  Optimizer: Adam', '\\n', '    train accuracy:\n1.0000', '\\n', '    validation accuracy: 1.0000', '\\n', '    train loss:\n0.0061', '\\n', '    validation loss: 0.0052', '\\n', '  Optimizer: SGD', '\\n', '\ntrain accuracy: 1.0000', '\\n', '    validation accuracy: 1.0000', '\\n', '\ntrain loss: 0.0115', '\\n', '    validation loss: 0.0106', '\\n', '  Optimizer:\nRMSprop', '\\n', '    train accuracy: 1.0000', '\\n', '    validation accuracy:\n1.0000', '\\n', '    train loss: 0.0014', '\\n', '    validation loss: 0.0012',\n'\\n', '  Optimizer: Adagrad', '\\n', '    train accuracy: 1.0000', '\\n', '\nvalidation accuracy: 1.0000', '\\n', '    train loss: 0.2337', '\\n', '\nvalidation loss: 0.2163', '\\n', '\\n', 'Execution time: a moment seconds (time\nlimit is an hour).']", "['Dataset: Synthetic', '\\n', '\\nDropout rate: 0.0', '\\n', '  training loss\n(final epoch): 0.0292', '\\n', '  validation loss (final epoch): 0.0236', '\\n', '\ntrain generation pass rate (final epoch): 1.0000', '\\n', '  validation\ngeneration pass rate (final epoch): 1.0000', '\\n', '\\nDropout rate: 0.2', '\\n',\n'  training loss (final epoch): 0.0432', '\\n', '  validation loss (final epoch):\n0.0218', '\\n', '  train generation pass rate (final epoch): 1.0000', '\\n', '\nvalidation generation pass rate (final epoch): 1.0000', '\\n', '\\nDropout rate:\n0.5', '\\n', '  training loss (final epoch): 0.0976', '\\n', '  validation loss\n(final epoch): 0.0149', '\\n', '  train generation pass rate (final epoch):\n1.0000', '\\n', '  validation generation pass rate (final epoch): 1.0000', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Weight decay = 0', '\\n', 'Dataset: synthetic', '\\n', 'Training loss: 0.0043',\n'\\n', 'Validation loss: 0.0039', '\\n', 'Training correctness rate: 1.0000',\n'\\n', 'Validation correctness rate: 1.0000', '\\n', '\\n', 'Weight decay = 1e-05',\n'\\n', 'Dataset: synthetic', '\\n', 'Training loss: 0.0053', '\\n', 'Validation\nloss: 0.0044', '\\n', 'Training correctness rate: 1.0000', '\\n', 'Validation\ncorrectness rate: 1.0000', '\\n', '\\n', 'Weight decay = 0.0001', '\\n', 'Dataset:\nsynthetic', '\\n', 'Training loss: 0.0050', '\\n', 'Validation loss: 0.0043',\n'\\n', 'Training correctness rate: 1.0000', '\\n', 'Validation correctness rate:\n1.0000', '\\n', '\\n', 'Weight decay = 0.001', '\\n', 'Dataset: synthetic', '\\n',\n'Training loss: 0.0104', '\\n', 'Validation loss: 0.0091', '\\n', 'Training\ncorrectness rate: 1.0000', '\\n', 'Validation correctness rate: 1.0000', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', '\\nHead depth 1:', '\\n', 'train loss: 0.0043',\n'\\n', 'validation loss: 0.0039', '\\n', 'train accuracy: 1.0000', '\\n',\n'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000', '\\n',\n'validation generation pass rate: 1.0000', '\\n', '\\nHead depth 2:', '\\n', 'train\nloss: 0.0006', '\\n', 'validation loss: 0.0005', '\\n', 'train accuracy: 1.0000',\n'\\n', 'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000',\n'\\n', 'validation generation pass rate: 1.0000', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', 'Dropout rate: 0.0', '\\n', '  Final training\naccuracy: 1.0000', '\\n', '  Final validation accuracy: 1.0000', '\\n', '  Final\ntraining loss: 0.0292', '\\n', '  Final validation loss: 0.0236', '\\n', 'Dropout\nrate: 0.2', '\\n', '  Final training accuracy: 1.0000', '\\n', '  Final validation\naccuracy: 1.0000', '\\n', '  Final training loss: 0.0425', '\\n', '  Final\nvalidation loss: 0.0213', '\\n', 'Dropout rate: 0.5', '\\n', '  Final training\naccuracy: 1.0000', '\\n', '  Final validation accuracy: 1.0000', '\\n', '  Final\ntraining loss: 0.0834', '\\n', '  Final validation loss: 0.0157', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', 'Batch size: 8', '\\n', '  final training loss:\n0.0008', '\\n', '  final validation loss: 0.0007', '\\n', '  final train accuracy:\n1.0000', '\\n', '  final validation accuracy: 1.0000', '\\n', '  final mean\ntraining iterations: 1.00', '\\n', '  final mean validation iterations: 1.00',\n'\\n', 'Batch size: 16', '\\n', '  final training loss: 0.0024', '\\n', '  final\nvalidation loss: 0.0020', '\\n', '  final train accuracy: 1.0000', '\\n', '  final\nvalidation accuracy: 1.0000', '\\n', '  final mean training iterations: 1.00',\n'\\n', '  final mean validation iterations: 1.00', '\\n', 'Batch size: 32', '\\n',\n'  final training loss: 0.0049', '\\n', '  final validation loss: 0.0043', '\\n',\n'  final train accuracy: 1.0000', '\\n', '  final validation accuracy: 1.0000',\n'\\n', '  final mean training iterations: 1.00', '\\n', '  final mean validation\niterations: 1.00', '\\n', 'Batch size: 64', '\\n', '  final training loss:\n0.0131', '\\n', '  final validation loss: 0.0108', '\\n', '  final train accuracy:\n1.0000', '\\n', '  final validation accuracy: 1.0000', '\\n', '  final mean\ntraining iterations: 1.00', '\\n', '  final mean validation iterations: 1.00',\n'\\n', 'Batch size: 128', '\\n', '  final training loss: 0.0616', '\\n', '  final\nvalidation loss: 0.0475', '\\n', '  final train accuracy: 1.0000', '\\n', '  final\nvalidation accuracy: 1.0000', '\\n', '  final mean training iterations: 1.00',\n'\\n', '  final mean validation iterations: 1.00', '\\n', '\\n', 'Execution time: a\nmoment seconds (time limit is an hour).']", "['Dataset: arithmetic', '\\n', 'Train accuracy: 1.0000', '\\n', 'Validation\naccuracy: 1.0000', '\\n', 'Train loss: 0.0043', '\\n', 'Validation loss:\n0.0039\\n', '\\n', 'Dataset: polynomial', '\\n', 'Train accuracy: 1.0000', '\\n',\n'Validation accuracy: 1.0000', '\\n', 'Train loss: 0.0023', '\\n', 'Validation\nloss: 0.0020\\n', '\\n', 'Dataset: bitwise', '\\n', 'Train accuracy: 0.5850', '\\n',\n'Validation accuracy: 0.5800', '\\n', 'Train loss: 0.0061', '\\n', 'Validation\nloss: 0.0052\\n', '\\n', 'Dataset: combined', '\\n', 'Train accuracy: 0.8137',\n'\\n', 'Validation accuracy: 0.8650', '\\n', 'Train loss: 0.0148', '\\n',\n'Validation loss: 0.0123\\n', '\\n', 'Execution time: a moment seconds (time limit\nis an hour).']", "['Dataset: synthetic', '\\n', 'Optimizer: Adam', '\\n', 'Training loss: 0.0061',\n'\\n', 'Validation loss: 0.0052', '\\n', 'Training accuracy: 1.0000', '\\n',\n'Validation accuracy: 1.0000', '\\n', 'Mean iterations to convergence (training):\n1.0000', '\\n', 'Mean iterations to convergence (validation): 1.0000', '\\n',\n'\\n', 'Optimizer: SGD', '\\n', 'Training loss: 0.0115', '\\n', 'Validation loss:\n0.0106', '\\n', 'Training accuracy: 1.0000', '\\n', 'Validation accuracy: 1.0000',\n'\\n', 'Mean iterations to convergence (training): 1.0000', '\\n', 'Mean\niterations to convergence (validation): 1.0000', '\\n', '\\n', 'Optimizer:\nRMSprop', '\\n', 'Training loss: 0.0014', '\\n', 'Validation loss: 0.0012', '\\n',\n'Training accuracy: 1.0000', '\\n', 'Validation accuracy: 1.0000', '\\n', 'Mean\niterations to convergence (training): 1.0000', '\\n', 'Mean iterations to\nconvergence (validation): 1.0000', '\\n', '\\n', 'Optimizer: Adagrad', '\\n',\n'Training loss: 0.2337', '\\n', 'Validation loss: 0.2163', '\\n', 'Training\naccuracy: 1.0000', '\\n', 'Validation accuracy: 1.0000', '\\n', 'Mean iterations\nto convergence (training): 1.0000', '\\n', 'Mean iterations to convergence\n(validation): 1.0000', '\\n', '\\n', 'Execution time: a moment seconds (time limit\nis an hour).']", "['Dataset: synthetic (label smoothing = 0.0)', '\\n', 'Final training loss:\n0.0061', '\\n', 'Final validation loss: 0.0052', '\\n', 'Final training generation\npass rate: 1.0000', '\\n', 'Final validation generation pass rate: 1.0000', '\\n',\n'\\n', 'Dataset: synthetic (label smoothing = 0.1)', '\\n', 'Final training loss:\n0.3488', '\\n', 'Final validation loss: 0.3488', '\\n', 'Final training generation\npass rate: 1.0000', '\\n', 'Final validation generation pass rate: 1.0000', '\\n',\n'\\n', 'Dataset: synthetic (label smoothing = 0.2)', '\\n', 'Final training loss:\n0.5875', '\\n', 'Final validation loss: 0.5875', '\\n', 'Final training generation\npass rate: 1.0000', '\\n', 'Final validation generation pass rate: 1.0000', '\\n',\n'\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', '\\nLabel smoothing = 0.0', '\\n', 'Final training\npass rate: 1.0000', '\\n', 'Final validation pass rate: 1.0000', '\\n', 'Final\ntraining loss: 0.0061', '\\n', 'Final validation loss: 0.0052', '\\n', 'Final mean\ntraining iterations: 1.00', '\\n', 'Final mean validation iterations: 1.00',\n'\\n', '\\nLabel smoothing = 0.1', '\\n', 'Final training pass rate: 1.0000', '\\n',\n'Final validation pass rate: 1.0000', '\\n', 'Final training loss: 0.3488', '\\n',\n'Final validation loss: 0.3488', '\\n', 'Final mean training iterations: 1.00',\n'\\n', 'Final mean validation iterations: 1.00', '\\n', '\\nLabel smoothing = 0.2',\n'\\n', 'Final training pass rate: 1.0000', '\\n', 'Final validation pass rate:\n1.0000', '\\n', 'Final training loss: 0.5875', '\\n', 'Final validation loss:\n0.5875', '\\n', 'Final mean training iterations: 1.00', '\\n', 'Final mean\nvalidation iterations: 1.00', '\\n', 'Execution time: a moment seconds (time\nlimit is an hour).']", "['Dataset: ops_4', '\\n', 'training loss: 0.0043', '\\n', 'validation loss:\n0.0039', '\\n', 'training generation pass rate: 1.0000', '\\n', 'validation\ngeneration pass rate: 1.0000\\n', '\\n', 'Dataset: ops_8', '\\n', 'training loss:\n0.0122', '\\n', 'validation loss: 0.0099', '\\n', 'training generation pass rate:\n0.7388', '\\n', 'validation generation pass rate: 0.7300\\n', '\\n', 'Dataset:\nops_16', '\\n', 'training loss: 0.0218', '\\n', 'validation loss: 0.0175', '\\n',\n'training generation pass rate: 0.7450', '\\n', 'validation generation pass rate:\n0.7800\\n', '\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', 'Learning rate: 0.001', '\\n', 'Train accuracy:\n1.0000', '\\n', 'Validation accuracy: 1.0000', '\\n', 'Learning rate: 0.005',\n'\\n', 'Train accuracy: 1.0000', '\\n', 'Validation accuracy: 1.0000', '\\n',\n'Learning rate: 0.01', '\\n', 'Train accuracy: 1.0000', '\\n', 'Validation\naccuracy: 1.0000', '\\n', 'Learning rate: 0.02', '\\n', 'Train accuracy: 1.0000',\n'\\n', 'Validation accuracy: 1.0000', '\\n', 'Execution time: a moment seconds\n(time limit is an hour).']", "['Dataset: synthetic', '\\n', 'untied train AICR pass rate: 1.0000', '\\n',\n'untied validation AICR pass rate: 1.0000', '\\n', 'untied train loss: 0.0061',\n'\\n', 'untied validation loss: 0.0052', '\\n', 'tied train AICR pass rate:\n1.0000', '\\n', 'tied validation AICR pass rate: 1.0000', '\\n', 'tied train loss:\n0.0000', '\\n', 'tied validation loss: 0.0000', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset: ops_4', '\\n', 'final training loss: 0.0043', '\\n', 'final validation\nloss: 0.0039', '\\n', 'train accuracy: 1.0000', '\\n', 'validation accuracy:\n1.0000', '\\n', 'train mean iterations: 1.0000', '\\n', 'validation mean\niterations: 1.0000', '\\n', '\\n', 'Dataset: ops_8', '\\n', 'final training loss:\n0.0122', '\\n', 'final validation loss: 0.0099', '\\n', 'train accuracy: 0.7388',\n'\\n', 'validation accuracy: 0.7300', '\\n', 'train mean iterations: 1.0000',\n'\\n', 'validation mean iterations: 1.0000', '\\n', '\\n', 'Dataset: ops_16', '\\n',\n'final training loss: 0.0218', '\\n', 'final validation loss: 0.0175', '\\n',\n'train accuracy: 0.7450', '\\n', 'validation accuracy: 0.7800', '\\n', 'train mean\niterations: 1.0000', '\\n', 'validation mean iterations: 1.0000', '\\n', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: synthetic (Noise level: 10%)', '\\n', 'Final train accuracy: 1.0000',\n'\\n', 'Final validation accuracy: 1.0000', '\\n', 'Final train loss: 0.4362',\n'\\n', 'Final validation loss: 0.0994', '\\n', 'Dataset: synthetic (Noise level:\n20%)', '\\n', 'Final train accuracy: 1.0000', '\\n', 'Final validation accuracy:\n1.0000', '\\n', 'Final train loss: 0.7231', '\\n', 'Final validation loss:\n0.2169', '\\n', 'Dataset: synthetic (Noise level: 30%)', '\\n', 'Final train\naccuracy: 1.0000', '\\n', 'Final validation accuracy: 1.0000', '\\n', 'Final train\nloss: 0.9517', '\\n', 'Final validation loss: 0.3653', '\\n', 'Execution time: a\nmoment seconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', '\\nHead depth 1:', '\\n', 'train loss: 0.0043',\n'\\n', 'validation loss: 0.0039', '\\n', 'train accuracy: 1.0000', '\\n',\n'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000', '\\n',\n'validation generation pass rate: 1.0000', '\\n', '\\nHead depth 2:', '\\n', 'train\nloss: 0.0006', '\\n', 'validation loss: 0.0005', '\\n', 'train accuracy: 1.0000',\n'\\n', 'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000',\n'\\n', 'validation generation pass rate: 1.0000', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', '\\nHead depth 1:', '\\n', 'train loss: 0.0043',\n'\\n', 'validation loss: 0.0039', '\\n', 'train accuracy: 1.0000', '\\n',\n'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000', '\\n',\n'validation generation pass rate: 1.0000', '\\n', '\\nHead depth 2:', '\\n', 'train\nloss: 0.0006', '\\n', 'validation loss: 0.0005', '\\n', 'train accuracy: 1.0000',\n'\\n', 'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000',\n'\\n', 'validation generation pass rate: 1.0000', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset: synthetic', '\\n', '\\nHead depth 1:', '\\n', 'train loss: 0.0043',\n'\\n', 'validation loss: 0.0039', '\\n', 'train accuracy: 1.0000', '\\n',\n'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000', '\\n',\n'validation generation pass rate: 1.0000', '\\n', '\\nHead depth 2:', '\\n', 'train\nloss: 0.0006', '\\n', 'validation loss: 0.0005', '\\n', 'train accuracy: 1.0000',\n'\\n', 'validation accuracy: 1.0000', '\\n', 'train generation pass rate: 1.0000',\n'\\n', 'validation generation pass rate: 1.0000', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"], "current_stage": "Stage_4"};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
