\begin{thebibliography}{10}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Austin et~al.(2021)Austin, Odena, Nye, Bosma, Michalewski, Dohan,
  Jiang, Cai, Terry, Le, and Sutton]{austin2021programsw}
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, H.~Michalewski, David
  Dohan, Ellen Jiang, Carrie~J. Cai, Michael Terry, Quoc~V. Le, and Charles
  Sutton.
\newblock Program synthesis with large language models.
\newblock \emph{ArXiv}, abs/2108.07732, 2021.

\bibitem[Bj{\o}rner et~al.(2008)Bj{\o}rner, Moura, and
  Tillmann]{bjrner2008satisfiabilitymb}
Nikolaj~S. Bj{\o}rner, L.~D. Moura, and N.~Tillmann.
\newblock Satisfiability modulo bit-precise theories for program exploration.
\newblock 2008.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pond{\'e}, Kaplan, Edwards,
  Burda, Joseph, Brockman, Ray, Puri, Krueger, Petrov, Khlaaf, Sastry, Mishkin,
  Chan, Gray, Ryder, Pavlov, Power, Kaiser, Bavarian, Winter, Tillet, Such,
  Cummings, Plappert, Chantzis, Barnes, Herbert-Voss, Guss, Nichol, Babuschkin,
  Balaji, Jain, Carr, Leike, Achiam, Misra, Morikawa, Radford, Knight,
  Brundage, Murati, Mayer, Welinder, McGrew, Amodei, McCandlish, Sutskever, and
  Zaremba]{chen2021evaluatingll}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond{\'e}, Jared
  Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex
  Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish
  Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
  Alethea Power, Lukasz Kaiser, Mo~Bavarian, Clemens Winter, Phil Tillet,
  F.~Such, D.~Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes,
  Ariel Herbert-Voss, William~H. Guss, Alex Nichol, Igor Babuschkin, S.~Balaji,
  Shantanu Jain, A.~Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,
  Alec Radford, M.~Knight, Miles Brundage, Mira Murati, Katie Mayer,
  P.~Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, I.~Sutskever, and
  Wojciech Zaremba.
\newblock Evaluating large language models trained on code.
\newblock \emph{ArXiv}, abs/2107.03374, 2021.

\bibitem[Cousot \& Cousot()Cousot and Cousot]{none}
P.~Cousot and R.~Cousot.
\newblock Interpretation : ‘a unified lattice model for static analysis of
  programs by construction or approximation.

\bibitem[de~la Rosa \& Fernandez(2022)de~la Rosa and
  Fernandez]{rosa2022zeroshotrc}
Javier~Casas de~la Rosa and A.~Fernandez.
\newblock Zero-shot reading comprehension and reasoning for spanish with bertin
  gpt-j-6b.
\newblock 2022.

\bibitem[Ernst et~al.(2007)Ernst, Perkins, Guo, McCamant, Pacheco, Tschantz,
  and Xiao]{ernst2007theds}
Michael~D. Ernst, J.~Perkins, Philip~J. Guo, Stephen McCamant, Carlos Pacheco,
  Matthew~S. Tschantz, and Chen Xiao.
\newblock The daikon system for dynamic detection of likely invariants.
\newblock \emph{Sci. Comput. Program.}, 69:\penalty0 35--45, 2007.

\bibitem[Iyer(2019)]{iyer2019learningtm}
Srini Iyer.
\newblock Learning to map natural language to general purpose source code.
\newblock 2019.

\bibitem[Lehtosalo \& Greaves(2011)Lehtosalo and
  Greaves]{lehtosalo2011languagewa}
J.~Lehtosalo and D.~Greaves.
\newblock Language with a pluggable type system and optional runtime monitoring
  of type errors.
\newblock 2011.

\bibitem[Schick \& Schütze(2020)Schick and Schütze]{schick2020itsnj}
Timo Schick and Hinrich Schütze.
\newblock It’s not just size that matters: Small language models are also
  few-shot learners.
\newblock \emph{ArXiv}, abs/2009.07118, 2020.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Chi, Xia, Le, and
  Zhou]{wei2022chainot}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed~H. Chi, F.~Xia, Quoc
  Le, and Denny Zhou.
\newblock Chain of thought prompting elicits reasoning in large language
  models.
\newblock \emph{ArXiv}, abs/2201.11903, 2022.

\end{thebibliography}
