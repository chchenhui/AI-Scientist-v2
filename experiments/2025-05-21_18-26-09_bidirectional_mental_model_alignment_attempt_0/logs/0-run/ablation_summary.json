[
  {
    "overall_plan": "Ablation name: Linear-Probe Classifier (No Hidden Layer).\nBelow is a script that runs both the original two-layer MLP (\u201cbaseline\u201d) and a single\u2010layer linear probe (\u201clinear_probe\u201d) on top of frozen DistilBERT embeddings across three datasets. It collects train/validation losses, accuracies (\u201cmetrics\u201d), alignments, MAI, and final predictions, stores everything in a nested dictionary keyed by ablation and dataset, converts lists to NumPy arrays, and saves the result as `experiment_data.npy` in the `working` directory.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train accuracy",
            "lower_is_better": false,
            "description": "Proportion of correct predictions on the training set",
            "data": [
              {
                "dataset_name": "ag_news (baseline)",
                "final_value": 0.878,
                "best_value": 0.878
              },
              {
                "dataset_name": "ag_news (linear_probe)",
                "final_value": 0.873,
                "best_value": 0.873
              },
              {
                "dataset_name": "yelp_polarity (baseline)",
                "final_value": 0.8635,
                "best_value": 0.8635
              },
              {
                "dataset_name": "yelp_polarity (linear_probe)",
                "final_value": 0.8385,
                "best_value": 0.8385
              },
              {
                "dataset_name": "dbpedia_14 (baseline)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "dbpedia_14 (linear_probe)",
                "final_value": 0.9685,
                "best_value": 0.9685
              }
            ]
          },
          {
            "metric_name": "validation accuracy",
            "lower_is_better": false,
            "description": "Proportion of correct predictions on the validation set",
            "data": [
              {
                "dataset_name": "ag_news (baseline)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "ag_news (linear_probe)",
                "final_value": 0.882,
                "best_value": 0.882
              },
              {
                "dataset_name": "yelp_polarity (baseline)",
                "final_value": 0.826,
                "best_value": 0.826
              },
              {
                "dataset_name": "yelp_polarity (linear_probe)",
                "final_value": 0.834,
                "best_value": 0.834
              },
              {
                "dataset_name": "dbpedia_14 (baseline)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "dbpedia_14 (linear_probe)",
                "final_value": 0.968,
                "best_value": 0.968
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# load tokenizer & model\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# classifier definitions\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# ablations\nablation_types = [\"baseline\", \"linear_probe\"]\nexperiment_data = {}\n\nfor ablation in ablation_types:\n    experiment_data[ablation] = {}\n    for name in [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]:\n        # load & tokenize\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        num_labels = len(set(train_ds[\"label\"]))\n        in_dim = distilbert.config.hidden_size\n\n        # instantiate models\n        if ablation == \"baseline\":\n            ai_model = MLP(in_dim, 128, num_labels).to(device)\n            user_model = MLP(in_dim, 128, num_labels).to(device)\n        else:\n            ai_model = nn.Linear(in_dim, num_labels).to(device)\n            user_model = nn.Linear(in_dim, num_labels).to(device)\n\n        optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n        loss_fn = nn.CrossEntropyLoss()\n\n        # storage\n        experiment_data[ablation][name] = {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_acc = n = 0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                optimizer_ai.zero_grad()\n                loss_ai.backward()\n                optimizer_ai.step()\n                optimizer_user.zero_grad()\n                loss_user.backward()\n                optimizer_user.step()\n\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (\n                    (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n                )\n                n += bs\n\n            train_loss = tot_loss / len(train_ds)\n            train_align = tot_align / n\n            train_acc = tot_acc / n\n            ed = experiment_data[ablation][name]\n            ed[\"losses\"][\"train\"].append(train_loss)\n            ed[\"alignments\"][\"train\"].append(train_align)\n            ed[\"metrics\"][\"train\"].append(train_acc)\n\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            ed[\"losses\"][\"val\"].append(val_loss)\n            ed[\"alignments\"][\"val\"].append(val_align)\n            ed[\"metrics\"][\"val\"].append(val_acc)\n            ed[\"mai\"].append(mai)\n            print(\n                f\"Ablation {ablation} Dataset {name} Epoch {epoch}: val_loss = {val_loss:.4f}, MAI = {mai:.4f}\"\n            )\n\n        # collect final predictions\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        ed[\"predictions\"] = np.concatenate(preds)\n        ed[\"ground_truth\"] = np.concatenate(gts)\n\n# convert lists to numpy arrays\nfor ablation in experiment_data:\n    for ds in experiment_data[ablation]:\n        d = experiment_data[ablation][ds]\n        for key in [\"metrics\", \"losses\", \"alignments\"]:\n            for split in [\"train\", \"val\"]:\n                d[key][split] = np.array(d[key][split])\n        d[\"mai\"] = np.array(d[\"mai\"])\n\n# save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# Plot combined accuracy and loss curves for each dataset\nfor ds in experiment_data.get(\"baseline\", {}):\n    try:\n        epochs = np.arange(\n            1, len(experiment_data[\"baseline\"][ds][\"metrics\"][\"train\"]) + 1\n        )\n        plt.figure(figsize=(10, 5))\n        # Accuracy subplot\n        plt.subplot(1, 2, 1)\n        for ab in experiment_data:\n            tr = experiment_data[ab][ds][\"metrics\"][\"train\"]\n            val = experiment_data[ab][ds][\"metrics\"][\"val\"]\n            plt.plot(epochs, tr, marker=\"o\", label=f\"{ab} Train\")\n            plt.plot(epochs, val, marker=\"x\", linestyle=\"--\", label=f\"{ab} Val\")\n        plt.title(f\"{ds} Accuracy Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.legend()\n        # Loss subplot\n        plt.subplot(1, 2, 2)\n        for ab in experiment_data:\n            tr = experiment_data[ab][ds][\"losses\"][\"train\"]\n            val = experiment_data[ab][ds][\"losses\"][\"val\"]\n            plt.plot(epochs, tr, marker=\"o\", label=f\"{ab} Train\")\n            plt.plot(epochs, val, marker=\"x\", linestyle=\"--\", label=f\"{ab} Val\")\n        plt.title(f\"{ds} Loss Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.suptitle(f\"Dataset: {ds} - Baseline vs Linear Probe\")\n        fname = os.path.join(working_dir, f\"{ds}_acc_loss_curves.png\")\n        plt.savefig(fname)\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating plot_{ds}_curves: {e}\")\n        plt.close()\n\n# Plot bar chart of final validation accuracy by ablation and dataset\ntry:\n    ds_list = list(experiment_data.get(\"baseline\", {}))\n    x = np.arange(len(ds_list))\n    width = 0.35\n    base_vals = [experiment_data[\"baseline\"][d][\"metrics\"][\"val\"][-1] for d in ds_list]\n    lin_vals = [\n        experiment_data[\"linear_probe\"][d][\"metrics\"][\"val\"][-1] for d in ds_list\n    ]\n    plt.figure()\n    plt.bar(x - width / 2, base_vals, width, label=\"Baseline\")\n    plt.bar(x + width / 2, lin_vals, width, label=\"Linear Probe\")\n    plt.xticks(x, ds_list)\n    plt.ylabel(\"Final Validation Accuracy\")\n    plt.title(\"Final Validation Accuracy by Dataset and Ablation\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"final_val_accuracy_bar.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating final_val_accuracy_bar plot: {e}\")\n    plt.close()\n",
    "plot_plan": "I will load the saved experiment data from the working directory, then iterate over each dataset (ag_news, yelp_polarity, dbpedia_14) to plot side-by-side subplots of training vs validation accuracy and loss, overlaying both ablation types (baseline and linear_probe). Each figure is wrapped in a try-except block to catch and report errors, and explicitly closed after saving to avoid resource leaks. Finally, I will assemble a bar chart comparing the final validation accuracy of both ablations across all datasets in another try-except block. All plots are saved with descriptive filenames into the working directory.",
    "plot_analyses": [
      {
        "analysis": "Dataset: yelp_polarity - Baseline fine-tuning achieves faster loss reduction and higher training accuracy (from ~0.63 to ~0.86) compared to the linear probe (from ~0.71 to ~0.84). Validation accuracy for the linear probe starts slightly above the baseline at epoch 1 (~0.84 vs ~0.83) and remains marginally higher at epoch 3 (~0.83 vs ~0.82), but both converge by epoch 2 with only ~1% difference. Baseline validation loss is consistently lower, indicating stronger generalization despite the slightly lower early validation accuracy.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/yelp_polarity_acc_loss_curves.png"
      },
      {
        "analysis": "Dataset: ag_news - Both methods converge by epoch 2 with validation accuracy near 0.88\u20130.89. Baseline fine-tuning yields lower training and validation losses throughout (e.g., val loss dropping from ~0.48 to ~0.33) and marginally higher validation accuracy at epochs 1 and 2 (~0.87 vs ~0.86; ~0.88 vs ~0.87). The linear probe catches up by epoch 3, ending with nearly identical validation accuracy (~0.89) but still retains somewhat higher loss values, signalling slower adaptation.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/ag_news_acc_loss_curves.png"
      },
      {
        "analysis": "Dataset: dbpedia_14 - Validation accuracy for the linear probe is slightly higher in early epochs (~0.93 vs ~0.915 at epoch 1; ~0.96 vs ~0.955 at epoch 2) but baseline overtakes by epoch 3 (~0.97 vs ~0.967). Training and validation losses are consistently lower for the baseline (train loss from ~2.7\u21920.22 vs ~2.6\u21920.40; val loss from ~0.78\u21920.17 vs ~1.1\u21920.35), showing more efficient convergence and stronger fine-tuning on this larger classification task.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/dbpedia_14_acc_loss_curves.png"
      },
      {
        "analysis": "Final Validation Accuracy by Dataset and Ablation - ag_news: linear probe edges baseline by ~1% (0.88 vs 0.87); yelp_polarity: linear probe higher by ~1% (0.84 vs 0.83); dbpedia_14: baseline higher by ~1% (0.98 vs 0.97). These differences are within 1% across all tasks, indicating that the lighter-weight linear probe remains competitive, while full fine-tuning consistently yields more robust loss reduction and slightly better performance on the largest dataset.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/final_val_accuracy_bar.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/yelp_polarity_acc_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/ag_news_acc_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/dbpedia_14_acc_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/final_val_accuracy_bar.png"
    ],
    "vlm_feedback_summary": "Ablation between full fine-tuning and a linear probe shows that both reach similar final validation accuracy within a 1% margin across three text classification datasets. Full fine-tuning yields faster and stronger loss reduction and higher training accuracy, whereas the linear probe occasionally outperforms in early validation accuracy on two datasets. All curves saturate by epoch 2, suggesting rapid convergence for both approaches.",
    "exp_results_dir": "experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279",
    "ablation_name": "Linear-Probe Classifier (No Hidden Layer)",
    "exp_results_npy_files": [
      "experiment_results/experiment_9529c89532744f2795767a760cae81c1_proc_4081279/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: MLP Dropout Rate Ablation.\nWe will extend the baseline by adding a Dropout layer in the MLP head parameterized by dropout probability, and sweep over the set {0.0, 0.1, 0.3, 0.5}. For each dropout rate and each dataset, we train ai_model and user_model for 3 epochs on DistilBERT embeddings, record training/validation losses, JSD\u2010based alignments, and the MAI metric per epoch, and finally collect predictions and ground truths. All results are stored in a nested `experiment_data` dictionary under `\"mlp_dropout_rate_ablation\"`, keyed by dropout rate and dataset name, then saved to `experiment_data.npy`. Below is the complete self-contained Python script.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Model training loss at final epoch",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.3793,
                "best_value": 0.3793
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.3623,
                "best_value": 0.3623
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.2447,
                "best_value": 0.2447
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.4064,
                "best_value": 0.4064
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.347,
                "best_value": 0.347
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.3411,
                "best_value": 0.3411
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.4706,
                "best_value": 0.4706
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.4231,
                "best_value": 0.4231
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.5765,
                "best_value": 0.5765
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Model validation loss at final epoch",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.3426,
                "best_value": 0.3426
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.3469,
                "best_value": 0.3469
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.1857,
                "best_value": 0.1857
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.3356,
                "best_value": 0.3356
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.3402,
                "best_value": 0.3402
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.2077,
                "best_value": 0.2077
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.3501,
                "best_value": 0.3501
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.3614,
                "best_value": 0.3614
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.3048,
                "best_value": 0.3048
              }
            ]
          },
          {
            "metric_name": "training alignment",
            "lower_is_better": false,
            "description": "Training alignment metric at final epoch",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.9884,
                "best_value": 0.9884
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.9883,
                "best_value": 0.9883
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.9819,
                "best_value": 0.9819
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.9743,
                "best_value": 0.9743
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.9792,
                "best_value": 0.9792
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.9577,
                "best_value": 0.9577
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.9528,
                "best_value": 0.9528
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.9761,
                "best_value": 0.9761
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.9086,
                "best_value": 0.9086
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Validation alignment metric at final epoch",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.9972,
                "best_value": 0.9972
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.9987,
                "best_value": 0.9987
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.9958,
                "best_value": 0.9958
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.9956,
                "best_value": 0.9956
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.9974,
                "best_value": 0.9974
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.9983,
                "best_value": 0.9983
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.9929,
                "best_value": 0.9929
              }
            ]
          },
          {
            "metric_name": "MAI",
            "lower_is_better": false,
            "description": "Mutual alignment index at final epoch",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.9416,
                "best_value": 0.9416
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.9246,
                "best_value": 0.9246
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.9865,
                "best_value": 0.9865
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.939,
                "best_value": 0.939
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.9253,
                "best_value": 0.9253
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.9827,
                "best_value": 0.9827
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.9361,
                "best_value": 0.9361
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.9298,
                "best_value": 0.9298
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.9813,
                "best_value": 0.9813
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "Test set accuracy",
            "data": [
              {
                "dataset_name": "ag_news (dropout=0.0)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.0)",
                "final_value": 0.824,
                "best_value": 0.824
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.0)",
                "final_value": 0.972,
                "best_value": 0.972
              },
              {
                "dataset_name": "ag_news (dropout=0.1)",
                "final_value": 0.888,
                "best_value": 0.888
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.1)",
                "final_value": 0.854,
                "best_value": 0.854
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.1)",
                "final_value": 0.976,
                "best_value": 0.976
              },
              {
                "dataset_name": "ag_news (dropout=0.3)",
                "final_value": 0.894,
                "best_value": 0.894
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.3)",
                "final_value": 0.864,
                "best_value": 0.864
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.3)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (dropout=0.5)",
                "final_value": 0.88,
                "best_value": 0.88
              },
              {
                "dataset_name": "yelp_polarity (dropout=0.5)",
                "final_value": 0.854,
                "best_value": 0.854
              },
              {
                "dataset_name": "dbpedia_14 (dropout=0.5)",
                "final_value": 0.964,
                "best_value": 0.964
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# Setup environment\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load tokenizer and frozen DistilBERT\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# MLP head with configurable dropout\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim, drop_p):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.dropout = nn.Dropout(drop_p)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\n\n# Ablation settings\ndropout_probs = [0.0, 0.1, 0.3, 0.5]\ndatasets_list = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\n\n# Container for all results\nexperiment_data = {\"mlp_dropout_rate_ablation\": {}}\n\n# Main loop over dropout rates and datasets\nfor p in dropout_probs:\n    key = f\"drop_{p}\"\n    experiment_data[\"mlp_dropout_rate_ablation\"][key] = {}\n    for name in datasets_list:\n        # Prepare and tokenize\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n\n        # Initialize models, optimizers, loss\n        num_labels = len(set(train_ds[\"label\"]))\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels, p).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels, p).to(device)\n        optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n        loss_fn = nn.CrossEntropyLoss()\n\n        # Storage for this configuration\n        store = {\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n        experiment_data[\"mlp_dropout_rate_ablation\"][key][name] = store\n\n        # Training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss, tot_align, n = 0.0, 0.0, 0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                optimizer_ai.zero_grad()\n                loss_ai.backward()\n                optimizer_ai.step()\n                optimizer_user.zero_grad()\n                loss_user.backward()\n                optimizer_user.step()\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                n += bs\n            train_loss = tot_loss / len(train_ds)\n            train_align = tot_align / n\n            store[\"losses\"][\"train\"].append(train_loss)\n            store[\"alignments\"][\"train\"].append(train_align)\n\n            # Validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss, v_align, v_acc, v_n = 0.0, 0.0, 0, 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    logits_user = user_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(logits_user, dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(logits_user, dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            store[\"losses\"][\"val\"].append(val_loss)\n            store[\"alignments\"][\"val\"].append(val_align)\n            store[\"mai\"].append(mai)\n            print(\n                f\"Dropout {p}, Dataset {name}, Epoch {epoch}: val_loss={val_loss:.4f}, MAI={mai:.4f}\"\n            )\n\n        # Final predictions and ground truth\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        store[\"predictions\"] = np.concatenate(preds)\n        store[\"ground_truth\"] = np.concatenate(gts)\n\n# Save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\ndrops = list(experiment_data.get(\"mlp_dropout_rate_ablation\", {}).keys())\nif drops:\n    ds_names = list(experiment_data[\"mlp_dropout_rate_ablation\"][drops[0]].keys())\n    for ds in ds_names:\n        # Plot loss curves\n        try:\n            fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n            for dk in drops:\n                p = dk.split(\"_\", 1)[1]\n                train = experiment_data[\"mlp_dropout_rate_ablation\"][dk][ds][\"losses\"][\n                    \"train\"\n                ]\n                val = experiment_data[\"mlp_dropout_rate_ablation\"][dk][ds][\"losses\"][\n                    \"val\"\n                ]\n                axs[0].plot(range(1, len(train) + 1), train, label=f\"drop {p}\")\n                axs[1].plot(range(1, len(val) + 1), val, label=f\"drop {p}\")\n            fig.suptitle(\n                f\"Loss Curves on {ds}\\nLeft: Training Loss, Right: Validation Loss\"\n            )\n            axs[0].set_title(\"Training Loss\")\n            axs[1].set_title(\"Validation Loss\")\n            axs[0].set_xlabel(\"Epoch\")\n            axs[1].set_xlabel(\"Epoch\")\n            axs[0].set_ylabel(\"Loss\")\n            axs[1].set_ylabel(\"Loss\")\n            axs[0].legend()\n            axs[1].legend()\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            plt.savefig(os.path.join(working_dir, f\"{ds}_loss_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {ds}: {e}\")\n            plt.close()\n        # Plot alignment curves\n        try:\n            fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n            for dk in drops:\n                p = dk.split(\"_\", 1)[1]\n                tr = experiment_data[\"mlp_dropout_rate_ablation\"][dk][ds][\"alignments\"][\n                    \"train\"\n                ]\n                va = experiment_data[\"mlp_dropout_rate_ablation\"][dk][ds][\"alignments\"][\n                    \"val\"\n                ]\n                axs[0].plot(range(1, len(tr) + 1), tr, label=f\"drop {p}\")\n                axs[1].plot(range(1, len(va) + 1), va, label=f\"drop {p}\")\n            fig.suptitle(\n                f\"Alignment Curves on {ds}\\nLeft: Training Alignment, Right: Validation Alignment\"\n            )\n            axs[0].set_title(\"Training Alignment\")\n            axs[1].set_title(\"Validation Alignment\")\n            axs[0].set_xlabel(\"Epoch\")\n            axs[1].set_xlabel(\"Epoch\")\n            axs[0].set_ylabel(\"Alignment\")\n            axs[1].set_ylabel(\"Alignment\")\n            axs[0].legend()\n            axs[1].legend()\n            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n            plt.savefig(os.path.join(working_dir, f\"{ds}_alignment_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating alignment plot for {ds}: {e}\")\n            plt.close()\n        # Plot MAI curves\n        try:\n            plt.figure(figsize=(6, 4))\n            for dk in drops:\n                p = dk.split(\"_\", 1)[1]\n                mai = experiment_data[\"mlp_dropout_rate_ablation\"][dk][ds][\"mai\"]\n                plt.plot(range(1, len(mai) + 1), mai, label=f\"drop {p}\")\n            plt.title(f\"MAI Curves on {ds}\\nMAI across Epochs\")\n            plt.xlabel(\"Epoch\")\n            plt.ylabel(\"MAI\")\n            plt.legend()\n            plt.tight_layout()\n            plt.savefig(os.path.join(working_dir, f\"{ds}_mai_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating MAI plot for {ds}: {e}\")\n            plt.close()\n",
    "plot_plan": "We load the saved experiment data, extract the dropout keys and dataset names, and then iterate over each dataset. For each dataset we create three plots wrapped in independent try-except blocks: (1) loss curves with left subplot showing training loss and right showing validation loss, (2) alignment curves similarly split, and (3) MAI curves across epochs. Each figure\u2019s title includes the dataset name and a clear subtitle describing its subplots, and legends differentiate dropout rates. We save each figure to the working directory with descriptive filenames containing both the dataset and plot type. After each save or on error, we close the figure to free resources. Any loading or plotting error is printed to the console.",
    "plot_analyses": [
      {
        "analysis": "Loss Curves on dbpedia_14 (Training & Validation Loss): All models show rapid loss reduction by epoch 2 and further improvement into epoch 3. Zero and light (0.1) dropout achieve the lowest training and validation losses, with nearly identical curves. Moderate dropout (0.3) slows convergence slightly and yields higher losses at each epoch. Heavy dropout (0.5) exhibits the slowest convergence and highest losses, particularly noticeable at epoch 1 (training loss ~3.4, validation ~1.23) and remains above other settings through epoch 3. Little to no overfitting is observed, but heavy dropout underperforms across both splits.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_loss_curves.png"
      },
      {
        "analysis": "Loss Curves on ag_news (Training & Validation Loss): All variants follow a steep decline from epoch 1 to 2, then plateau. Dropout 0.1 yields the lowest training loss at epoch 3, slightly below no-dropout, while dropout 0.5 again shows the highest training loss. On validation, dropout 0.3 reaches the lowest loss by epoch 3 (~0.35), outperforming both no-dropout and light dropout. Heavy dropout remains suboptimal. These patterns suggest moderate dropout can improve generalization for ag_news.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_loss_curves.png"
      },
      {
        "analysis": "Alignment Curves on yelp_polarity (Training & Validation Alignment): Training alignment climbs for all settings, with no-dropout reaching near-perfect alignment fastest. Increasing dropout consistently lowers training alignment at each epoch. In validation, alignment is uniformly high (>0.99). No-dropout and 0.1 are essentially tied at the top; dropout 0.3 lags behind and dropout 0.5 recovers somewhat but still trails light settings. Overall, dropout reduces alignment effectiveness, with heavier rates having a stronger negative effect.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_alignment_curves.png"
      },
      {
        "analysis": "Alignment Curves on dbpedia_14 (Training & Validation Alignment): Zero dropout yields the highest training alignment growth (from ~0.97 to ~0.997), followed by 0.1, 0.3, and 0.5 in descending order. Validation alignment similarly ranks settings: no-dropout highest, then 0.1, then 0.3, then 0.5. All settings improve over epochs, but alignment capacity degrades progressively as dropout rate increases, indicating dropout undermines the model\u2019s ability to align predictions with the inferred user model.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_alignment_curves.png"
      },
      {
        "analysis": "MAI Curves on dbpedia_14: Mutual alignment index improves sharply from epoch 1 to 2 for all settings, then plateaus. No-dropout achieves the highest MAI at each epoch. Light and moderate dropout show slightly lower MAI, with dropout 0.5 worst at epoch 2 but catching up by epoch 3. Differences narrow over time but remain: heavier dropout yields marginally lower final MAI, suggesting some adverse impact on bidirectional alignment quality.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_mai_curves.png"
      },
      {
        "analysis": "MAI Curves on yelp_polarity: No-dropout starts higher but barely improves after epoch 2, actually dipping by epoch 3. Dropout 0.1, 0.3, and 0.5 all show stronger gains through epoch 3, with dropout 0.5 achieving the highest MAI (~0.93), followed by 0.3 and 0.1. Moderate-to-heavy dropout enhances MAI progression on yelp_polarity at later epochs, indicating beneficial regularization in this dataset.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_mai_curves.png"
      },
      {
        "analysis": "MAI Curves on ag_news: All settings improve. No-dropout and 0.1 dropouts lead at epoch 2, but by epoch 3 no-dropout edges ahead (~0.943), with 0.1 slightly below and 0.3/0.5 trailing. Dropout accelerates initial MAI growth but heavier rates slow final convergence relative to no-dropout. Overall, minimal or no dropout yields the best MAI on ag_news.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_mai_curves.png"
      },
      {
        "analysis": "Alignment Curves on ag_news (Training & Validation Alignment): Training alignment: no-dropout quickly reaches near-perfect (>0.999) by epoch 3. Dropout 0.1 plateaus slightly lower (~0.989), dropout 0.3 and 0.5 lag significantly. Validation alignment is uniformly high (>0.993), with no-dropout and 0.1 best, moderate dropout trailing and heavy dropout lowest. Again, dropout consistently trades off alignment quality for robustness.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_alignment_curves.png"
      },
      {
        "analysis": "Loss Curves on yelp_polarity (Training & Validation Loss): Training losses drop steeply to epoch 2 for all settings then decrease mildly. No-dropout attains the lowest final training loss (~0.35), followed by dropout 0.1, 0.3, and 0.5. Validation shows dropout 0.3 yields the lowest loss at epoch 3 (~0.34), light dropout next, with no-dropout and heavy dropout slightly higher. Moderate dropout improves generalization, but heavy dropout underperforms.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_loss_curves.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/dbpedia_14_mai_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_mai_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_mai_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/ag_news_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/yelp_polarity_loss_curves.png"
    ],
    "vlm_feedback_summary": "Across tasks, dropout has mixed effects: light dropout (0.1) closely matches no-dropout on loss and alignment, offering slight regularization benefits. Moderate dropout (0.3) can improve generalization (validation loss, MAI) on sentiment tasks, but consistently undermines alignment metrics, especially on dbpedia_14 and ag_news. Heavy dropout (0.5) slows convergence, raises losses, and degrades alignment and MAI except on yelp_polarity where it boosts late-stage MAI. For CAMMA\u2019s bidirectional alignment, minimal or no dropout best preserves alignment quality, while moderate dropout may be selectively beneficial for generalization in text classification benchmarks.",
    "exp_results_dir": "experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279",
    "ablation_name": "MLP Dropout Rate Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_c01d46ac1e9c48da88cc5010da1fc00e_proc_4081279/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Activation Function Ablation.\nI will parameterize the MLP head to accept different activations (ReLU, GELU, Tanh, LeakyReLU) and loop over these in our ablation. For each activation and dataset, I train paired AI and user models as before, recording train/validation losses, JS\u2010based alignment, and validation MAI. After finishing each run I collect the AI model\u2019s predictions and ground truth into a nested dictionary keyed by activation and dataset. Finally, I save the complete experiment_data structure to working_dir/experiment_data.npy.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Final training loss (minimum across activations)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.3362,
                "best_value": 0.3362
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.3175,
                "best_value": 0.3175
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.1243,
                "best_value": 0.1243
              }
            ]
          },
          {
            "metric_name": "training alignment",
            "lower_is_better": false,
            "description": "Final training alignment (maximum across activations)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9982,
                "best_value": 0.9982
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Validation loss (minimum across activations)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.3372,
                "best_value": 0.3372
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.3478,
                "best_value": 0.3478
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.1281,
                "best_value": 0.1281
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Validation alignment (maximum across activations)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9982,
                "best_value": 0.9982
              }
            ]
          },
          {
            "metric_name": "MAI",
            "lower_is_better": false,
            "description": "Mutual Agreement Index (maximum across activations)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9438,
                "best_value": 0.9438
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9221,
                "best_value": 0.9221
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.987,
                "best_value": 0.987
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# backbone\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# MLP with pluggable activation\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim, act):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n        self.act = act\n\n    def forward(self, x):\n        return self.fc2(self.act(self.fc1(x)))\n\n\n# activations to ablate\nact_map = {\"ReLU\": nn.ReLU, \"GELU\": nn.GELU, \"Tanh\": nn.Tanh, \"LeakyReLU\": nn.LeakyReLU}\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nexperiment_data = {act: {} for act in act_map}\n\nfor act_name, act_cls in act_map.items():\n    for name in datasets:\n        # load & preprocess\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\"torch\", [\"input_ids\", \"attention_mask\", \"label\"])\n        val_ds.set_format(\"torch\", [\"input_ids\", \"attention_mask\", \"label\"])\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        num_labels = len(set(train_ds[\"label\"]))\n        # models, optimizers\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels, act_cls()).to(\n            device\n        )\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels, act_cls()).to(\n            device\n        )\n        opt_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        opt_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n        loss_fn = nn.CrossEntropyLoss()\n        # storage\n        losses = {\"train\": [], \"val\": []}\n        aligns = {\"train\": [], \"val\": []}\n        mai_list = []\n        # training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_n = 0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                opt_ai.zero_grad()\n                loss_ai.backward()\n                opt_ai.step()\n                opt_user.zero_grad()\n                loss_user.backward()\n                opt_user.step()\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_n += bs\n            losses[\"train\"].append(tot_loss / len(train_ds))\n            aligns[\"train\"].append(tot_align / tot_n)\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            losses[\"val\"].append(val_loss)\n            aligns[\"val\"].append(val_align)\n            mai_list.append(mai)\n            print(\n                f\"Activation {act_name} Dataset {name} Epoch {epoch}: validation_loss = {val_loss:.4f}, MAI = {mai:.4f}\"\n            )\n        # collect predictions\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        experiment_data[act_name][name] = {\n            \"losses\": losses,\n            \"alignments\": aligns,\n            \"mai\": mai_list,\n            \"predictions\": np.concatenate(preds),\n            \"ground_truth\": np.concatenate(gts),\n        }\n\n# save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nif \"experiment_data\" in locals():\n    datasets = list(next(iter(experiment_data.values())).keys())\n    activations = list(experiment_data.keys())\nelse:\n    datasets, activations = [], []\n\nfor dataset in datasets:\n    try:\n        plt.figure(figsize=(10, 5))\n        # Left: Loss Curves\n        ax1 = plt.subplot(1, 2, 1)\n        for act in activations:\n            losses = experiment_data[act][dataset][\"losses\"]\n            epochs = range(1, len(losses[\"train\"]) + 1)\n            ax1.plot(epochs, losses[\"train\"], label=f\"{act} Train\")\n            ax1.plot(epochs, losses[\"val\"], linestyle=\"--\", label=f\"{act} Val\")\n        ax1.set_title(\"Training vs Validation Loss\")\n        ax1.set_xlabel(\"Epoch\")\n        ax1.set_ylabel(\"Loss\")\n        ax1.legend()\n\n        # Right: MAI Curves\n        ax2 = plt.subplot(1, 2, 2)\n        for act in activations:\n            mai = experiment_data[act][dataset][\"mai\"]\n            ax2.plot(range(1, len(mai) + 1), mai, label=act)\n        ax2.set_title(\"MAI over Epochs\")\n        ax2.set_xlabel(\"Epoch\")\n        ax2.set_ylabel(\"MAI\")\n        ax2.legend()\n\n        plt.suptitle(\n            f\"{dataset} Metrics (Left: Loss Curves, Right: MAI Curves)\", fontsize=14\n        )\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n        save_path = os.path.join(working_dir, f\"{dataset}_metrics.png\")\n        plt.savefig(save_path)\n        plt.close()\n\n        # Print final MAI values\n        final_mai = {\n            act: experiment_data[act][dataset][\"mai\"][-1] for act in activations\n        }\n        print(f\"{dataset} Final MAI: {final_mai}\")\n    except Exception as e:\n        print(f\"Error creating plot for {dataset}: {e}\")\n        plt.close()\n",
    "plot_plan": "First, we load the saved experiment data from the working directory and extract the list of datasets and activations. For each dataset, we create a figure with two side-by-side panels: on the left we plot training and validation loss curves across epochs for each activation function, and on the right we plot MAI curves across epochs. Each subplot is titled and labeled, and a succinct suptitle indicates \u201cLeft: Loss Curves, Right: MAI Curves\u201d along with the dataset name. We wrap each dataset\u2019s plotting routine in a try-except block to catch errors, ensure the figure is always closed, and save the image to the working folder with a descriptive filename. After saving, we compute and print the final MAI values for all activations on that dataset to summarize performance.",
    "plot_analyses": [
      {
        "analysis": "yelp_polarity_metrics: Training losses for all activations plummet from ~1.8\u20131.6 at epoch 1 to ~0.35 by epoch 2 and ~0.30 by epoch 3. Validation losses follow suit, leveling off around ~0.38 with negligible overfitting. Among activations, Tanh and LeakyReLU have marginally lower training loss at epoch 3, but all validations converge similarly. MAI: Tanh exhibits the largest early jump (0.892\u21920.919), while GELU and LeakyReLU achieve the highest MAI (~0.922) by epoch 3, edging out ReLU which plateaus and dips slightly. This suggests strong early alignment from Tanh and top\u2010end alignment from GELU/LeakyReLU.",
        "},{": "},{",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278/yelp_polarity_metrics.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278/yelp_polarity_metrics.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278/dbpedia_14_metrics.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278/ag_news_metrics.png"
    ],
    "vlm_feedback_summary": "Across all three datasets, activation functions converge rapidly, with GELU often achieving the lowest loss and strongest MAI trajectory. Tanh drives early MAI gains on smaller datasets like yelp_polarity, but GELU and LeakyReLU match or surpass it by saturation. On large datasets (dbpedia_14), GELU consistently leads in both loss minimization and MAI. ag_news shows minimal differences after sufficient training, suggesting activation choice is less critical once convergence is reached.",
    "exp_results_dir": "experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278",
    "ablation_name": "Activation Function Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_31b90be82e6447e180577bc2ef7e6136_proc_4081278/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Alignment Regularization Ablation.\nBelow is a single\u2010file Python script that loads DistilBERT embeddings and trains paired MLP \u201cai\u201d and \u201cuser\u201d models on three text classification datasets, sweeping the JSD alignment penalty \u03bb\u2208{0,0.1,0.5,1.0}.  For each \u03bb and each dataset, it jointly optimizes cross\u2010entropy plus \u03bb\u00b7JSD over the models\u2019 soft\u2010predictions, records per\u2010epoch train/val losses, accuracies, alignment scores and MAI, gathers final predictions and ground truth, and stores everything in a nested `experiment_data` dict which is saved to `experiment_data.npy`.  Reproducibility is ensured by reseeding before each sweep.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train accuracy",
            "lower_is_better": false,
            "description": "Accuracy on the training data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.878,
                "best_value": 0.878
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.8635,
                "best_value": 0.8635
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.878,
                "best_value": 0.878
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.8625,
                "best_value": 0.8625
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.8795,
                "best_value": 0.8795
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.863,
                "best_value": 0.863
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.8805,
                "best_value": 0.8805
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.861,
                "best_value": 0.861
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.9785,
                "best_value": 0.9785
              }
            ]
          },
          {
            "metric_name": "validation accuracy",
            "lower_is_better": false,
            "description": "Accuracy on the validation data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.826,
                "best_value": 0.826
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.828,
                "best_value": 0.828
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.83,
                "best_value": 0.83
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.894,
                "best_value": 0.894
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.836,
                "best_value": 0.836
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.974,
                "best_value": 0.974
              }
            ]
          },
          {
            "metric_name": "train loss",
            "lower_is_better": true,
            "description": "Loss on the training data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.3674,
                "best_value": 0.3674
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.3441,
                "best_value": 0.3441
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.21,
                "best_value": 0.21
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.3682,
                "best_value": 0.3682
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.3442,
                "best_value": 0.3442
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.2083,
                "best_value": 0.2083
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.3705,
                "best_value": 0.3705
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.3378,
                "best_value": 0.3378
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.2076,
                "best_value": 0.2076
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Loss on the validation data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.379,
                "best_value": 0.379
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.1726,
                "best_value": 0.1726
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.3764,
                "best_value": 0.3764
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.1715,
                "best_value": 0.1715
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.3478,
                "best_value": 0.3478
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.3697,
                "best_value": 0.3697
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.1709,
                "best_value": 0.1709
              }
            ]
          },
          {
            "metric_name": "train alignment",
            "lower_is_better": false,
            "description": "Alignment metric on the training data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.9972,
                "best_value": 0.9972
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.9976,
                "best_value": 0.9976
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.9997,
                "best_value": 0.9997
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.998,
                "best_value": 0.998
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Alignment metric on the validation data",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.9979,
                "best_value": 0.9979
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.9982,
                "best_value": 0.9982
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.9985,
                "best_value": 0.9985
              }
            ]
          },
          {
            "metric_name": "MAI",
            "lower_is_better": false,
            "description": "Mean Alignment Index",
            "data": [
              {
                "dataset_name": "ag_news (lambda=0.0)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.0)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.0)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (lambda=0.1)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.1)",
                "final_value": 0.9059,
                "best_value": 0.9059
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.1)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (lambda=0.5)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (lambda=0.5)",
                "final_value": 0.9071,
                "best_value": 0.9071
              },
              {
                "dataset_name": "dbpedia_14 (lambda=0.5)",
                "final_value": 0.986,
                "best_value": 0.986
              },
              {
                "dataset_name": "ag_news (lambda=1.0)",
                "final_value": 0.9438,
                "best_value": 0.9438
              },
              {
                "dataset_name": "yelp_polarity (lambda=1.0)",
                "final_value": 0.9106,
                "best_value": 0.9106
              },
              {
                "dataset_name": "dbpedia_14 (lambda=1.0)",
                "final_value": 0.9861,
                "best_value": 0.9861
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os, random\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# set up\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# global seeds\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# tokenizer + frozen encoder\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# simple two\u2010layer MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# hyperparameters\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nlambdas = [0.0, 0.1, 0.5, 1.0]\nnum_epochs = 3\nbatch_size = 32\nlr = 1e-3\nloss_fn = nn.CrossEntropyLoss()\n\n# container for everything\nexperiment_data = {}\n\nfor lam in lambdas:\n    # reseed so each lambda run starts from identical MLP init\n    torch.manual_seed(42)\n    np.random.seed(42)\n    random.seed(42)\n    lam_key = f\"lambda_{str(lam).replace('.', '_')}\"\n    experiment_data[lam_key] = {}\n    print(f\"\\n=== Starting ablation {lam_key} ===\")\n\n    for name in datasets:\n        print(f\"\\nDataset {name}, \u03bb={lam}\")\n        # prepare storage\n        experiment_data[lam_key][name] = {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # load and tokenize\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=batch_size)\n\n        # models + optimizers\n        num_labels = len(set(train_ds[\"label\"]))\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n        optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n        # training epochs\n        for epoch in range(1, num_epochs + 1):\n            ai_model.train()\n            user_model.train()\n            tot_loss, tot_align, tot_acc, n = 0.0, 0.0, 0, 0\n\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                # embed\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                # forward\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                # CE losses\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                # JSD penalty\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                loss_reg = jsd.mean()\n\n                # joint backward + step\n                optimizer_ai.zero_grad()\n                optimizer_user.zero_grad()\n                total_loss = loss_ai + loss_user + lam * loss_reg\n                total_loss.backward()\n                optimizer_ai.step()\n                optimizer_user.step()\n\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (\n                    (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n                )\n                n += bs\n\n            # record train stats\n            experiment_data[lam_key][name][\"losses\"][\"train\"].append(\n                tot_loss / len(train_ds)\n            )\n            experiment_data[lam_key][name][\"alignments\"][\"train\"].append(tot_align / n)\n            experiment_data[lam_key][name][\"metrics\"][\"train\"].append(tot_acc / n)\n\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss, v_align, v_acc, v_n = 0.0, 0.0, 0, 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n\n            # record val stats\n            experiment_data[lam_key][name][\"losses\"][\"val\"].append(val_loss)\n            experiment_data[lam_key][name][\"alignments\"][\"val\"].append(val_align)\n            experiment_data[lam_key][name][\"metrics\"][\"val\"].append(val_acc)\n            experiment_data[lam_key][name][\"mai\"].append(mai)\n\n            print(\n                f\"  Ep{epoch}: train_loss={tot_loss/len(train_ds):.4f}, \"\n                f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, val_align={val_align:.4f}, MAI={mai:.4f}\"\n            )\n\n        # final predictions by ai_model\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        experiment_data[lam_key][name][\"predictions\"] = np.concatenate(preds)\n        experiment_data[lam_key][name][\"ground_truth\"] = np.concatenate(gts)\n\n# save everything\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\nprint(\"\\nSaved experiment_data.npy\")\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    exp = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    exp = {}\n\nif exp:\n    datasets = list(next(iter(exp.values())).keys())\n    lam_keys = sorted(\n        exp.keys(), key=lambda x: float(x[len(\"lambda_\") :].replace(\"_\", \".\"))\n    )\n\n    for name in datasets:\n        try:\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n            for lam in lam_keys:\n                data = exp[lam][name]\n                epochs = range(1, len(data[\"losses\"][\"train\"]) + 1)\n                ax1.plot(epochs, data[\"losses\"][\"train\"], label=lam)\n                ax2.plot(epochs, data[\"losses\"][\"val\"], label=lam)\n            fig.suptitle(f\"Loss Curves for {name}\")\n            ax1.set_title(\"Left: Training Loss\")\n            ax2.set_title(\"Right: Validation Loss\")\n            ax1.set_xlabel(\"Epoch\")\n            ax2.set_xlabel(\"Epoch\")\n            ax1.set_ylabel(\"Loss\")\n            ax2.set_ylabel(\"Loss\")\n            ax1.legend()\n            ax2.legend()\n            plt.savefig(os.path.join(working_dir, f\"{name}_loss_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating loss plot for {name}: {e}\")\n            plt.close()\n\n    for name in datasets:\n        try:\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n            for lam in lam_keys:\n                data = exp[lam][name]\n                epochs = range(1, len(data[\"metrics\"][\"train\"]) + 1)\n                ax1.plot(epochs, data[\"metrics\"][\"train\"], label=lam)\n                ax2.plot(epochs, data[\"metrics\"][\"val\"], label=lam)\n            fig.suptitle(f\"Accuracy Curves for {name}\")\n            ax1.set_title(\"Left: Training Accuracy\")\n            ax2.set_title(\"Right: Validation Accuracy\")\n            ax1.set_xlabel(\"Epoch\")\n            ax2.set_xlabel(\"Epoch\")\n            ax1.set_ylabel(\"Accuracy\")\n            ax2.set_ylabel(\"Accuracy\")\n            ax1.legend()\n            ax2.legend()\n            plt.savefig(os.path.join(working_dir, f\"{name}_accuracy_curves.png\"))\n            plt.close()\n        except Exception as e:\n            print(f\"Error creating accuracy plot for {name}: {e}\")\n            plt.close()\n\n    for name in datasets:\n        print(f\"Dataset {name}:\")\n        for lam in lam_keys:\n            d = exp[lam][name]\n            print(\n                f\" {lam}: final val_acc={d['metrics']['val'][-1]:.4f}, final MAI={d['mai'][-1]:.4f}\"\n            )\n",
    "plot_plan": "I will load the saved experiment data and extract losses and accuracies for each lambda and dataset. For each dataset I will make two plots: one showing training vs validation loss curves across epochs, and another showing the corresponding accuracy curves. Each figure uses two subplots (left for training, right for validation) and includes all lambdas in the legend. Every plotting step is wrapped in a try-except to log errors and always close the figure afterward. Filenames include the dataset name and plot type for clarity. Finally, I will print a summary of the final validation accuracy and MAI for each lambda and dataset. This ensures we visualize convergence behavior and compare ablations succinctly.",
    "plot_analyses": [
      {
        "analysis": "Training accuracy curves for yelp_polarity overlap almost perfectly across all four \u03bb configurations, rising from ~0.63 at epoch 1 to ~0.87 by epoch 3. Validation accuracy peaks around epoch 2 for \u03bb=0.1 (0.838) and \u03bb=0.5 (0.842) then dips by epoch 3, while \u03bb=1.0 achieves the highest initial validation accuracy (0.848) and remains marginally above the others at epoch 3. Overall differences are under 1%, indicating rapid convergence and only slight generalization gains for the highest \u03bb early on.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/yelp_polarity_accuracy_curves.png"
      },
      {
        "analysis": "For dbpedia_14, training loss decreases identically from ~2.7 to ~0.2 over three epochs under every \u03bb. Validation loss follows the same pattern, falling from ~0.80 to ~0.17 with no visible separation between \u03bb settings. This uniformity implies that the \u03bb hyperparameter has negligible impact on convergence speed or final loss on this dataset.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/dbpedia_14_loss_curves.png"
      },
      {
        "analysis": "On ag_news, training loss uniformly declines from ~2.1 to ~0.36 across all \u03bb values. Validation loss also drops in lockstep from ~0.495 to ~0.345. No \u03bb configuration stands out, demonstrating that this ablation has no measurable effect on loss reduction or overfitting for ag_news.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/ag_news_loss_curves.png"
      },
      {
        "analysis": "Training accuracy for dbpedia_14 climbs from ~0.67 to ~0.98 by epoch 3 under every \u03bb. Validation accuracy shows a minor initial spread (\u03bb=0.0 at ~0.915 vs. \u03bb=1.0 at ~0.923 at epoch 1) but converges to ~0.975 for all \u03bb by epoch 3. The tiny early advantage of \u03bb=1.0 vanishes after epoch 2, indicating minimal sensitivity to this hyperparameter in final performance.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/dbpedia_14_accuracy_curves.png"
      },
      {
        "analysis": "Yelp_polarity training loss declines identically (~1.8\u21920.35) across \u03bb settings. Validation loss reveals a slight edge for \u03bb=1.0: at epoch 2 it is lowest (0.377 vs. 0.379\u20130.383) and this margin persists into epoch 3 (0.370 vs. 0.377\u20130.380). The other \u03bb curves remain essentially indistinguishable, suggesting only a modest generalization benefit for the highest \u03bb.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/yelp_polarity_loss_curves.png"
      },
      {
        "analysis": "Validation accuracy on ag_news shows the clearest \u03bb-dependent effect: \u03bb=1.0 rises from ~0.860 at epoch 1 to ~0.894 by epoch 3, outperforming \u03bb=0.0 (0.872\u21920.887) and \u03bb=0.5 (0.868\u21920.892). Training accuracy is nearly identical across all \u03bb. Thus, only on ag_news does \u03bb=1.0 yield a modest but consistent generalization improvement.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/ag_news_accuracy_curves.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/yelp_polarity_accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/dbpedia_14_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/ag_news_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/dbpedia_14_accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/yelp_polarity_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/ag_news_accuracy_curves.png"
    ],
    "vlm_feedback_summary": "Across six complementary plots, training curves are virtually invariant to \u03bb choice, indicating rapid convergence independent of this hyperparameter. Validation metrics show only minor sensitivity: \u03bb=1.0 consistently edges out other settings on yelp_polarity and ag_news, but has no effect on dbpedia_14. Given the minimal impact, further ablations should explore additional components or more challenging tasks to tease apart the contributions of the co-adaptive framework.",
    "exp_results_dir": "experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280",
    "ablation_name": "Alignment Regularization Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_e1adbc0569d4459b888faf7a298452ab_proc_4081280/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Loss Function Ablation \u2013 Focal Loss.\nBelow is a sketch of the approach followed by the full Python program:\n\nWe define a custom FocalLoss module and then loop over \u03b3\u2208{1,2,5} as separate ablation settings. For each \u03b3 and each dataset we train both the AI and user MLPs for 3 epochs, replacing cross\u2010entropy by focal loss, while tracking training/validation losses, JS\u2010divergence alignment, and MAI. Finally we save all collected losses, alignments, MAIs, predictions and labels into a single experiment_data.npy.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train MAI",
            "lower_is_better": false,
            "description": "Multi-class accuracy metric on the training set",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9387,
                "best_value": 0.9387
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9267,
                "best_value": 0.9267
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9874,
                "best_value": 0.9874
              }
            ]
          },
          {
            "metric_name": "validation MAI",
            "lower_is_better": false,
            "description": "Multi-class accuracy metric on the validation set",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9458,
                "best_value": 0.9458
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9223,
                "best_value": 0.9223
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9854,
                "best_value": 0.9854
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# Setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\nprint(f\"Using device: {device}\")\n\n# Tokenizer & frozen encoder\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# Simple MLP head\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, reduction=\"mean\", eps=1e-8):\n        super().__init__()\n        self.gamma = gamma\n        self.reduction = reduction\n        self.eps = eps\n\n    def forward(self, inputs, targets):\n        probs = F.softmax(inputs, dim=1).clamp(min=self.eps)\n        t_one = F.one_hot(targets, inputs.size(1)).float().to(inputs.device)\n        p_t = (probs * t_one).sum(1)\n        loss = -((1 - p_t) ** self.gamma) * torch.log(p_t)\n        if self.reduction == \"mean\":\n            return loss.mean()\n        if self.reduction == \"sum\":\n            return loss.sum()\n        return loss\n\n\n# Ablation settings & data structures\ngammas = [1, 2, 5]\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nexperiment_data = {}\n\nfor gamma in gammas:\n    ab_key = f\"focal_loss_gamma_{gamma}\"\n    experiment_data[ab_key] = {}\n    loss_fn = FocalLoss(gamma=gamma)\n\n    for name in datasets:\n        # Load & tokenize\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tok(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tok, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tok, batched=True, remove_columns=[text_key])\n        cols = [\"input_ids\", \"attention_mask\", \"label\"]\n        train_ds.set_format(type=\"torch\", columns=cols)\n        val_ds.set_format(type=\"torch\", columns=cols)\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        num_labels = len(set(train_ds[\"label\"]))\n\n        # Models & optimizers\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        opt_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        opt_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n\n        # Storage per dataset\n        experiment_data[ab_key][name] = {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # Training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_acc = n = 0\n            for b in train_loader:\n                b = {k: v.to(device) for k, v in b.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"]\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, b[\"label\"])\n                # AI update\n                opt_ai.zero_grad()\n                loss_ai.backward()\n                opt_ai.step()\n                # User update\n                loss_user = loss_fn(logits_user, b[\"label\"])\n                opt_user.zero_grad()\n                loss_user.backward()\n                opt_user.step()\n\n                bs = b[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = (P * (torch.log(P + 1e-8) - torch.log(M + 1e-8))).sum(1)\n                kl2 = (Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8))).sum(1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += (1 - jsd).sum().item()\n                tot_acc += (torch.argmax(logits_user, 1) == b[\"label\"]).sum().item()\n                n += bs\n\n            # Compute train stats\n            train_loss = tot_loss / len(train_ds)\n            train_align = tot_align / n\n            train_acc = tot_acc / n\n            train_mai = 2 * (train_align * train_acc) / (train_align + train_acc + 1e-8)\n            experiment_data[ab_key][name][\"losses\"][\"train\"].append(train_loss)\n            experiment_data[ab_key][name][\"alignments\"][\"train\"].append(train_align)\n            experiment_data[ab_key][name][\"metrics\"][\"train\"].append(train_mai)\n\n            # Validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0\n            with torch.no_grad():\n                for b in val_loader:\n                    b = {k: v.to(device) for k, v in b.items()}\n                    emb = distilbert(\n                        input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"]\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, b[\"label\"]).item() * b[\"label\"].size(0)\n                    P = F.softmax(logits_ai, 1)\n                    Q = F.softmax(user_model(emb), 1)\n                    M = 0.5 * (P + Q)\n                    kl1 = (P * (torch.log(P + 1e-8) - torch.log(M + 1e-8))).sum(1)\n                    kl2 = (Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8))).sum(1)\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += (1 - jsd).sum().item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), 1) == b[\"label\"]).sum().item()\n                    )\n                    v_n += b[\"label\"].size(0)\n\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            val_mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            experiment_data[ab_key][name][\"losses\"][\"val\"].append(val_loss)\n            experiment_data[ab_key][name][\"alignments\"][\"val\"].append(val_align)\n            experiment_data[ab_key][name][\"metrics\"][\"val\"].append(val_mai)\n\n            print(\n                f\"Ablation {ab_key} Dataset {name} Epoch {epoch}: val_loss={val_loss:.4f}, MAI={val_mai:.4f}\"\n            )\n\n        # Final predictions on val\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for b in val_loader:\n                b = {k: v.to(device) for k, v in b.items()}\n                emb = distilbert(\n                    input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), 1).cpu().numpy())\n                gts.append(b[\"label\"].cpu().numpy())\n        experiment_data[ab_key][name][\"predictions\"] = np.concatenate(preds)\n        experiment_data[ab_key][name][\"ground_truth\"] = np.concatenate(gts)\n\n# Save everything\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# Prepare averaged metrics across datasets\nab_keys = sorted(\n    experiment_data.keys(), key=lambda k: int(k.split(\"_\")[-1])\n)  # sort by gamma\nloss_avg = {}\nalign_avg = {}\nmai_avg = {}\n\nfor ab in ab_keys:\n    ds_data = experiment_data[ab]\n    # stack per-dataset lists\n    train_losses = np.array([ds_data[ds][\"losses\"][\"train\"] for ds in ds_data])\n    val_losses = np.array([ds_data[ds][\"losses\"][\"val\"] for ds in ds_data])\n    train_align = np.array([ds_data[ds][\"alignments\"][\"train\"] for ds in ds_data])\n    val_align = np.array([ds_data[ds][\"alignments\"][\"val\"] for ds in ds_data])\n    train_mai = np.array([ds_data[ds][\"metrics\"][\"train\"] for ds in ds_data])\n    val_mai = np.array([ds_data[ds][\"metrics\"][\"val\"] for ds in ds_data])\n    # average over datasets\n    loss_avg[ab] = {\"train\": train_losses.mean(0), \"val\": val_losses.mean(0)}\n    align_avg[ab] = {\"train\": train_align.mean(0), \"val\": val_align.mean(0)}\n    mai_avg[ab] = {\"train\": train_mai.mean(0), \"val\": val_mai.mean(0)}\n\n# Define epoch axis\nif ab_keys:\n    epochs = np.arange(1, len(loss_avg[ab_keys[0]][\"train\"]) + 1)\n\n# Plot average loss\ntry:\n    plt.figure()\n    for ab in ab_keys:\n        gamma = ab.split(\"_\")[-1]\n        plt.plot(epochs, loss_avg[ab][\"train\"], \"-o\", label=f\"\u03b3={gamma} train\")\n        plt.plot(epochs, loss_avg[ab][\"val\"], \"--s\", label=f\"\u03b3={gamma} val\")\n    plt.title(\"Avg Loss vs Epoch\\nSubtitle: Averaged Across Datasets\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"avg_loss_gamma_comparison.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\n# Plot average alignment\ntry:\n    plt.figure()\n    for ab in ab_keys:\n        gamma = ab.split(\"_\")[-1]\n        plt.plot(epochs, align_avg[ab][\"train\"], \"-o\", label=f\"\u03b3={gamma} train\")\n        plt.plot(epochs, align_avg[ab][\"val\"], \"--s\", label=f\"\u03b3={gamma} val\")\n    plt.title(\"Avg Alignment vs Epoch\\nSubtitle: Averaged Across Datasets\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Alignment\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"avg_alignment_gamma_comparison.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating alignment plot: {e}\")\n    plt.close()\n\n# Plot average MAI\ntry:\n    plt.figure()\n    for ab in ab_keys:\n        gamma = ab.split(\"_\")[-1]\n        plt.plot(epochs, mai_avg[ab][\"train\"], \"-o\", label=f\"\u03b3={gamma} train\")\n        plt.plot(epochs, mai_avg[ab][\"val\"], \"--s\", label=f\"\u03b3={gamma} val\")\n    plt.title(\"Avg MAI vs Epoch\\nSubtitle: Averaged Across Datasets\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"MAI\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"avg_MAI_gamma_comparison.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MAI plot: {e}\")\n    plt.close()\n",
    "plot_plan": "We will load the saved experiment_data dictionary and extract the three focal_loss_gamma ablation keys. For each gamma, we will gather the per-epoch train/val losses, alignments, and MAI metrics across all datasets and compute their averages. We define epochs simply as [1,\u2026,n_epochs] based on the recorded lists. We then create three separate plots\u2014average loss, average alignment, and average MAI\u2014each wrapped in its own try\u2013except block to ensure errors are caught without aborting. Each plot includes curves for train and val for all gamma settings, a clear title with a subtitle indicating that the data is averaged across datasets, labeled axes, and a legend. Filenames incorporate the metric name and note that this is a gamma comparison across datasets. Figures are saved into the working directory and closed after saving to manage resources.",
    "plot_analyses": [
      {
        "analysis": "Avg Loss vs Epoch shows a dramatic drop in both training and validation loss between epoch 1 and epoch 2, followed by a marginal decline by epoch 3. At epoch 1, \u03b3 = 5 yields the lowest losses (\u22481.55 train, \u22480.08 val), followed by \u03b3 = 2 (\u22481.85 train, \u22480.22 val) and \u03b3 = 1 (\u22481.97 train, \u22480.35 val). By epoch 2, losses converge to roughly 0.23/0.17 (train/val) for \u03b3 = 1, 0.18/0.12 for \u03b3 = 2, and 0.05/0.01 for \u03b3 = 5, and by epoch 3 these flatten to around 0.17/0.17, 0.14/0.14, and 0.03/0.02 respectively. The validation curves closely track the training curves without any sign of overfitting, suggesting good generalization. Higher \u03b3 accelerates convergence and yields lower final loss, indicating that the corresponding component weight is critical for loss optimization.",
        "valid_plots_received": true,
        "vlm_feedback_summary": "Loss is steeply reduced in the first epoch and nearly converges by the second. Larger \u03b3 values improve both convergence speed and final loss. No significant overfitting observed; validation curves mirror training.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_loss_gamma_comparison.png"
      },
      {
        "analysis": "Avg Alignment vs Epoch rises sharply from epoch 1 to epoch 2, then edges toward saturation by epoch 3. Initial training alignment at epoch 1 is around 0.965 (\u03b3 = 1), 0.968 (\u03b3 = 2), and 0.969 (\u03b3 = 5), while validation alignment starts at 0.996, 0.996, and 0.995 respectively. At epoch 2 these all jump to approximately 0.996\u20130.997 for training and 0.998\u20130.999 for validation, and by epoch 3 they reach \u22480.998\u20130.999 (train) and \u22480.999 (val) across all \u03b3 settings. Differences between \u03b3 values are negligible after epoch 2, and validation alignment consistently exceeds training alignment by a small margin, indicating robust and generalizable mutual\u2010model alignment.",
        "valid_plots_received": true,
        "vlm_feedback_summary": "Alignment improves nearly to ceiling by the second epoch regardless of \u03b3. Validation alignment slightly outperforms training, and all models converge to ~0.998\u20130.999 alignment by epoch 3.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_alignment_gamma_comparison.png"
      },
      {
        "analysis": "Avg MAI vs Epoch mirrors the alignment trend, with a steep jump between epoch 1 and epoch 2, then a mild increase to epoch 3. At epoch 1, training MAI is about 0.77 (\u03b3 = 1), 0.77 (\u03b3 = 2), 0.74 (\u03b3 = 5), and validation MAI is 0.92, 0.93, and 0.92 respectively. By epoch 2, all settings reach \u22480.94\u20130.945 (train) and \u22480.94\u20130.945 (val). Final values at epoch 3 sit near 0.948\u20130.95 for training and 0.948\u20130.949 for validation, with \u03b3 = 2 yielding the highest MAI. The close alignment of training and validation metrics again signals minimal overfitting. This rapid convergence suggests two epochs suffice to achieve near\u2010optimal mutual attention and interpretability interaction scores.",
        "valid_plots_received": true,
        "vlm_feedback_summary": "MAI jumps from ~0.75 to ~0.94 in one epoch and saturates by the second. \u03b3 = 2 gives the highest final MAI but differences among \u03b3 settings are small. Good generalization is observed.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_MAI_gamma_comparison.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_loss_gamma_comparison.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_alignment_gamma_comparison.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/avg_MAI_gamma_comparison.png"
    ],
    "vlm_feedback_summary": "All three metrics (loss, alignment, MAI) exhibit sharp gains between epoch 1 and 2 and plateau by epoch 3. Higher \u03b3 speeds up loss reduction and yields lower final loss, though alignment and MAI saturate rapidly with minimal \u03b3\u2010dependent differences beyond epoch 2. Validation curves match training curves closely, indicating strong generalization and little overfitting.",
    "exp_results_dir": "experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278",
    "ablation_name": "Loss Function Ablation \u2013 Focal Loss",
    "exp_results_npy_files": [
      "experiment_results/experiment_5423d385102944c4a70669fbe1229642_proc_4081278/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Attention Head Ablation.\nBelow is a self\u2010contained Python script that performs attention\u2010head ablation (random vs. importance\u2010ranked) at 12, 8, 4, and 2 heads per layer on three text classification datasets. It gathers losses, JS\u2010alignment, MAI, predictions, and ground truths into a nested dictionary and saves everything as `experiment_data.npy`.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train loss",
            "lower_is_better": true,
            "description": "Final training loss",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.3635,
                "best_value": 0.3635
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.3563,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.2235,
                "best_value": 0.2103
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Final validation loss",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.3453,
                "best_value": 0.3453
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.3458,
                "best_value": 0.3458
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.1858,
                "best_value": 0.1728
              }
            ]
          },
          {
            "metric_name": "train alignment",
            "lower_is_better": false,
            "description": "Final training alignment",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9992,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9997,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.996,
                "best_value": 0.9971
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Final validation alignment",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9994,
                "best_value": 0.9997
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9997,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9968,
                "best_value": 0.9978
              }
            ]
          },
          {
            "metric_name": "validation MAI",
            "lower_is_better": false,
            "description": "Final validation mean average similarity (MAI)",
            "data": [
              {
                "dataset_name": "ag_news",
                "final_value": 0.9416,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity",
                "final_value": 0.9258,
                "best_value": 0.9258
              },
              {
                "dataset_name": "dbpedia_14",
                "final_value": 0.9843,
                "best_value": 0.9858
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# load model & tokenizer\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = (\n    DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device).eval()\n)\n\n# compute head importance via L2 norm of output\u2010projection weights\nn_layers = len(distilbert.transformer.layer)\nn_heads = distilbert.transformer.layer[0].attention.n_heads\nhead_dim = distilbert.config.hidden_size // n_heads\nhead_importance = {}\nfor l in range(n_layers):\n    W = distilbert.transformer.layer[l].attention.out_lin.weight.data.cpu()\n    imp = []\n    for h in range(n_heads):\n        block = W[:, h * head_dim : (h + 1) * head_dim]\n        imp.append(torch.norm(block).item())\n    head_importance[l] = np.array(imp)\n\n# prepare head masks\nablation_types = [\"random\", \"importance\"]\nhead_counts = [12, 8, 4, 2]\nhead_masks = {t: {} for t in ablation_types}\nfor t in ablation_types:\n    for hc in head_counts:\n        mask = torch.zeros(n_layers, n_heads)\n        for l in range(n_layers):\n            if t == \"random\":\n                keep = np.random.choice(n_heads, hc, replace=False)\n            else:  # importance\n                keep = np.argsort(-head_importance[l])[:hc]\n            mask[l, keep] = 1.0\n        head_masks[t][hc] = mask.to(device)\n\n# load datasets once\ndataset_names = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\ntrain_loaders, val_loaders, num_labels = {}, {}, {}\nfor name in dataset_names:\n    raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n    split = raw.train_test_split(test_size=0.2, seed=0)\n    train_ds, val_ds = split[\"train\"], split[\"test\"]\n    text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n    def tokenize_fn(batch):\n        return tokenizer(\n            batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n        )\n\n    train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n    val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n    train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    train_loaders[name] = DataLoader(train_ds, batch_size=32, shuffle=True)\n    val_loaders[name] = DataLoader(val_ds, batch_size=32)\n    num_labels[name] = len(set(train_ds[\"label\"]))\n\n\n# simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# init data structure\nexperiment_data = {\n    t: {\n        name: {\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"head_counts\": [],\n            \"predictions\": {},\n            \"ground_truth\": None,\n        }\n        for name in dataset_names\n    }\n    for t in ablation_types\n}\n\n# run ablations\nfor t in ablation_types:\n    for hc in head_counts:\n        mask = head_masks[t][hc]\n        for name in dataset_names:\n            train_loader = train_loaders[name]\n            val_loader = val_loaders[name]\n            nl = num_labels[name]\n            ai_model = MLP(distilbert.config.hidden_size, 128, nl).to(device)\n            user_model = MLP(distilbert.config.hidden_size, 128, nl).to(device)\n            opt_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n            opt_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n            loss_fn = nn.CrossEntropyLoss()\n\n            # epochs\n            for epoch in range(1, 4):\n                ai_model.train()\n                user_model.train()\n                tot_loss, tot_align, tot_acc, n = 0.0, 0.0, 0, 0\n                for batch in train_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    with torch.no_grad():\n                        out = distilbert(\n                            input_ids=batch[\"input_ids\"],\n                            attention_mask=batch[\"attention_mask\"],\n                            head_mask=mask,\n                        )\n                        emb = out.last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    logits_user = user_model(emb)\n                    loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                    loss_user = loss_fn(logits_user, batch[\"label\"])\n                    opt_ai.zero_grad()\n                    loss_ai.backward()\n                    opt_ai.step()\n                    opt_user.zero_grad()\n                    loss_user.backward()\n                    opt_user.step()\n                    bs = batch[\"label\"].size(0)\n                    tot_loss += loss_ai.item() * bs\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(logits_user, dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    tot_align += torch.sum(1 - jsd).item()\n                    tot_acc += (\n                        (torch.argmax(logits_user, dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    n += bs\n                train_loss = tot_loss / len(train_loader.dataset)\n                train_align = tot_align / n\n                experiment_data[t][name][\"losses\"][\"train\"].append(train_loss)\n                experiment_data[t][name][\"alignments\"][\"train\"].append(train_align)\n\n                # validation\n                ai_model.eval()\n                user_model.eval()\n                v_loss, v_align, v_acc, v_n = 0.0, 0.0, 0, 0\n                with torch.no_grad():\n                    for batch in val_loader:\n                        batch = {k: v.to(device) for k, v in batch.items()}\n                        out = distilbert(\n                            input_ids=batch[\"input_ids\"],\n                            attention_mask=batch[\"attention_mask\"],\n                            head_mask=mask,\n                        )\n                        emb = out.last_hidden_state[:, 0, :]\n                        logits_ai = ai_model(emb)\n                        v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                            \"label\"\n                        ].size(0)\n                        P = F.softmax(logits_ai, dim=1)\n                        Q = F.softmax(user_model(emb), dim=1)\n                        M = 0.5 * (P + Q)\n                        kl1 = torch.sum(\n                            P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                        )\n                        kl2 = torch.sum(\n                            Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                        )\n                        jsd = 0.5 * (kl1 + kl2)\n                        v_align += torch.sum(1 - jsd).item()\n                        v_acc += (\n                            (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                            .sum()\n                            .item()\n                        )\n                        v_n += batch[\"label\"].size(0)\n                val_loss = v_loss / len(val_loader.dataset)\n                val_align = v_align / v_n\n                val_acc = v_acc / v_n\n                mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n                experiment_data[t][name][\"losses\"][\"val\"].append(val_loss)\n                experiment_data[t][name][\"alignments\"][\"val\"].append(val_align)\n                experiment_data[t][name][\"mai\"].append(mai)\n                experiment_data[t][name][\"head_counts\"].append(hc)\n                print(\n                    f\"Ablation {t} heads={hc} ds={name} epoch={epoch}: val_loss={val_loss:.4f}, MAI={mai:.4f}\"\n                )\n\n            # collect predictions & ground truth\n            preds, gts = [], []\n            ai_model.eval()\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    out = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                        head_mask=mask,\n                    )\n                    emb = out.last_hidden_state[:, 0, :]\n                    preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                    gts.append(batch[\"label\"].cpu().numpy())\n            preds = np.concatenate(preds)\n            gts = np.concatenate(gts)\n            experiment_data[t][name][\"predictions\"][str(hc)] = preds\n            experiment_data[t][name][\"ground_truth\"] = gts\n\n# save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# load data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nablation_types = [\"random\", \"importance\"]\nhead_counts_list = [2, 4, 8, 12]\n\n# 1\u20133: MAI vs head count for each dataset\nfor name in datasets:\n    try:\n        plt.figure()\n        for t in ablation_types:\n            heads = []\n            mais = []\n            data = experiment_data.get(t, {}).get(name, {})\n            hs = data.get(\"head_counts\", [])\n            m = data.get(\"mai\", [])\n            # compute final MAI per head count\n            for h in sorted(set(hs)):\n                idxs = [i for i, hh in enumerate(hs) if hh == h]\n                if idxs:\n                    heads.append(h)\n                    mais.append(m[max(idxs)])\n            # sort pairs\n            paired = sorted(zip(heads, mais))\n            x, y = zip(*paired)\n            plt.plot(x, y, marker=\"o\", label=t.capitalize())\n        plt.xlabel(\"Number of Heads\")\n        plt.ylabel(\"MAI\")\n        plt.title(f\"{name} MAI vs Head Count\\nRandom vs Importance Ablation\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{name}_MAI_vs_heads.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating MAI plot for {name}: {e}\")\n        plt.close()\n\n# 4\u20135: Loss curves for ag_news at head_count=12\nfor t in ablation_types:\n    try:\n        plt.figure()\n        data = experiment_data.get(t, {}).get(\"ag_news\", {})\n        hs = data.get(\"head_counts\", [])\n        train_losses = data.get(\"losses\", {}).get(\"train\", [])\n        val_losses = data.get(\"losses\", {}).get(\"val\", [])\n        # filter for head_count = 12\n        idxs = [i for i, hh in enumerate(hs) if hh == 12]\n        epochs = list(range(1, len(idxs) + 1))\n        tr = [train_losses[i] for i in idxs]\n        vl = [val_losses[i] for i in idxs]\n        plt.plot(epochs, tr, marker=\"o\", label=\"Train Loss\")\n        plt.plot(epochs, vl, marker=\"o\", linestyle=\"--\", label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"ag_news Loss Curves for {t.capitalize()} Ablation\\nHead Count = 12\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"ag_news_{t}_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss curves for ag_news ({t}): {e}\")\n        plt.close()\n",
    "plot_plan": "We start by loading the saved `experiment_data.npy` from the working directory and handle any loading errors gracefully. For each of the three datasets, we compute the final MAI at each head\u2010count by selecting the last value among the three epochs per head\u2010count, then plot MAI vs. number of heads with separate curves for random and importance\u2013based ablations. Each plot is wrapped in a try/except to catch errors, and we save with a descriptive filename like `ag_news_MAI_vs_heads.png`. Then, focusing on `ag_news`, we extract train and validation losses for head\u2010count 12 across the three epochs for each ablation type, plot these curves in separate figures, and again wrap each in try/except. We label axes clearly and include titles that specify the dataset, plot type, and ablation method. All figures are saved to the `working` directory and figures are closed after saving. This yields five plots in total: three MAI\u2010vs\u2010head\u2010count plots and two loss\u2010curve plots.",
    "plot_analyses": [
      {
        "analysis": "MAI improves as head count increases for both ablation methods, with importance-based ablation consistently outperforming random pruning at lower head counts. At 2 heads, importance (0.867) significantly exceeds random (0.742). Gains diminish at higher head counts, and both methods converge near 0.985 MAI at 12 heads, suggesting redundancy across many heads.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/dbpedia_14_MAI_vs_heads.png"
      },
      {
        "analysis": "Random-ablation model on ag_news with 12 heads shows rapid loss reduction: training loss drops from ~2.08 to ~0.36 by epoch 3, while validation loss decreases more modestly from ~0.49 to ~0.35. The gap narrows across epochs, indicating stable generalization and limited overfitting under random pruning.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_random_loss_curves.png"
      },
      {
        "analysis": "Importance-based ablation on ag_news (12 heads) also yields fast convergence: train loss decreases from ~1.95 to ~0.36 by epoch 3, with validation loss falling from ~0.47 to ~0.34. Compared to random, importance pruning achieves slightly lower initial training loss and marginally reduced final validation loss, indicating more efficient head selection.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_importance_loss_curves.png"
      },
      {
        "analysis": "On ag_news MAI vs. head count, both methods benefit from additional heads, but importance ablation leads at low (2 heads: 0.908 vs. 0.862) and mid counts (8 heads: 0.938 vs. 0.935). Random briefly surpasses at 4 heads (0.926 vs. 0.920). Convergence near 0.943\u20130.942 at 12 heads indicates diminishing returns from head importance ranking as capacity increases.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_MAI_vs_heads.png"
      },
      {
        "analysis": "Yelp-polarity MAI shows a strong advantage for importance pruning at low capacity (2 heads: 0.818 vs. 0.652). At 4 heads, random edges out slightly (0.874 vs. 0.867). At higher counts (8 and 12 heads), importance regains lead (0.922 vs. 0.908 and 0.925 vs. 0.903), demonstrating that head importance selection yields more robust alignment gains when model capacity is constrained.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/yelp_polarity_MAI_vs_heads.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/dbpedia_14_MAI_vs_heads.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_random_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_importance_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/ag_news_MAI_vs_heads.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/yelp_polarity_MAI_vs_heads.png"
    ],
    "vlm_feedback_summary": "Across datasets, importance-based head ablation consistently yields modestly better alignment (MAI) and slightly lower validation losses compared to random pruning, especially at low head counts. Differences shrink as head count increases, and both methods converge at high capacity. Loss curves on ag_news demonstrate that importance pruning can achieve marginally faster convergence and reduced final validation loss, suggesting more efficient utilization of attention heads.",
    "exp_results_dir": "experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279",
    "ablation_name": "Attention Head Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_00b9d440cc414af5af98e9b2d351e02a_proc_4081279/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: DistilBERT Pre-training Ablation.\nBelow is the outline and the full implementation.\n\nWe loop over two ablation types (\u201cpretrained\u201d vs. \u201crandom_init\u201d), initialize/freeze the corresponding DistilBERT encoder, and then for each dataset train two MLPs exactly as before. We record per\u2010epoch losses, alignment scores, MAI, and final predictions & ground truths into a nested dictionary `experiment_data` keyed by ablation type and dataset, then save it all to `experiment_data.npy`.",
    "analysis": "The script executed without any runtime errors on CUDA as expected. It ran 3 epochs of ablation studies for two model initializations (pretrained vs. random_init) on three datasets (AG News, Yelp Polarity, DBpedia-14). Results show that using a pretrained DistilBERT backbone yields substantially lower validation losses and much higher MAI scores compared to a randomly initialized backbone. Specifically, pretrained models achieved val_loss reductions from ~0.49\u21920.35 (AG News), ~0.47\u21920.38 (Yelp), and ~0.79\u21920.17 (DBpedia) with MAI rising to ~0.94, 0.91, and 0.99, respectively. Randomly initialized models remained far weaker (val_loss ~1.4\u21921.4 / ~0.7\u21920.68 / ~2.64\u21922.54 with MAI ~0.40, 0.65, 0.30). These findings confirm the critical role of pretraining for both task performance and alignment metrics.",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train loss",
            "lower_is_better": true,
            "description": "Cross-entropy loss on the training dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 1.393,
                "best_value": 1.393
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.689,
                "best_value": 0.689
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 2.6121,
                "best_value": 2.6121
              }
            ]
          },
          {
            "metric_name": "training alignment",
            "lower_is_better": false,
            "description": "Alignment score on the training dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 0.9973,
                "best_value": 0.9973
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.9991,
                "best_value": 0.9991
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 0.9889,
                "best_value": 0.9889
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Cross-entropy loss on the validation dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 1.4047,
                "best_value": 1.4047
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.6791,
                "best_value": 0.6791
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 2.5436,
                "best_value": 2.5436
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Alignment score on the validation dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 0.9857,
                "best_value": 0.9857
              }
            ]
          },
          {
            "metric_name": "validation MAI",
            "lower_is_better": false,
            "description": "Mean alignment index on the validation dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 0.3896,
                "best_value": 0.3896
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.7146,
                "best_value": 0.7146
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 0.3044,
                "best_value": 0.3044
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "Classification accuracy on the test dataset",
            "data": [
              {
                "dataset_name": "ag_news (pretrained)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (pretrained)",
                "final_value": 0.824,
                "best_value": 0.824
              },
              {
                "dataset_name": "dbpedia_14 (pretrained)",
                "final_value": 0.972,
                "best_value": 0.972
              },
              {
                "dataset_name": "ag_news (random_init)",
                "final_value": 0.242,
                "best_value": 0.242
              },
              {
                "dataset_name": "yelp_polarity (random_init)",
                "final_value": 0.542,
                "best_value": 0.542
              },
              {
                "dataset_name": "dbpedia_14 (random_init)",
                "final_value": 0.148,
                "best_value": 0.148
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel, DistilBertConfig\n\n# setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n\n\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\ndatasets_list = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nablations = {\n    \"pretrained\": lambda: DistilBertModel.from_pretrained(\"distilbert-base-uncased\"),\n    \"random_init\": lambda: DistilBertModel(\n        DistilBertConfig.from_pretrained(\"distilbert-base-uncased\")\n    ),\n}\n\nexperiment_data = {ab: {} for ab in ablations}\n\nfor ablation_type, model_fn in ablations.items():\n    # reset seed for consistent random-init behavior\n    torch.manual_seed(42)\n    np.random.seed(42)\n    distilbert = model_fn().to(device)\n    distilbert.eval()\n    for p in distilbert.parameters():\n        p.requires_grad = False\n\n    for name in datasets_list:\n        # load and preprocess\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        num_labels = len(set(train_ds[\"label\"]))\n\n        # models & optimizers\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n        loss_fn = nn.CrossEntropyLoss()\n\n        # init storage\n        experiment_data[ablation_type][name] = {\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss, tot_align, tot_acc, n = 0.0, 0.0, 0, 0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                optimizer_ai.zero_grad()\n                loss_ai.backward()\n                optimizer_ai.step()\n                optimizer_user.zero_grad()\n                loss_user.backward()\n                optimizer_user.step()\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (\n                    (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n                )\n                n += bs\n\n            experiment_data[ablation_type][name][\"losses\"][\"train\"].append(\n                tot_loss / len(train_ds)\n            )\n            experiment_data[ablation_type][name][\"alignments\"][\"train\"].append(\n                tot_align / n\n            )\n\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss, v_align, v_acc, v_n = 0.0, 0.0, 0, 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n\n            experiment_data[ablation_type][name][\"losses\"][\"val\"].append(val_loss)\n            experiment_data[ablation_type][name][\"alignments\"][\"val\"].append(val_align)\n            experiment_data[ablation_type][name][\"mai\"].append(mai)\n\n            print(\n                f\"Ablation={ablation_type} Dataset={name} Epoch={epoch} val_loss={val_loss:.4f} MAI={mai:.4f}\"\n            )\n\n        # final predictions\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        experiment_data[ablation_type][name][\"predictions\"] = np.concatenate(preds)\n        experiment_data[ablation_type][name][\"ground_truth\"] = np.concatenate(gts)\n\n# save everything\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\n# Print best MAI per dataset and ablation\nfor ab in data:\n    for ds in data[ab]:\n        mai_list = data[ab][ds].get(\"mai\", [])\n        if mai_list:\n            print(f\"Dataset: {ds}, Ablation: {ab}, Best MAI: {max(mai_list):.4f}\")\n\n# Generate plots per dataset\ndatasets = next(iter(data.values())).keys()\nfor ds in datasets:\n    # Loss curves\n    try:\n        plt.figure()\n        for ab in data:\n            losses = data[ab][ds][\"losses\"]\n            epochs = np.arange(1, len(losses[\"train\"]) + 1)\n            plt.plot(epochs, losses[\"train\"], label=f\"{ab} train\")\n            plt.plot(epochs, losses[\"val\"], label=f\"{ab} val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(f\"Loss Curves for {ds} Dataset\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds}_loss_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds}: {e}\")\n        plt.close()\n\n    # Alignment curves\n    try:\n        plt.figure()\n        for ab in data:\n            align = data[ab][ds][\"alignments\"]\n            epochs = np.arange(1, len(align[\"train\"]) + 1)\n            plt.plot(epochs, align[\"train\"], label=f\"{ab} train\")\n            plt.plot(epochs, align[\"val\"], label=f\"{ab} val\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Alignment\")\n        plt.title(f\"Alignment Curves for {ds} Dataset\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds}_alignment_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating alignment plot for {ds}: {e}\")\n        plt.close()\n\n    # Validation MAI curves\n    try:\n        plt.figure()\n        for ab in data:\n            mai_list = data[ab][ds][\"mai\"]\n            epochs = np.arange(1, len(mai_list) + 1)\n            plt.plot(epochs, mai_list, label=f\"{ab} val MAI\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MAI\")\n        plt.title(f\"Validation MAI for {ds} Dataset\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{ds}_mai_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating MAI plot for {ds}: {e}\")\n        plt.close()\n",
    "plot_plan": "First, the script loads the experiment_data.npy file from the working directory. It then iterates over each dataset recorded under both 'pretrained' and 'random_init' ablations. For each dataset, it computes and prints the best validation MAI per ablation. Next, it creates three standard plots per dataset: a loss curve (training vs validation) combining both ablations; an alignment curve (training vs validation) combining both ablations; and a validation MAI curve for both ablations. Each plot is wrapped in its own try-except block, uses basic matplotlib calls, includes a descriptive title and saves to working_dir with a clear filename. Figures are always closed after saving or on exception. No extra styling or simulated data is used; only values extracted from experiment_data are plotted.",
    "plot_analyses": [
      {
        "analysis": "Alignment Curves for dbpedia_14 Dataset: pretrained initialization yields high alignment from the start (~0.97 train, ~0.99 val) and further improves to ~0.997 train and ~0.998 val by epoch 3. Random initialization starts significantly lower (~0.94 train, ~0.99 val), only catching up on the train curve by epoch 2 but showing a slight validation dip at epoch 3 (~0.985). This indicates that pretrained components drive stable, high-quality alignment, while random models learn more slowly and generalize less consistently.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_alignment_curve.png"
      },
      {
        "analysis": "Loss Curves for ag_news Dataset: pretrained model loss plummets from ~2.1 to ~0.44 on train and ~0.49 to ~0.35 on validation by epoch 2, continuing to decrease to ~0.35. Random initialization stays around 1.9\u21921.4 train loss and 1.45\u21921.40 validation, with minimal improvement. Pretrained setup converges rapidly and achieves significantly lower loss than random, highlighting sample efficiency and better generalization.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_loss_curve.png"
      },
      {
        "analysis": "Alignment Curves for yelp_polarity Dataset: both pretrained and random initializations reach near-perfect alignment (>0.997) on train and validation by epoch 2. Pretrained starts slightly lower on train at epoch 1 (~0.957 vs. ~0.964) but aligns fully by epoch 2. Validation alignment is already very high (>0.997) for both. Indicates that this dataset is easily aligned and both setups can achieve saturation, though pretrained still demonstrates marginal stability.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_alignment_curve.png"
      },
      {
        "analysis": "Validation MAI for yelp_polarity Dataset: pretrained MAI holds around ~0.90\u20130.91 across all epochs, whereas random init starts at ~0.655, dips to ~0.63 at epoch 2, and rises to ~0.715 by epoch 3. The pretrained system maintains calibrated inference, while random initialization struggles to produce reliable alignment signals and only partly recovers by the end.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_mai_curve.png"
      },
      {
        "analysis": "Loss Curves for yelp_polarity Dataset: pretrained train loss drops sharply from ~1.8 to ~0.40 by epoch 2 and further to ~0.35, with validation loss falling from ~0.47 to ~0.37 then ~0.38. Random init starts at ~1.48, reduces to ~0.72\u21920.67 on train, and ~0.70\u21920.68 on validation, still well above pretrained. Confirms pretrained model\u2019s superior efficiency and generalization on this task.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_loss_curve.png"
      },
      {
        "analysis": "Loss Curves for dbpedia_14 Dataset: pretrained train loss decreases from ~2.65 to ~0.47\u2192~0.20 over three epochs, and validation from ~0.79 to ~0.30\u2192~0.15. Random init shows minimal change (~3.40\u21922.60 train, ~2.65\u21922.55 val), indicating failure to learn effectively. Pretrained initialization is critical for meaningful training progress in this domain.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_loss_curve.png"
      },
      {
        "analysis": "Validation MAI for dbpedia_14 Dataset: pretrained MAI climbs from ~0.95 to ~0.98\u2192~0.99, whereas random init remains flat near ~0.14\u2192~0.13 before a modest rise to ~0.30 in epoch 3. Pretrained model delivers well-calibrated mental alignment, random init yields poor calibration until very late and still far below.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_mai_curve.png"
      },
      {
        "analysis": "Validation MAI for ag_news Dataset: pretrained MAI steadily improves from ~0.93\u2192~0.94 over epochs, while random init hovers around ~0.41 and even dips slightly by epoch 3. Reinforces that pretrained architectures maintain reliable calibration and trust metrics, random frameworks fail to align users effectively.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_mai_curve.png"
      },
      {
        "analysis": "Alignment Curves for ag_news Dataset: pretrained train alignment grows from ~0.968 to ~0.998 and validation from ~0.998 to ~0.999. Random init rises from ~0.945\u2192~0.997 train and ~0.998\u2192~0.999 val, but shows a slight val dip at epoch 2. Both reach high final alignment, yet pretrained is more stable and faster converging.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_alignment_curve.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_alignment_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_loss_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_alignment_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_mai_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/yelp_polarity_loss_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_loss_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/dbpedia_14_mai_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_mai_curve.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/ag_news_alignment_curve.png"
    ],
    "vlm_feedback_summary": "Across tasks, pretrained initialization consistently enables rapid convergence, lower loss, stable high alignment, and superior MAI compared to random initialization. Randomly initialized models take longer to align, yield higher losses, and produce poorly calibrated MAI, especially on complex datasets like dbpedia_14 and ag_news. On easier datasets such as yelp_polarity, both eventually reach high alignment but pretrained still offers better calibration and efficiency.",
    "exp_results_dir": "experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280",
    "ablation_name": "DistilBERT Pre-training Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_33b1f7cfac554a38be76dd24c08c5ae6_proc_4081280/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Token Dropout Ablation.\nWe load three classification datasets and tokenize them to length 128. For each token\u2010dropout rate (0%, 10%, 20%, 30%), we randomly mask tokens (excluding [CLS] and padding) before passing through a frozen DistilBERT, then train two MLP heads to capture classification accuracy and JSD\u2010based alignment (plus MAI) over three epochs. We record train/val losses, accuracies, alignments, and val MAI per epoch, along with final predictions and ground truths. All results are stored in a nested dictionary keyed by ablation rate and dataset, then saved to `experiment_data.npy`.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train accuracy",
            "lower_is_better": false,
            "description": "Accuracy on training set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.878,
                "best_value": 0.878
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.8635,
                "best_value": 0.8635
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.8775,
                "best_value": 0.8775
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.835,
                "best_value": 0.835
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.962,
                "best_value": 0.962
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.874,
                "best_value": 0.874
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.826,
                "best_value": 0.826
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.959,
                "best_value": 0.959
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.87,
                "best_value": 0.87
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.813,
                "best_value": 0.813
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.949,
                "best_value": 0.949
              }
            ]
          },
          {
            "metric_name": "validation accuracy",
            "lower_is_better": false,
            "description": "Accuracy on validation set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.826,
                "best_value": 0.826
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.884,
                "best_value": 0.884
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.844,
                "best_value": 0.844
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.97,
                "best_value": 0.97
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.876,
                "best_value": 0.876
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.81,
                "best_value": 0.81
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.964,
                "best_value": 0.964
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.882,
                "best_value": 0.882
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.792,
                "best_value": 0.792
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.94,
                "best_value": 0.94
              }
            ]
          },
          {
            "metric_name": "train loss",
            "lower_is_better": true,
            "description": "Loss on training set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.3797,
                "best_value": 0.3797
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.3817,
                "best_value": 0.3817
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.3125,
                "best_value": 0.3125
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.3905,
                "best_value": 0.3905
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.4024,
                "best_value": 0.4024
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.3137,
                "best_value": 0.3137
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.4055,
                "best_value": 0.4055
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.4365,
                "best_value": 0.4365
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.3475,
                "best_value": 0.3475
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Loss on validation set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.366,
                "best_value": 0.366
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.3901,
                "best_value": 0.3901
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.2426,
                "best_value": 0.2426
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.352,
                "best_value": 0.352
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.412,
                "best_value": 0.412
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.2362,
                "best_value": 0.2362
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.3617,
                "best_value": 0.3617
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.4453,
                "best_value": 0.4453
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.2835,
                "best_value": 0.2835
              }
            ]
          },
          {
            "metric_name": "train alignment",
            "lower_is_better": false,
            "description": "Alignment on training set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.9959,
                "best_value": 0.9959
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.9992,
                "best_value": 0.9992
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.9997,
                "best_value": 0.9997
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.9959,
                "best_value": 0.9959
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.9997,
                "best_value": 0.9997
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.9961,
                "best_value": 0.9961
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Alignment on validation set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.9964,
                "best_value": 0.9964
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.9997,
                "best_value": 0.9997
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.9969,
                "best_value": 0.9969
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.9997,
                "best_value": 0.9997
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.9969,
                "best_value": 0.9969
              }
            ]
          },
          {
            "metric_name": "validation MAI",
            "lower_is_better": false,
            "description": "MAI on validation set",
            "data": [
              {
                "dataset_name": "ag_news (ablation: token_dropout_0)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_0)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_0)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_10)",
                "final_value": 0.9383,
                "best_value": 0.9383
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_10)",
                "final_value": 0.9151,
                "best_value": 0.9151
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_10)",
                "final_value": 0.983,
                "best_value": 0.983
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_20)",
                "final_value": 0.9337,
                "best_value": 0.9337
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_20)",
                "final_value": 0.8949,
                "best_value": 0.8949
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_20)",
                "final_value": 0.9802,
                "best_value": 0.9802
              },
              {
                "dataset_name": "ag_news (ablation: token_dropout_30)",
                "final_value": 0.9372,
                "best_value": 0.9372
              },
              {
                "dataset_name": "yelp_polarity (ablation: token_dropout_30)",
                "final_value": 0.8838,
                "best_value": 0.8838
              },
              {
                "dataset_name": "dbpedia_14 (ablation: token_dropout_30)",
                "final_value": 0.9676,
                "best_value": 0.9676
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# setup working directory and seeds\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# load tokenizer and frozen DistilBERT\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# simple MLP head\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# token dropout helper (masks tokens with [MASK])\ndef apply_token_dropout(input_ids, attention_mask, drop_rate):\n    if drop_rate <= 0:\n        return input_ids, attention_mask\n    mask = torch.rand(input_ids.shape, device=input_ids.device) < drop_rate\n    mask &= attention_mask.bool()\n    mask[:, 0] = False  # never mask [CLS]\n    dropped = input_ids.clone()\n    dropped[mask] = tokenizer.mask_token_id\n    return dropped, attention_mask\n\n\n# ablation rates and datasets\nablation_rates = [0.0, 0.1, 0.2, 0.3]\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nexperiment_data = {}\n\nfor drop in ablation_rates:\n    key = f\"token_dropout_{int(drop*100)}\"\n    experiment_data[key] = {}\n    for name in datasets:\n        # load and tokenize\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n\n        # initialize models and optimizers\n        num_labels = len(set(train_ds[\"label\"]))\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n        optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n        loss_fn = nn.CrossEntropyLoss()\n\n        # storage for this dataset & ablation\n        data = {\n            \"metrics\": {\"train\": [], \"val\": []},  # classification accuracies\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],  # val MAI per epoch\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # training loop\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_acc = n_samples = 0.0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                ids, att = apply_token_dropout(\n                    batch[\"input_ids\"], batch[\"attention_mask\"], drop\n                )\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=ids, attention_mask=att\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                optimizer_ai.zero_grad()\n                loss_ai.backward()\n                optimizer_ai.step()\n                optimizer_user.zero_grad()\n                loss_user.backward()\n                optimizer_user.step()\n\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (\n                    (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n                )\n                n_samples += bs\n\n            loss_train = tot_loss / len(train_ds)\n            align_train = tot_align / n_samples\n            acc_train = tot_acc / n_samples\n            data[\"losses\"][\"train\"].append(loss_train)\n            data[\"alignments\"][\"train\"].append(align_train)\n            data[\"metrics\"][\"train\"].append(acc_train)\n\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0.0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    ids, att = apply_token_dropout(\n                        batch[\"input_ids\"], batch[\"attention_mask\"], drop\n                    )\n                    emb = distilbert(\n                        input_ids=ids, attention_mask=att\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                        \"label\"\n                    ].size(0)\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += batch[\"label\"].size(0)\n\n            loss_val = v_loss / len(val_ds)\n            align_val = v_align / v_n\n            acc_val = v_acc / v_n\n            mai_val = 2 * (align_val * acc_val) / (align_val + acc_val + 1e-8)\n            data[\"losses\"][\"val\"].append(loss_val)\n            data[\"alignments\"][\"val\"].append(align_val)\n            data[\"metrics\"][\"val\"].append(acc_val)\n            data[\"mai\"].append(mai_val)\n\n            print(\n                f\"{key} {name} Epoch {epoch}: val_loss={loss_val:.4f}, \"\n                f\"val_acc={acc_val:.4f}, val_align={align_val:.4f}, MAI={mai_val:.4f}\"\n            )\n\n        # final predictions & ground truth\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                ids, att = apply_token_dropout(\n                    batch[\"input_ids\"], batch[\"attention_mask\"], drop\n                )\n                emb = distilbert(input_ids=ids, attention_mask=att).last_hidden_state[\n                    :, 0, :\n                ]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        data[\"predictions\"] = np.concatenate(preds)\n        data[\"ground_truth\"] = np.concatenate(gts)\n        experiment_data[key][name] = data\n\n# save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    experiment_data = {}\n\n# get sorted dropout keys and dataset names\ndrop_keys = sorted(experiment_data.keys(), key=lambda x: int(x.split(\"_\")[-1]))\ndataset_names = list(experiment_data[drop_keys[0]].keys()) if drop_keys else []\n\n# plot accuracy curves per dataset\nfor ds in dataset_names:\n    try:\n        plt.figure()\n        for key in drop_keys:\n            rate = int(key.split(\"_\")[-1])\n            acc_tr = experiment_data[key][ds][\"metrics\"][\"train\"]\n            acc_val = experiment_data[key][ds][\"metrics\"][\"val\"]\n            epochs = np.arange(1, len(acc_tr) + 1)\n            plt.plot(epochs, acc_tr, label=f\"Train {rate}% dropout\")\n            plt.plot(epochs, acc_val, \"--\", label=f\"Val {rate}% dropout\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Accuracy\")\n        plt.title(\n            f'{ds.replace(\"_\",\" \").title()} Classification\\nTrain (solid) vs Val (dashed) Accuracy'\n        )\n        plt.legend()\n        fname = f\"{ds}_accuracy_curves.png\"\n        plt.savefig(os.path.join(working_dir, fname))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating accuracy plot for {ds}: {e}\")\n        plt.close()\n\n# plot MAI vs dropout rate for all datasets\ntry:\n    plt.figure()\n    rates = [int(k.split(\"_\")[-1]) for k in drop_keys]\n    for ds in dataset_names:\n        mai_vals = [experiment_data[k][ds][\"mai\"][-1] for k in drop_keys]\n        plt.plot(rates, mai_vals, marker=\"o\", label=ds)\n    plt.xlabel(\"Token Dropout Rate (%)\")\n    plt.ylabel(\"Final Epoch MAI\")\n    plt.title(\"MAI vs Token Dropout Rate\\nFinal Epoch MAI for Each Dataset\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"mai_vs_dropout_rate.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MAI vs dropout plot: {e}\")\n    plt.close()\n",
    "plot_plan": "The solution first loads the saved experiment data from the working directory. It then identifies all token-dropout variants and dataset names. For each dataset, it plots training versus validation accuracy curves across epochs for every dropout rate, using solid lines for training and dashed for validation. Each plot is wrapped in try-except to handle errors and always closes the figure. Finally, it generates a combined MAI versus dropout rate plot across all datasets using the final epoch\u2019s MAI, again with error handling and figure cleanup. All figures are titled with dataset information and saved under descriptive filenames in the working directory.",
    "plot_analyses": [
      {
        "analysis": "Yelp Polarity Classification\nTrain accuracy for models with 0% and 10% dropout jumps sharply between epoch 1 and 2, reaching ~0.85 and ~0.82 respectively by epoch 2, then modestly increasing by epoch 3. Validation accuracy for 0% and 10% dropout remains around 0.82\u20130.83 throughout, indicating fast convergence but a small generalization gap. Higher dropout rates (20% and 30%) show slower training (starting below 0.60 at epoch 1) and lower final validation (\u22480.81 and \u22480.79), though they close the gap by epoch 3. Overall, minimal or no token dropout yields the best validation performance and fastest convergence; heavier dropout hurts both training speed and final accuracy on this sentiment task.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/yelp_polarity_accuracy_curves.png"
      },
      {
        "analysis": "Dbpedia 14 Classification\nAt epoch 1, models with no dropout already achieve ~0.68 train vs ~0.92 val, while 10% dropout underfits heavily (0.40 train / 0.75 val). By epoch 2, all variants converge to high performance: no dropout and 10% reach ~0.96 train & val, 20% about 0.92/0.94, 30% about 0.90/0.93. Epoch 3 yields marginal gains. This suggests that for this large taxonomy task, even moderate dropout slows early learning but by epoch 2 the network recovers. No or low dropout is optimal for peak accuracy; higher rates incur a slight persistent penalty on both train and val.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/dbpedia_14_accuracy_curves.png"
      },
      {
        "analysis": "Ag News Classification\nAll models start with moderate underfitting at epoch 1 (train 0.62\u20130.67, val 0.86\u20130.89). 10% dropout leads to the highest initial validation (~0.89). By epoch 2 and 3, 0% and 10% dropout both converge to ~0.87\u20130.88 validation, with training above 0.86. Higher dropout (20%, 30%) starts lower and remains marginally behind through epoch 3. The validation curves are relatively flat after epoch 1, indicating early convergence. A small amount of token dropout can speed generalization early, but beyond 10% it offers no added benefit and slightly degrades final accuracy.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/ag_news_accuracy_curves.png"
      },
      {
        "analysis": "MAI vs Token Dropout Rate \u2013 Final Epoch MAI\nAlignment Index (MAI) decreases as token dropout increases. For ag_news, MAI falls from ~0.943 (0%) to ~0.933 (20%) then slightly recovers to ~0.937 (30%). Yelp polarity peaks at 10% dropout (0.915) before declining to 0.883 at 30%. Dbpedia declines steadily from ~0.985 (0%) to ~0.967 (30%). These trends show that injecting token-level noise generally disrupts the learned alignment between user and model representations. A small dropout rate (\u224810%) can occasionally offer negligible MAI improvement in smaller tasks, but higher rates consistently reduce bidirectional alignment.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/mai_vs_dropout_rate.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/yelp_polarity_accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/dbpedia_14_accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/ag_news_accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/mai_vs_dropout_rate.png"
    ],
    "vlm_feedback_summary": "Low or zero token dropout consistently yields the fastest convergence, highest classification accuracy, and strongest mental alignment (MAI) across all three datasets. Small dropout rates (around 10%) may offer slight early regularization but do not improve final metrics and can harm bidirectional mental-model alignment when applied beyond minimal levels. The ablation underscores that token dropout as a regularizer must be used sparingly in a co-adaptive alignment framework to avoid degrading both performance and mutual understanding.",
    "exp_results_dir": "experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278",
    "ablation_name": "Token Dropout Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_ec7d598449024b57a51ff39af928139d_proc_4081278/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: Optimizer Choice Ablation.\nWe will loop over three optimizers (Adam, SGD with momentum, AdamW) as our ablation variations, and for each dataset (AG News, Yelp Polarity, DBpedia) we reinitialize the MLP models, train for three epochs on frozen DistilBERT embeddings, and record training/validation losses, alignment (via JS divergence), user accuracy, and MAI. After training, we collect AI model predictions and ground truths on the validation set. All metrics are stored in a nested experiment_data dictionary keyed by optimizer and dataset, then saved to \"experiment_data.npy\" under a \"working\" folder.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "train loss",
            "lower_is_better": true,
            "description": "Training set loss",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 1.13,
                "best_value": 1.13
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.6519,
                "best_value": 0.6519
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 2.3955,
                "best_value": 2.3955
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.3577,
                "best_value": 0.3577
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.3221,
                "best_value": 0.3221
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.2191,
                "best_value": 0.2191
              }
            ]
          },
          {
            "metric_name": "train alignment",
            "lower_is_better": false,
            "description": "Training set alignment metric",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 0.9991,
                "best_value": 0.9991
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 0.9953,
                "best_value": 0.9953
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.9994,
                "best_value": 0.9994
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.9989,
                "best_value": 0.9989
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.9957,
                "best_value": 0.9957
              }
            ]
          },
          {
            "metric_name": "train accuracy",
            "lower_is_better": false,
            "description": "Training set accuracy",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.878,
                "best_value": 0.878
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.8635,
                "best_value": 0.8635
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.9785,
                "best_value": 0.9785
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 0.629,
                "best_value": 0.629
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.668,
                "best_value": 0.668
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 0.3,
                "best_value": 0.3
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.88,
                "best_value": 0.88
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.859,
                "best_value": 0.859
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.978,
                "best_value": 0.978
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Validation set loss",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 1.0416,
                "best_value": 1.0416
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.6379,
                "best_value": 0.6379
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 2.3031,
                "best_value": 2.3031
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.3395,
                "best_value": 0.3395
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.3548,
                "best_value": 0.3548
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.1857,
                "best_value": 0.1857
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Validation set alignment metric",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 0.9989,
                "best_value": 0.9989
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 0.9957,
                "best_value": 0.9957
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.9987,
                "best_value": 0.9987
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.9965,
                "best_value": 0.9965
              }
            ]
          },
          {
            "metric_name": "validation accuracy",
            "lower_is_better": false,
            "description": "Validation set accuracy",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.826,
                "best_value": 0.826
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.974,
                "best_value": 0.974
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 0.72,
                "best_value": 0.72
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.81,
                "best_value": 0.81
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 0.438,
                "best_value": 0.438
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.904,
                "best_value": 0.904
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.852,
                "best_value": 0.852
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.974,
                "best_value": 0.974
              }
            ]
          },
          {
            "metric_name": "validation MAI",
            "lower_is_better": false,
            "description": "Validation set MAI metric",
            "data": [
              {
                "dataset_name": "ag_news (adam)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (adam)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (adam)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (sgd)",
                "final_value": 0.8368,
                "best_value": 0.8368
              },
              {
                "dataset_name": "yelp_polarity (sgd)",
                "final_value": 0.895,
                "best_value": 0.895
              },
              {
                "dataset_name": "dbpedia_14 (sgd)",
                "final_value": 0.6084,
                "best_value": 0.6084
              },
              {
                "dataset_name": "ag_news (adamw)",
                "final_value": 0.9494,
                "best_value": 0.9494
              },
              {
                "dataset_name": "yelp_polarity (adamw)",
                "final_value": 0.9195,
                "best_value": 0.9195
              },
              {
                "dataset_name": "dbpedia_14 (adamw)",
                "final_value": 0.9851,
                "best_value": 0.9851
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# Setup\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Frozen encoder\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# Ablation: optimizer choices\noptimizers = {\n    \"adam\": lambda params: torch.optim.Adam(params, lr=1e-3),\n    \"sgd\": lambda params: torch.optim.SGD(params, lr=1e-3, momentum=0.9),\n    \"adamw\": lambda params: torch.optim.AdamW(params, lr=1e-3),\n}\n\ndatasets_list = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nloss_fn = nn.CrossEntropyLoss()\nexperiment_data = {}\n\nfor opt_name, opt_fn in optimizers.items():\n    experiment_data[opt_name] = {}\n    for name in datasets_list:\n        # Load and preprocess\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tokenize_fn(batch):\n            return tokenizer(\n                batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n\n        # Storage\n        experiment_data[opt_name][name] = {\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"accuracy\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n\n        # Models and optimizers\n        num_labels = len(set(train_ds[\"label\"]))\n        ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n        optimizer_ai = opt_fn(ai_model.parameters())\n        optimizer_user = opt_fn(user_model.parameters())\n\n        # Train epochs\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_acc = n = 0.0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                optimizer_ai.zero_grad()\n                loss_ai.backward()\n                optimizer_ai.step()\n                optimizer_user.zero_grad()\n                loss_user.backward()\n                optimizer_user.step()\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (\n                    (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n                )\n                n += bs\n            train_loss = tot_loss / len(train_ds)\n            train_align = tot_align / n\n            train_acc = tot_acc / n\n            experiment_data[opt_name][name][\"losses\"][\"train\"].append(train_loss)\n            experiment_data[opt_name][name][\"alignments\"][\"train\"].append(train_align)\n            experiment_data[opt_name][name][\"accuracy\"][\"train\"].append(train_acc)\n\n            # Validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0.0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    logits_user = user_model(emb)\n                    bs = batch[\"label\"].size(0)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * bs\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(logits_user, dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(logits_user, dim=1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += bs\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            experiment_data[opt_name][name][\"losses\"][\"val\"].append(val_loss)\n            experiment_data[opt_name][name][\"alignments\"][\"val\"].append(val_align)\n            experiment_data[opt_name][name][\"accuracy\"][\"val\"].append(val_acc)\n            experiment_data[opt_name][name][\"mai\"].append(mai)\n            print(\n                f\"Opt {opt_name} | {name} | Epoch {epoch} | val_loss={val_loss:.4f} val_align={val_align:.4f} val_acc={val_acc:.4f} MAI={mai:.4f}\"\n            )\n\n        # Collect predictions\n        preds, gts = [], []\n        ai_model.eval()\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        experiment_data[opt_name][name][\"predictions\"] = np.concatenate(preds)\n        experiment_data[opt_name][name][\"ground_truth\"] = np.concatenate(gts)\n\n# Save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\noptimizers = list(experiment_data.keys())\ndatasets = list(experiment_data[optimizers[0]].keys())\n\n# Plot loss curves\ntry:\n    plt.figure(figsize=(12, 4))\n    for i, ds in enumerate(datasets):\n        ax = plt.subplot(1, len(datasets), i + 1)\n        for opt in optimizers:\n            epochs = np.arange(1, len(experiment_data[opt][ds][\"losses\"][\"train\"]) + 1)\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"losses\"][\"train\"],\n                linestyle=\"-\",\n                label=f\"{opt} Train\",\n            )\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"losses\"][\"val\"],\n                linestyle=\"--\",\n                label=f\"{opt} Val\",\n            )\n        ax.set_title(f\"{ds} Dataset\")\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"Loss\")\n        ax.legend()\n    plt.suptitle(\"Loss Curves Across Datasets\\nSolid: Train, Dashed: Val\")\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.savefig(os.path.join(working_dir, \"loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves: {e}\")\n    plt.close()\n\n# Plot accuracy curves\ntry:\n    plt.figure(figsize=(12, 4))\n    for i, ds in enumerate(datasets):\n        ax = plt.subplot(1, len(datasets), i + 1)\n        for opt in optimizers:\n            epochs = np.arange(\n                1, len(experiment_data[opt][ds][\"accuracy\"][\"train\"]) + 1\n            )\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"accuracy\"][\"train\"],\n                linestyle=\"-\",\n                label=f\"{opt} Train\",\n            )\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"accuracy\"][\"val\"],\n                linestyle=\"--\",\n                label=f\"{opt} Val\",\n            )\n        ax.set_title(f\"{ds} Dataset\")\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"Accuracy\")\n        ax.legend()\n    plt.suptitle(\"Accuracy Curves Across Datasets\\nSolid: Train, Dashed: Val\")\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.savefig(os.path.join(working_dir, \"accuracy_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy curves: {e}\")\n    plt.close()\n\n# Plot alignment curves\ntry:\n    plt.figure(figsize=(12, 4))\n    for i, ds in enumerate(datasets):\n        ax = plt.subplot(1, len(datasets), i + 1)\n        for opt in optimizers:\n            epochs = np.arange(\n                1, len(experiment_data[opt][ds][\"alignments\"][\"train\"]) + 1\n            )\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"alignments\"][\"train\"],\n                linestyle=\"-\",\n                label=f\"{opt} Train\",\n            )\n            ax.plot(\n                epochs,\n                experiment_data[opt][ds][\"alignments\"][\"val\"],\n                linestyle=\"--\",\n                label=f\"{opt} Val\",\n            )\n        ax.set_title(f\"{ds} Dataset\")\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"Alignment\")\n        ax.legend()\n    plt.suptitle(\"Alignment Curves Across Datasets\\nSolid: Train, Dashed: Val\")\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.savefig(os.path.join(working_dir, \"alignment_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating alignment curves: {e}\")\n    plt.close()\n\n# Plot MAI curves\ntry:\n    plt.figure(figsize=(12, 4))\n    for i, ds in enumerate(datasets):\n        ax = plt.subplot(1, len(datasets), i + 1)\n        for opt in optimizers:\n            epochs = np.arange(1, len(experiment_data[opt][ds][\"mai\"]) + 1)\n            ax.plot(epochs, experiment_data[opt][ds][\"mai\"], label=f\"{opt}\")\n        ax.set_title(f\"{ds} Dataset\")\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(\"MAI\")\n        ax.legend()\n    plt.suptitle(\"MAI Across Datasets\")\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.savefig(os.path.join(working_dir, \"mai_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MAI curves: {e}\")\n    plt.close()\n",
    "plot_plan": "Here\u2019s a sketch of the solution:  \n1. Load the saved `experiment_data.npy` from the working directory.  \n2. Extract the list of optimizers and datasets contained in the data.  \n3. In separate try\u2013except blocks, create and save a figure of loss curves: a 1\u00d73 grid of subplots (one per dataset), plotting solid lines for training loss and dashed for validation loss, with subplot titles naming each dataset and a clear suptitle.  \n4. Repeat similarly for accuracy and alignment curves, saving each as its own PNG.  \n5. Finally, plot MAI across epochs in a 1\u00d73 subplot figure, with each optimizer\u2019s MAI curve per dataset, appropriate legends, titles, and save the figure.  \n6. Always close figures after saving and catch any exceptions to avoid crashing.",
    "plot_analyses": [
      {
        "analysis": "Loss trajectories reinforce these findings: on ag_news and yelp_polarity, Adam and AdamW drop loss from ~2.0 and ~1.9 to ~0.3\u20130.4 in two epochs, while SGD only falls from ~5.2 and ~4.0 to ~1.2 and ~0.7. On dbpedia_14, Adam/AdamW reduce loss from ~2.7\u20132.8 to ~0.2\u20130.4, whereas SGD remains above ~2.8. The marginally lower validation loss of AdamW vs. Adam at epoch 3 underscores the regularizing influence of weight decay.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/accuracy_curves.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/accuracy_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/mai_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/loss_curves.png"
    ],
    "vlm_feedback_summary": "Adaptive optimizers (Adam, AdamW) consistently enable faster convergence, higher accuracy, stronger mental\u2010model alignment, and lower loss than SGD across all datasets. Incorporating weight decay (AdamW) yields slight but consistent improvements in validation metrics and generalization, underscoring its value in co\u2010adaptive human\u2013AI alignment systems.",
    "exp_results_dir": "experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279",
    "ablation_name": "Optimizer Choice Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_8b1e5415f46b4fd4a24eeaf1ff52ebec_proc_4081279/experiment_data.npy"
    ]
  },
  {
    "overall_plan": "Ablation name: MLP Parameter Sharing Ablation.\nHere is a sketch of the implementation: we loop over three ablation conditions\u2014independent MLPs, sharing only fc1, and fully shared\u2014creating models and optimizers appropriately, then run the same training/validation procedure while recording losses, alignment, MAI, and final predictions. We store everything in a nested `experiment_data` dict and save it once at the end.",
    "analysis": "",
    "metric": {
      "value": {
        "metric_names": [
          {
            "metric_name": "training loss",
            "lower_is_better": true,
            "description": "Final training loss",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.3672,
                "best_value": 0.3672
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.3435,
                "best_value": 0.3435
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.2103,
                "best_value": 0.2103
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.3825,
                "best_value": 0.3825
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.3648,
                "best_value": 0.3648
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.2793,
                "best_value": 0.2793
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 0.3595,
                "best_value": 0.3595
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 0.3505,
                "best_value": 0.3505
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 0.2265,
                "best_value": 0.2265
              }
            ]
          },
          {
            "metric_name": "training alignment",
            "lower_is_better": false,
            "description": "Final training alignment",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.9993,
                "best_value": 0.9993
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.9971,
                "best_value": 0.9971
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.9987,
                "best_value": 0.9987
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.9996,
                "best_value": 0.9996
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.9965,
                "best_value": 0.9965
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              }
            ]
          },
          {
            "metric_name": "validation loss",
            "lower_is_better": true,
            "description": "Final validation loss",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.3472,
                "best_value": 0.3472
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.3789,
                "best_value": 0.3789
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.1728,
                "best_value": 0.1728
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.3568,
                "best_value": 0.3568
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.3651,
                "best_value": 0.3651
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.2299,
                "best_value": 0.2299
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 0.3451,
                "best_value": 0.3451
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 0.3574,
                "best_value": 0.3574
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 0.1876,
                "best_value": 0.1876
              }
            ]
          },
          {
            "metric_name": "validation alignment",
            "lower_is_better": false,
            "description": "Final validation alignment",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.9995,
                "best_value": 0.9995
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.9999,
                "best_value": 0.9999
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.9978,
                "best_value": 0.9978
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.9991,
                "best_value": 0.9991
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.9998,
                "best_value": 0.9998
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.9975,
                "best_value": 0.9975
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 1.0,
                "best_value": 1.0
              }
            ]
          },
          {
            "metric_name": "MAI",
            "lower_is_better": false,
            "description": "Final MAI",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.9427,
                "best_value": 0.9427
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.9047,
                "best_value": 0.9047
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.9858,
                "best_value": 0.9858
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.9403,
                "best_value": 0.9403
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.9246,
                "best_value": 0.9246
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.9835,
                "best_value": 0.9835
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 0.9418,
                "best_value": 0.9418
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 0.9189,
                "best_value": 0.9189
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 0.9858,
                "best_value": 0.9858
              }
            ]
          },
          {
            "metric_name": "test accuracy",
            "lower_is_better": false,
            "description": "Final test accuracy",
            "data": [
              {
                "dataset_name": "ag_news (independent)",
                "final_value": 0.892,
                "best_value": 0.892
              },
              {
                "dataset_name": "yelp_polarity (independent)",
                "final_value": 0.824,
                "best_value": 0.824
              },
              {
                "dataset_name": "dbpedia_14 (independent)",
                "final_value": 0.972,
                "best_value": 0.972
              },
              {
                "dataset_name": "ag_news (shared_fc1)",
                "final_value": 0.882,
                "best_value": 0.882
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1)",
                "final_value": 0.852,
                "best_value": 0.852
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1)",
                "final_value": 0.966,
                "best_value": 0.966
              },
              {
                "dataset_name": "ag_news (shared_fc1_fc2)",
                "final_value": 0.89,
                "best_value": 0.89
              },
              {
                "dataset_name": "yelp_polarity (shared_fc1_fc2)",
                "final_value": 0.85,
                "best_value": 0.85
              },
              {
                "dataset_name": "dbpedia_14 (shared_fc1_fc2)",
                "final_value": 0.972,
                "best_value": 0.972
              }
            ]
          }
        ]
      },
      "maximize": null,
      "name": null,
      "description": null
    },
    "code": "import os\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\n# setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\nnp.random.seed(42)\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# model classes\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\nclass MLPShared1(nn.Module):\n    def __init__(self, shared_fc1, fc2):\n        super().__init__()\n        self.fc1 = shared_fc1\n        self.fc2 = fc2\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\n# settings\ndatasets = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\nablations = [\"independent\", \"shared_fc1\", \"shared_fc1_fc2\"]\nexperiment_data = {a: {} for a in ablations}\nloss_fn = nn.CrossEntropyLoss()\n\nfor ablation in ablations:\n    for name in datasets:\n        # prepare data\n        raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n        split = raw.train_test_split(test_size=0.2, seed=0)\n        train_ds, val_ds = split[\"train\"], split[\"test\"]\n        text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n        def tok(b):\n            return tokenizer(\n                b[text_key], padding=\"max_length\", truncation=True, max_length=128\n            )\n\n        train_ds = train_ds.map(tok, batched=True, remove_columns=[text_key])\n        val_ds = val_ds.map(tok, batched=True, remove_columns=[text_key])\n        train_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        val_ds.set_format(\n            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n        )\n        train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        num_labels = len(set(train_ds[\"label\"]))\n        # build models & optimizers\n        in_dim, hid_dim, out_dim = distilbert.config.hidden_size, 128, num_labels\n        if ablation == \"independent\":\n            ai_model = MLP(in_dim, hid_dim, out_dim).to(device)\n            user_model = MLP(in_dim, hid_dim, out_dim).to(device)\n            opt_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n            opt_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n            optimizer = None\n        elif ablation == \"shared_fc1\":\n            shared_fc1 = nn.Linear(in_dim, hid_dim).to(device)\n            ai_fc2 = nn.Linear(hid_dim, out_dim).to(device)\n            user_fc2 = nn.Linear(hid_dim, out_dim).to(device)\n            ai_model = MLPShared1(shared_fc1, ai_fc2).to(device)\n            user_model = MLPShared1(shared_fc1, user_fc2).to(device)\n            optimizer = torch.optim.Adam(\n                list(shared_fc1.parameters())\n                + list(ai_fc2.parameters())\n                + list(user_fc2.parameters()),\n                lr=1e-3,\n            )\n        else:  # fully shared\n            shared = MLP(in_dim, hid_dim, out_dim).to(device)\n            ai_model, user_model = shared, shared\n            optimizer = torch.optim.Adam(shared.parameters(), lr=1e-3)\n        # init logs\n        ed = {\n            \"losses\": {\"train\": [], \"val\": []},\n            \"alignments\": {\"train\": [], \"val\": []},\n            \"mai\": [],\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n        # train & validate\n        for epoch in range(1, 4):\n            ai_model.train()\n            user_model.train()\n            tot_loss = tot_align = tot_acc = n = 0\n            for batch in train_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                with torch.no_grad():\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                logits_user = user_model(emb)\n                loss_ai = loss_fn(logits_ai, batch[\"label\"])\n                loss_user = loss_fn(logits_user, batch[\"label\"])\n                # update\n                if ablation == \"independent\":\n                    opt_ai.zero_grad()\n                    loss_ai.backward()\n                    opt_ai.step()\n                    opt_user.zero_grad()\n                    loss_user.backward()\n                    opt_user.step()\n                else:\n                    optimizer.zero_grad()\n                    (loss_ai + loss_user).backward()\n                    optimizer.step()\n                # metrics\n                bs = batch[\"label\"].size(0)\n                tot_loss += loss_ai.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                tot_align += torch.sum(1 - jsd).item()\n                tot_acc += (torch.argmax(logits_user, 1) == batch[\"label\"]).sum().item()\n                n += bs\n            ed[\"losses\"][\"train\"].append(tot_loss / len(train_ds))\n            ed[\"alignments\"][\"train\"].append(tot_align / n)\n            # validation\n            ai_model.eval()\n            user_model.eval()\n            v_loss = v_align = v_acc = v_n = 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = {k: v.to(device) for k, v in batch.items()}\n                    emb = distilbert(\n                        input_ids=batch[\"input_ids\"],\n                        attention_mask=batch[\"attention_mask\"],\n                    ).last_hidden_state[:, 0, :]\n                    logits_ai = ai_model(emb)\n                    bs = batch[\"label\"].size(0)\n                    v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * bs\n                    P = F.softmax(logits_ai, dim=1)\n                    Q = F.softmax(user_model(emb), dim=1)\n                    M = 0.5 * (P + Q)\n                    kl1 = torch.sum(\n                        P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    kl2 = torch.sum(\n                        Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1\n                    )\n                    jsd = 0.5 * (kl1 + kl2)\n                    v_align += torch.sum(1 - jsd).item()\n                    v_acc += (\n                        (torch.argmax(user_model(emb), 1) == batch[\"label\"])\n                        .sum()\n                        .item()\n                    )\n                    v_n += bs\n            val_loss = v_loss / len(val_ds)\n            val_align = v_align / v_n\n            val_acc = v_acc / v_n\n            mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n            ed[\"losses\"][\"val\"].append(val_loss)\n            ed[\"alignments\"][\"val\"].append(val_align)\n            ed[\"mai\"].append(mai)\n            print(\n                f\"Ablation {ablation} Dataset {name} Epoch {epoch}: \"\n                f\"validation_loss={val_loss:.4f}, MAI={mai:.4f}\"\n            )\n        # final preds\n        ai_model.eval()\n        preds, gts = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                preds.append(torch.argmax(ai_model(emb), 1).cpu().numpy())\n                gts.append(batch[\"label\"].cpu().numpy())\n        ed[\"predictions\"] = np.concatenate(preds)\n        ed[\"ground_truth\"] = np.concatenate(gts)\n        experiment_data[ablation][name] = ed\n\n# save\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n",
    "plot_code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\nelse:\n    for ablation, ds_dict in experiment_data.items():\n        for dataset_name, ed in ds_dict.items():\n            epochs = list(range(1, len(ed[\"losses\"][\"train\"]) + 1))\n            try:\n                plt.figure()\n                plt.plot(epochs, ed[\"losses\"][\"train\"], label=\"Train Loss\")\n                plt.plot(epochs, ed[\"losses\"][\"val\"], label=\"Validation Loss\")\n                plt.title(\n                    f\"Dataset {dataset_name} - Ablation {ablation}: Loss Curves\\n\"\n                    \"Train vs Validation Loss\"\n                )\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Loss\")\n                plt.legend()\n                fname = f\"{dataset_name}_{ablation}_loss_curves.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n            except Exception as e:\n                print(f\"Error creating loss plot for {dataset_name} {ablation}: {e}\")\n                plt.close()\n            try:\n                plt.figure()\n                plt.plot(epochs, ed[\"alignments\"][\"train\"], label=\"Train Alignment\")\n                plt.plot(epochs, ed[\"alignments\"][\"val\"], label=\"Validation Alignment\")\n                plt.title(\n                    f\"Dataset {dataset_name} - Ablation {ablation}: Alignment Curves\\n\"\n                    \"Train vs Validation Alignment\"\n                )\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"Alignment\")\n                plt.legend()\n                fname = f\"{dataset_name}_{ablation}_alignment_curves.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n            except Exception as e:\n                print(\n                    f\"Error creating alignment plot for {dataset_name} {ablation}: {e}\"\n                )\n                plt.close()\n            try:\n                plt.figure()\n                plt.plot(epochs, ed[\"mai\"], marker=\"o\")\n                plt.title(\n                    f\"Dataset {dataset_name} - Ablation {ablation}: MAI over Epochs\\n\"\n                    \"Validation MAI\"\n                )\n                plt.xlabel(\"Epoch\")\n                plt.ylabel(\"MAI\")\n                fname = f\"{dataset_name}_{ablation}_mai.png\"\n                plt.savefig(os.path.join(working_dir, fname))\n                plt.close()\n            except Exception as e:\n                print(f\"Error creating MAI plot for {dataset_name} {ablation}: {e}\")\n                plt.close()\n",
    "plot_plan": "Our solution will load the saved experiment_data.npy from the working directory. Then we loop over each ablation setting and dataset, extracting the logged losses, alignments, and MAI metrics. We will create three standard plots per combination: loss curves (train vs validation), alignment curves (train vs validation), and the MAI over epochs. Each plot will be generated in its own try-except block to catch errors and ensure the figure closes properly even on exceptions. We will use basic matplotlib plotting without custom styles, labeling axes, legends, and using a two-line title to specify dataset, ablation, and subtitle (e.g., 'Train vs Validation Loss'). Saved file names will include the dataset name, ablation, and plot type for clarity (e.g., ag_news_independent_loss.png). All plots will be saved in the working directory. Finally, we ensure no more than five similar figures are generated per category (which is met since we have only three epochs).",
    "plot_analyses": [
      {
        "analysis": "Dataset ag_news \u2014 Ablation independent: Alignment curves show that train alignment starts at about 0.968 in epoch 1, jumps to 0.998 by epoch 2, and plateaus near 0.999 at epoch 3. Validation alignment begins high (\u22480.997) and steadily climbs to 0.999 by epoch 3. The small gap between train and validation at epoch 1 closes rapidly, indicating fast convergence and minimal overfitting in this independent\u2010component setup.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_alignment_curves.png"
      },
      {
        "analysis": "Dataset yelp_polarity \u2014 Ablation independent: Train alignment rises from roughly 0.956 at epoch 1 to virtually 1.000 by epoch 2, and remains flat thereafter. Validation alignment moves from 0.998 at epoch 1 to 0.9999+ by epoch 3. This mirrors the ag_news behavior: an initial gap at epoch 1 that disappears by epoch 2, confirming that the independent configuration achieves almost perfect alignment within two epochs.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_mai.png"
      },
      {
        "analysis": "Dataset dbpedia_14 \u2014 Ablation independent: Training alignment climbs from about 0.970 at epoch 1 to 0.994 at epoch 2 and 0.997 at epoch 3. Validation follows a similar trajectory (0.990 \u2192 0.996 \u2192 0.998). Again, the independent variant exhibits rapid improvement and strong generalization, with train and validation alignment nearly indistinguishable after epoch 2.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_independent_alignment_curves.png"
      },
      {
        "analysis": "Dataset ag_news \u2014 Ablation shared_fc1_fc2: Both train and validation alignment curves are flat at exactly 1.000 across all three epochs. Such saturation suggests that sharing the two final fully\u2010connected layers forces the alignment metric to max out immediately, preventing any observable dynamics in this measurement.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_independent_alignment_curves.png"
      },
      {
        "analysis": "Dataset yelp_polarity \u2014 Ablation shared_fc1_fc2: As with ag_news, train and validation alignment remain at 1.000 from epoch 1 onward. The lack of variance indicates that the shared\u2010layer design collapses the alignment score to its upper bound, masking any meaningful progression.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_independent_mai.png"
      },
      {
        "analysis": "Dataset dbpedia_14 \u2014 Ablation shared_fc1_fc2: Alignment is constant at 1.000 for both train and validation through epochs 1\u20133. This uniformity confirms that the shared_fc1_fc2 ablation universally saturates the alignment metric across datasets.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_loss_curves.png"
      },
      {
        "analysis": "Dataset ag_news \u2014 Ablation independent: Loss curves show train loss plummeting from 2.08 at epoch 1 to 0.45 at epoch 2 and 0.36 at epoch 3. Validation loss decreases more gradually (0.50 \u2192 0.35 \u2192 0.34). The smooth, parallel declines and small train/validation gap indicate stable learning without overfitting.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_fc2_loss_curves.png"
      },
      {
        "analysis": "Dataset yelp_polarity \u2014 Ablation independent: Train loss drops from 1.81 to 0.40 and then 0.34 over three epochs. Validation loss decreases from 0.47 to 0.38 to 0.37. The consistent downward trends again reflect effective training dynamics and robust generalization in the independent\u2010component variant.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_fc2_alignment_curves.png"
      },
      {
        "analysis": "Dataset dbpedia_14 \u2014 Ablation independent: Starting at 2.70, train loss falls to 0.46 and then 0.19. Validation loss descends from 0.80 to 0.30 to 0.17. These curves confirm that the independent ablation reliably drives loss reduction on both splits, with no signs of divergence.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_independent_loss_curves.png"
      },
      {
        "analysis": "Dataset ag_news \u2014 Ablation shared_fc1_fc2: Validation MAI (mean alignment index) increases steadily from 0.919 at epoch 1 to 0.936 at epoch 2 and 0.942 at epoch 3. Despite the alignment metric saturation seen earlier, MAI reveals ongoing improvement in the shared\u2010layer model\u2019s performance over time.",
        "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_mai.png"
      }
    ],
    "plot_paths": [
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_independent_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_independent_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_independent_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_fc2_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_fc2_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_independent_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_fc2_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_independent_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_fc2_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_fc2_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_independent_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_fc2_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_fc2_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_independent_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_fc2_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_loss_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_independent_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/ag_news_shared_fc1_fc2_mai.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/yelp_polarity_shared_fc1_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_shared_fc1_alignment_curves.png",
      "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/dbpedia_14_independent_loss_curves.png"
    ],
    "vlm_feedback_summary": "Independent\u2010component ablations produce realistic, rapidly converging alignment and loss curves with minimal train/validation gaps, demonstrating both effective learning and generalization. By contrast, shared_fc1_fc2 ablation causes the alignment metric to saturate immediately at its maximum, obscuring the model\u2019s true alignment dynamics. However, the MAI score still rises over epochs under the shared configuration, suggesting that the alignment metric lacks sufficient dynamic range in that setting. Revisiting the alignment scoring function or its scaling when layers are shared is recommended to capture more nuanced progression.",
    "exp_results_dir": "experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280",
    "ablation_name": "MLP Parameter Sharing Ablation",
    "exp_results_npy_files": [
      "experiment_results/experiment_4e9f1eeb3d094f9096032491721f8311_proc_4081280/experiment_data.npy"
    ]
  }
]