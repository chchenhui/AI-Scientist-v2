<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script>
      // Check if we're running under Live Server
      if (window.location.hostname === '127.0.0.1' || window.location.hostname === 'localhost') {
          let lastModified = '';

          // Check for file changes every second
          setInterval(async () => {
              try {
                  const response = await fetch(window.location.href, { method: 'HEAD' });
                  // get a timestamp that shows when the file was last changed
                  const currentModified = response.headers.get('last-modified');

                  if (lastModified && lastModified !== currentModified) {
                      window.location.reload();
                  }

                  lastModified = currentModified;
              } catch (e) {
                  console.error('Error checking for updates:', e);
              }
          }, 1000);
      }
  </script>
    <script
      id="p5scripttag"
      src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"
      integrity="sha512-uaz5GpnQoE6t5echKlX8P52czvsIGgLPcvlzfvRubLZ1Hp8JemUDnbUiAahbVtPb+jUVrNETuXvAhDDF/N3M4w=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>
      const bgCol = "#FFFFFF";
const accentCol = "#1a439e";

hljs.initHighlightingOnLoad();

// Function to update background color globally
function updateBackgroundColor(color) {
  // Update the JS variable
  window.bgColCurrent = color;

  // Update body background
  document.body.style.backgroundColor = color;

  // Update canvas container background
  const canvasContainer = document.getElementById('canvas-container');
  if (canvasContainer) {
    canvasContainer.style.backgroundColor = color;
  }
}

// Store tree data for each stage
const stageData = {
  Stage_1: null,
  Stage_2: null,
  Stage_3: null,
  Stage_4: null
};

// Keep track of current selected stage
let currentStage = null;
let currentSketch = null;
let availableStages = [];

// Class definitions for nodes and edges
class Node {
  constructor(x, y, id, isRoot = false) {
    this.x = x;
    this.y = y;
    this.id = id;
    this.visible = isRoot; // Only root nodes are visible initially
    this.appearProgress = 0;
    this.popEffect = 0;
    this.selected = false;
    this.isRootNode = isRoot;
  }

  update() {
    if (this.visible) {
      // Handle the main appearance animation
      if (this.appearProgress < 1) {
        this.appearProgress += 0.06;

        // When we reach full size, trigger the pop effect
        if (this.appearProgress >= 1) {
          this.appearProgress = 1; // Cap at 1
          this.popEffect = 1; // Start the pop effect
        }
      }

      // Handle the pop effect animation
      if (this.popEffect > 0) {
        this.popEffect -= 0.15; // Control how quickly it shrinks back
        if (this.popEffect < 0) this.popEffect = 0; // Don't go negative
      }
    }
  }

  startAnimation() {
    this.visible = true;
  }

  color() {
    if (this.selected) {
      return accentCol; // Use the global accent color variable for selected node
    }
    return '#4263eb'; // Default blue color
  }

  render(p5) {
    if (this.visible) {
      const popBonus = this.popEffect * 0.1;
      const nodeScale = p5.map(this.appearProgress, 0, 1, 0, 1) + popBonus;
      const alpha = p5.map(this.appearProgress, 0, 1, 0, 255);

      p5.push();
      p5.translate(this.x, this.y);

      // Shadow effect
      p5.noStroke();
      p5.rectMode(p5.CENTER);

      for (let i = 1; i <= 4; i++) {
        p5.fill(0, 0, 0, alpha * 0.06);
        p5.rect(i, i, 30 * nodeScale, 30 * nodeScale, 10);
      }

      // Main square - use node's color with alpha
      let nodeColor = p5.color(this.color());
      nodeColor.setAlpha(alpha);
      p5.fill(nodeColor);
      p5.rect(0, 0, 30 * nodeScale, 30 * nodeScale, 10);

      // Draw checkmark icon if the node is selected
      if (this.selected && this.appearProgress >= 1) {
        p5.stroke(255);
        p5.strokeWeight(2 * nodeScale);
        p5.noFill();
        // Draw checkmark
        p5.beginShape();
        p5.vertex(-8, 0);
        p5.vertex(-3, 5);
        p5.vertex(8, -6);
        p5.endShape();
      }

      p5.pop();
    }
  }

  isMouseOver(p5) {
    return this.visible &&
           p5.mouseX > this.x - 15 &&
           p5.mouseX < this.x + 15 &&
           p5.mouseY > this.y - 15 &&
           p5.mouseY < this.y + 15;
  }

  // Connect this node to a child node
  child(childNode) {
    // Create an edge from this node to the child
    let isLeft = childNode.x < this.x;
    let isRight = childNode.x > this.x;
    let edge = new Edge(this, childNode, isLeft, isRight);
    return edge;
  }
}

class Edge {
  constructor(parent, child, isLeft, isRight) {
    this.parent = parent;
    this.child = child;
    this.isLeft = isLeft;
    this.isRight = isRight;
    this.progress = 0;

    // Calculate the midpoint where branching occurs
    this.midY = parent.y + (child.y - parent.y) * 0.6;

    // Use the actual child x-coordinate
    // This ensures the edge will connect directly to the child node
    this.branchX = child.x;
  }

  update() {
    if (this.parent.visible && this.progress < 1) {
      this.progress += 0.01; // Adjust animation speed
    }
    if (this.progress >= 1) {
      this.child.visible = true;
    }
  }

  color() {
    return this.child.color();
  }

  render(p5) {
    if (!this.parent.visible) return;

    // Calculate path lengths
    const verticalDist1 = this.midY - this.parent.y;
    const horizontalDist = Math.abs(this.branchX - this.parent.x);
    const verticalDist2 = this.child.y - this.midY;
    const totalLength = verticalDist1 + horizontalDist + verticalDist2;

    // Calculate how much of each segment to draw
    const currentLength = totalLength * this.progress;

    p5.stroke(180, 190, 205);
    p5.strokeWeight(1.5);
    p5.noFill();

    // Always draw the first vertical segment from parent
    if (currentLength > 0) {
      const firstSegmentLength = Math.min(currentLength, verticalDist1);
      const currentMidY = p5.lerp(this.parent.y, this.midY, firstSegmentLength / verticalDist1);
      p5.line(this.parent.x, this.parent.y, this.parent.x, currentMidY);
    }

    if (currentLength > verticalDist1) {
      // Draw second segment (horizontal)
      const secondSegmentLength = Math.min(currentLength - verticalDist1, horizontalDist);
      const currentBranchX = p5.lerp(this.parent.x, this.branchX, secondSegmentLength / horizontalDist);
      p5.line(this.parent.x, this.midY, currentBranchX, this.midY);

      if (currentLength > verticalDist1 + horizontalDist) {
        // Draw third segment (vertical to child)
        const thirdSegmentLength = currentLength - verticalDist1 - horizontalDist;
        const currentChildY = p5.lerp(this.midY, this.child.y, thirdSegmentLength / verticalDist2);
        p5.line(this.branchX, this.midY, this.branchX, currentChildY);
      }
    }
  }
}

// Create a modified sketch for each stage
function createTreeSketch(stageId) {
  return function(p5) {
    let nodes = [];
    let edges = [];
    let treeData = stageData[stageId];

    p5.setup = function() {
      const canvas = p5.createCanvas(p5.windowWidth * 0.4, p5.windowHeight);
      canvas.parent('canvas-container');
      p5.smooth();
      p5.frameRate(60);

      if (treeData) {
        createTreeFromData(treeData);
      }
    };

    p5.windowResized = function() {
      p5.resizeCanvas(p5.windowWidth * 0.4, p5.windowHeight);
    };

    function createTreeFromData(data) {
      // Clear existing nodes and edges
      nodes = [];
      edges = [];

      // Add defensive checks to prevent errors
      if (!data || !data.layout || !Array.isArray(data.layout) || !data.edges || !Array.isArray(data.edges)) {
        console.error("Invalid tree data format:", data);
        return; // Exit if data structure is invalid
      }

      // Find all parent nodes in edges
      const parentNodes = new Set();
      for (const [parentId, childId] of data.edges) {
        parentNodes.add(parentId);
      }

      // Create nodes
      for (let i = 0; i < data.layout.length; i++) {
        const [nx, ny] = data.layout[i];
        // A node is a root if it's a parent and not a child in any edge
        const isRoot = parentNodes.has(i) && data.edges.every(edge => edge[1] !== i);

        const node = new Node(
          nx * p5.width * 0.8 + p5.width * 0.1,
          ny * p5.height * 0.8 + p5.height * 0.1,
          i,
          isRoot
        );
        nodes.push(node);
      }

      // If no root was found, make the first parent node visible
      if (!nodes.some(node => node.visible) && parentNodes.size > 0) {
        // Get the first parent node
        const firstParentId = [...parentNodes][0];
        if (nodes[firstParentId]) {
          nodes[firstParentId].visible = true;
        }
      }

      // Create edges
      for (const [parentId, childId] of data.edges) {
        const parent = nodes[parentId];
        const child = nodes[childId];
        if (parent && child) { // Verify both nodes exist
          const isLeft = child.x < parent.x;
          const isRight = child.x > parent.x;
          edges.push(new Edge(parent, child, isLeft, isRight));
        }
      }

      // Select the first node by default
      if (nodes.length > 0) {
        nodes[0].selected = true;
        updateNodeInfo(0);
      }
    }

    p5.draw = function() {
      // Use the global background color if available, otherwise use the default bgCol
      const currentBgColor = window.bgColCurrent || bgCol;
      p5.background(currentBgColor);

      // Update and render edges
      for (const edge of edges) {
        edge.update();
        edge.render(p5);
      }

      // Update and render nodes
      for (const node of nodes) {
        node.update();
        node.render(p5);
      }

      // Handle mouse hover
      p5.cursor(p5.ARROW);
      for (const node of nodes) {
        if (node.isMouseOver(p5)) {
          p5.cursor(p5.HAND);
        }
      }
    };

    p5.mousePressed = function() {
      // Check if any node was clicked
      for (let i = 0; i < nodes.length; i++) {
        if (nodes[i].visible && nodes[i].isMouseOver(p5)) {
          // Deselect all nodes
          nodes.forEach(n => n.selected = false);
          // Select the clicked node
          nodes[i].selected = true;
          // Update the right panel with node info
          updateNodeInfo(i);
          break;
        }
      }
    };

    function updateNodeInfo(nodeIndex) {
      if (treeData) {
        setNodeInfo(
          treeData.code[nodeIndex],
          treeData.plan[nodeIndex],
          treeData.plot_code?.[nodeIndex],
          treeData.plot_plan?.[nodeIndex],
          treeData.metrics?.[nodeIndex],
          treeData.exc_type?.[nodeIndex] || '',
          treeData.exc_info?.[nodeIndex]?.args?.[0] || '',
          treeData.exc_stack?.[nodeIndex] || [],
          treeData.plots?.[nodeIndex] || [],
          treeData.plot_analyses?.[nodeIndex] || [],
          treeData.vlm_feedback_summary?.[nodeIndex] || '',
          treeData.datasets_successfully_tested?.[nodeIndex] || [],
          treeData.exec_time_feedback?.[nodeIndex] || '',
          treeData.exec_time?.[nodeIndex] || ''
        );
      }
    }
  };
}

// Start a new p5 sketch for the given stage
function startSketch(stageId) {
  if (currentSketch) {
    currentSketch.remove();
  }

  if (stageData[stageId]) {
    currentSketch = new p5(createTreeSketch(stageId));

    // Update stage info
    const stageNumber = stageId.split('_')[1];
    let stageDesc = '';
    switch(stageId) {
      case 'Stage_1': stageDesc = 'Preliminary Investigation'; break;
      case 'Stage_2': stageDesc = 'Baseline Tuning'; break;
      case 'Stage_3': stageDesc = 'Research Agenda Execution'; break;
      case 'Stage_4': stageDesc = 'Ablation Studies'; break;
    }

    document.getElementById('stage-info').innerHTML =
      `<strong>Current Stage: ${stageNumber} - ${stageDesc}</strong>`;
  }
}

// Handle tab selection
function selectStage(stageId) {
  if (!stageData[stageId] || !availableStages.includes(stageId)) {
    return; // Don't allow selection of unavailable stages
  }

  // Update active tab styles
  document.querySelectorAll('.tab').forEach(tab => {
    tab.classList.remove('active');
  });
  document.querySelector(`.tab[data-stage="${stageId}"]`).classList.add('active');

  // Start the new sketch
  currentStage = stageId;
  startSketch(stageId);
}

// Function to load the tree data for all stages
async function loadAllStageData(baseTreeData) {
  console.log("Loading stage data with base data:", baseTreeData);

  // The base tree data is for the current stage
  const currentStageId = baseTreeData.current_stage || 'Stage_1';

  // Ensure base tree data is valid and has required properties
  if (baseTreeData && baseTreeData.layout && baseTreeData.edges) {
    stageData[currentStageId] = baseTreeData;
    availableStages.push(currentStageId);
    console.log(`Added current stage ${currentStageId} to available stages`);
  } else {
    console.warn(`Current stage ${currentStageId} data is invalid:`, baseTreeData);
  }

  // Use relative path to load other stage trees
  const logDirPath = baseTreeData.log_dir_path || '.';
  console.log("Log directory path:", logDirPath);

  // Load data for each stage if available
  const stageNames = ['Stage_1', 'Stage_2', 'Stage_3', 'Stage_4'];
  const stageNames2actualNames = {
    'Stage_1': 'stage_1_initial_implementation_1_preliminary',
    'Stage_2': 'stage_2_baseline_tuning_1_first_attempt',
    'Stage_3': 'stage_3_creative_research_1_first_attempt',
    'Stage_4': 'stage_4_ablation_studies_1_first_attempt'
    }

  for (const stage of stageNames) {

    if (baseTreeData.completed_stages && baseTreeData.completed_stages.includes(stage)) {
      try {
        console.log(`Attempting to load data for ${stage} from ${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);
        const response = await fetch(`${logDirPath}/${stageNames2actualNames[stage]}/tree_data.json`);

        if (response.ok) {
          const data = await response.json();

          // Validate the loaded data
          if (data && data.layout && data.edges) {
            stageData[stage] = data;
            availableStages.push(stage);
            console.log(`Successfully loaded and validated data for ${stage}`);
          } else {
            console.warn(`Loaded data for ${stage} is invalid:`, data);
          }
        } else {
          console.warn(`Failed to load data for ${stage} - HTTP status ${response.status}`);
        }
      } catch (error) {
        console.error(`Error loading data for ${stage}:`, error);
      }
    } else {
      console.log(`Skipping stage ${stage} - not in completed stages list:`, baseTreeData.completed_stages);
    }
  }

  // Update tab visibility based on available stages
  updateTabVisibility();

  // Start with the first available stage
  if (availableStages.length > 0) {
    selectStage(availableStages[0]);
  } else {
    console.warn("No stages available to display");
    // Display a message in the canvas area
    document.getElementById('canvas-container').innerHTML =
      '<div style="padding: 20px; color: #333; text-align: center;"><h3>No valid tree data available to display</h3></div>';
  }
}

// Update tab visibility based on available stages
function updateTabVisibility() {
  const tabs = document.querySelectorAll('.tab');
  tabs.forEach(tab => {
    const stageId = tab.getAttribute('data-stage');
    if (availableStages.includes(stageId)) {
      tab.classList.remove('disabled');
    } else {
      tab.classList.add('disabled');
    }
  });
}

// Utility function to set the node info in the right panel
const setNodeInfo = (code, plan, plot_code, plot_plan, metrics = null, exc_type = '', exc_info = '',
    exc_stack = [], plots = [], plot_analyses = [], vlm_feedback_summary = '',
    datasets_successfully_tested = [], exec_time_feedback = '', exec_time = '') => {
  const codeElm = document.getElementById("code");
  if (codeElm) {
    if (code) {
      codeElm.innerHTML = hljs.highlight(code, { language: "python" }).value;
    } else {
      codeElm.innerHTML = '<p>No code available</p>';
    }
  }

  const planElm = document.getElementById("plan");
  if (planElm) {
    if (plan) {
      planElm.innerHTML = hljs.highlight(plan, { language: "plaintext" }).value;
    } else {
      planElm.innerHTML = '<p>No plan available</p>';
    }
  }

  const plot_codeElm = document.getElementById("plot_code");
  if (plot_codeElm) {
    if (plot_code) {
      plot_codeElm.innerHTML = hljs.highlight(plot_code, { language: "python" }).value;
    } else {
      plot_codeElm.innerHTML = '<p>No plot code available</p>';
    }
  }

  const plot_planElm = document.getElementById("plot_plan");
  if (plot_planElm) {
    if (plot_plan) {
      plot_planElm.innerHTML = hljs.highlight(plot_plan, { language: "plaintext" }).value;
    } else {
      plot_planElm.innerHTML = '<p>No plot plan available</p>';
    }
  }

  const metricsElm = document.getElementById("metrics");
  if (metricsElm) {
      let metricsContent = `<h3>Metrics:</h3>`;
      if (metrics && metrics.metric_names) {
          for (const metric of metrics.metric_names) {
              metricsContent += `<div class="metric-group">`;
              metricsContent += `<h4>${metric.metric_name}</h4>`;
              metricsContent += `<p><strong>Description:</strong> ${metric.description || 'N/A'}</p>`;
              metricsContent += `<p><strong>Optimization:</strong> ${metric.lower_is_better ? 'Minimize' : 'Maximize'}</p>`;

              // Create table for dataset values
              metricsContent += `<table class="metric-table">
                  <tr>
                      <th>Dataset</th>
                      <th>Final Value</th>
                      <th>Best Value</th>
                  </tr>`;

              for (const dataPoint of metric.data) {
                  metricsContent += `<tr>
                      <td>${dataPoint.dataset_name}</td>
                      <td>${dataPoint.final_value?.toFixed(4) || 'N/A'}</td>
                      <td>${dataPoint.best_value?.toFixed(4) || 'N/A'}</td>
                  </tr>`;
              }

              metricsContent += `</table></div>`;
          }
      } else if (metrics === null) {
          metricsContent += `<p>No metrics available</p>`;
      }
      metricsElm.innerHTML = metricsContent;
  }

  // Add plots display
  const plotsElm = document.getElementById("plots");
  if (plotsElm) {
      if (plots && plots.length > 0) {
          let plotsContent = '';
          plots.forEach(plotPath => {
              plotsContent += `
                  <div class="plot-item">
                      <img src="${plotPath}" alt="Experiment Plot" onerror="console.error('Failed to load plot:', this.src)"/>
                  </div>`;
          });
          plotsElm.innerHTML = plotsContent;
      } else {
          plotsElm.innerHTML = '';
      }
  }

  // Add error info display
  const errorElm = document.getElementById("exc_info");
  if (errorElm) {
    if (exc_type) {
      let errorContent = `<h3 style="color: #ff5555">Exception Information:</h3>
                          <p><strong>Type:</strong> ${exc_type}</p>`;

      if (exc_info) {
        errorContent += `<p><strong>Details:</strong> <pre>${JSON.stringify(exc_info, null, 2)}</pre></p>`;
      }

      if (exc_stack) {
        errorContent += `<p><strong>Stack Trace:</strong> <pre>${exc_stack.join('\n')}</pre></p>`;
      }

      errorElm.innerHTML = errorContent;
    } else {
      errorElm.innerHTML = "No exception info available";
    }
  }

  const exec_timeElm = document.getElementById("exec_time");
  if (exec_timeElm) {
    let exec_timeContent = '<div id="exec_time"><h3>Execution Time (in seconds):</h3><p>' + exec_time + '</p></div>';
    exec_timeElm.innerHTML = exec_timeContent;
  }

  const exec_time_feedbackElm = document.getElementById("exec_time_feedback");
  if (exec_time_feedbackElm) {
    let exec_time_feedbackContent = '<div id="exec_time_feedback_content">'
    exec_time_feedbackContent += '<h3>Execution Time Feedback:</h3>'
    exec_time_feedbackContent += '<p>' + exec_time_feedback + '</p>'
    exec_time_feedbackContent += '</div>';
    exec_time_feedbackElm.innerHTML = exec_time_feedbackContent;
  }

  const vlm_feedbackElm = document.getElementById("vlm_feedback");
  if (vlm_feedbackElm) {
      let vlm_feedbackContent = '';

      if (plot_analyses && plot_analyses.length > 0) {
          vlm_feedbackContent += `<h3>Plot Analysis:</h3>`;
          plot_analyses.forEach(analysis => {
              if (analysis && analysis.plot_path) {  // Add null check
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <h4>Analysis for ${analysis.plot_path.split('/').pop()}</h4>
                          <p>${analysis.analysis || 'No analysis available'}</p>
                          <ul class="key-findings">
                              ${(analysis.key_findings || []).map(finding => `<li>${finding}</li>`).join('')}
                          </ul>
                      </div>`;
              } else {
                  console.warn('Received invalid plot analysis:', analysis);
                  vlm_feedbackContent += `
                      <div class="plot-analysis">
                          <p>Invalid plot analysis data received</p>
                      </div>`;
              }
          });
      }

      // Add actionable insights if available
      if (vlm_feedback_summary && typeof vlm_feedback_summary === 'string') {
          vlm_feedbackContent += `
              <div class="vlm_feedback">
                  <h3>VLM Feedback Summary:</h3>
                  <p>${vlm_feedback_summary}</p>
              </div>`;
      }

      console.log("Datasets successfully tested:", datasets_successfully_tested);
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          vlm_feedbackContent += `
              <div id="datasets_successfully_tested">
                  <h3>Datasets Successfully Tested:</h3>
                  <p>${datasets_successfully_tested.join(', ')}</p>
              </div>`;
      }

      if (!vlm_feedbackContent) {
          vlm_feedbackContent = '<p>No insights available for this experiment.</p>';
      }

      vlm_feedbackElm.innerHTML = vlm_feedbackContent;
  }

  const datasets_successfully_testedElm = document.getElementById("datasets_successfully_tested");
  if (datasets_successfully_testedElm) {
      let datasets_successfully_testedContent = '';
      if (datasets_successfully_tested && datasets_successfully_tested.length > 0) {
          datasets_successfully_testedContent = `<h3>Datasets Successfully Tested:</h3><ul>`;
          datasets_successfully_tested.forEach(dataset => {
              datasets_successfully_testedContent += `<li>${dataset}</li>`;
          });
          datasets_successfully_testedContent += `</ul>`;
      } else {
          datasets_successfully_testedContent = '<p>No datasets tested yet</p>';
      }
      datasets_successfully_testedElm.innerHTML = datasets_successfully_testedContent;
  }
};

// Initialize with the provided tree data
const treeStructData = {"edges": [[0, 16], [0, 2], [0, 10], [0, 11], [0, 8], [0, 7], [0, 13], [0, 14], [0, 3], [0, 15], [0, 6], [0, 5], [0, 1], [1, 12], [2, 9], [3, 4]], "layout": [[0.5, 0.0], [0.0, 0.5], [0.08333333333333333, 0.5], [0.16666666666666666, 0.5], [0.16666666666666666, 1.0], [0.25, 0.5], [0.3333333333333333, 0.5], [0.4166666666666667, 0.5], [0.5, 0.5], [0.08333333333333333, 1.0], [0.5833333333333334, 0.5], [0.6666666666666666, 0.5], [0.0, 1.0], [0.75, 0.5], [0.8333333333333334, 0.5], [0.9166666666666666, 0.5], [1.0, 0.5]], "plan": ["Hyperparam tuning name: learning_rate. I\u2019ll sweep the Adam initial learning rate\nover a log\u2010uniform grid [1e-4, 5e-4, 1e-3, 5e-3, 1e-2], re\u2010initializing models\nat each setting for a fair comparison. For each learning rate I train both AI\nand user MLPs jointly over a fixed number of epochs, recording\ntraining/validation losses and alignments per epoch, and finally collecting\nvalidation predictions and ground truth. All plottable data (metrics, losses,\npredictions, ground truth) are organized under\n`experiment_data['learning_rate']['synthetic']` and saved via `np.save(...,\n'experiment_data.npy')`.", "We extend our co\u2010adaptive alignment baseline to three HuggingFace text\nclassification tasks (AG News, IMDb, Yelp Polarity) to probe generalization. For\neach dataset we sample 1,000 training and 200 validation texts, vectorize with\nTF\u2010IDF (max_features=2000) then standardize. We co\u2010train lightweight AI and user\nMLPs on each split and compute two alignment sub\u2010scores: AI\u2013user model alignment\nand AI\u2019s model\u2010of\u2010user vs. actual behavior using 1\u2013Jensen\u2013Shannon divergence. We\nthen combine these into a Mutual Alignment Index (MAI) via harmonic mean and\ntrack it alongside loss at each epoch. We print the validation loss and MAI per\nepoch for monitoring and store all losses, individual alignments and MAI in a\nstructured dictionary. Finally, we save the experiment_data as a NumPy file in\nworking_dir for easy downstream analysis. This experiment gives our first\ninsights into bidirectional alignment behavior across diverse real\u2010world\ndatasets.", "We propose to validate our co\u2010adaptive alignment framework on three real\u2010world\ntext classification datasets from Hugging Face: AG News, IMDb, and Yelp Reviews.\nFor each dataset, we subsample a manageable number of examples, vectorize text\nvia TF\u2010IDF (max_features=2000), and normalize features. We define two simple\ntwo\u2010layer MLPs to represent the AI's decision function and the user's mental\nmodel. We train both models jointly with Adam, computing cross\u2010entropy loss for\neach and updating them per batch. During both training and validation, we\ncompute the alignment score (1 minus Jensen\u2010Shannon divergence between their\noutput distributions) and the Mutual Alignment Index (harmonic mean of the\nAI\u2013user alignment and the user\u2013behavior alignment). We report validation loss\nand MAI at each epoch and save all per\u2010epoch metrics, predictions, and ground\ntruths into a structured numpy file. We seed all randomness for reproducibility\nand leverage GPU acceleration when available. This setup will reveal how well\nbidirectional adaptation generalizes across diverse NLP tasks.", "We will validate CAMMA on three diverse text\u2010classification benchmarks from\nHuggingFace\u2014AG News, Yelp Polarity, and IMDb\u2014by sampling each dataset down to 2k\ntraining and 500 validation texts for efficiency.  Texts are featurized via a\nCountVectorizer (max 2k tokens) and L2\u2010normalized before feeding into two\nco\u2010trained MLPs (AI and user models) with a shared architecture per dataset.\nDuring each of five epochs, we minimize cross\u2010entropy for both models separately\nand compute at each step the 1\u2013Jensen\u2013Shannon divergences between AI vs. user\noutputs and between user outputs vs. the true one\u2010hot labels.  We define the\nMutual Alignment Index (MAI) as the harmonic mean of the two 1\u2013JSD sub\u2010scores,\ntracking it alongside losses and alignment for both training and validation.\nValidation losses are printed every epoch, and we collect predictions for later\nuser\u2010behavior comparison.  All per\u2010epoch metrics (loss, alignment, MAI),\npredictions, and ground truths are saved in `experiment_data.npy` under the\nworking directory.  This protocol will reveal how bidirectional model alignment\nbehaves across different real-world NLP tasks.", "I replaced the sklearn vectorizer with a manual vocabulary built via Python\u2019s\nCounter over whitespace\u2010tokenized words, limiting to the top MAX_FEATS tokens\nand converting texts to count vectors. A custom Dataset returns dicts so each\nDataLoader batch can be moved to the correct device in one go, satisfying the\nGPU handling guidelines. This removes the sklearn dependency and ensures inputs,\nmodels, and metrics are all properly computed on the selected device.", "To evaluate co\u2010adaptive mental model alignment across diverse text\nclassification tasks, we derive fixed DistilBERT sentence embeddings and jointly\ntrain an AI model and a user mental model (each a 2\u2010layer MLP) on three\nHuggingFace datasets: AG News, DBpedia-14, and Yelp Polarity. We extract 768-dim\nfeatures by averaging the last hidden states of DistilBERT, standardize them per\ndataset, and feed 500 training and 100 validation samples into PyTorch\nDataLoaders. During each of 5 epochs, we compute cross\u2010entropy losses for both\nmodels and two Jensen\u2013Shannon divergences per batch: (1) between AI and user\nmodel distributions, and (2) between the user model and the true one\u2010hot labels.\nWe define the Mutual Alignment Index (MAI) as the harmonic mean of these 1\u2013JSD\nsub\u2010scores, track MAI and validation loss at each epoch (printing them), and\naccumulate all losses, sub\u2010scores, MAI, predictions, and ground truths in a\nnested experiment_data dict. All models and tensors are moved to GPU if\navailable, optimizers are set up post\u2010.to(device), and we save the complete\nexperiment_data to `working/experiment_data.npy` for later analysis.", "We propose to validate CAMMA across three diverse text\u2010classification datasets\n(AG News, Yelp Polarity, and DBpedia) by co\u2010training two distinct models per\ndataset: a fine\u2010tuned DistilBERT \u201cAI model\u201d and a randomly\u2010initialized\nDistilBERT \u201cuser model\u201d. Each model is trained on small subsets (800 train, 200\nvalidation) for two epochs, with synchronous updates to both. At validation time\nwe compute (1) the alignment between AI and user predictive distributions, and\n(2) the alignment between user predictions and true labels, both via\n1\u2013Jensen\u2013Shannon divergence. We then compute a Mutual Alignment Index (MAI) as\nthe harmonic mean of these two sub\u2010scores. Per\u2010epoch validation loss and MAI are\nprinted, and all metrics are stored in a structured dict and saved to\nworking/experiment_data.npy. This setup tests bidirectional alignment in a\ncontrolled, reproducible manner across three Hugging Face datasets.", "In our improved CAMMA prototype, we instantiate two parallel DistilBERT\u2010based\nclassifiers\u2014one emulating the AI and one serving as the user model\u2014freezing\ntheir encoders and training only the classification heads on three HuggingFace\ntext\u2010classification benchmarks (AG News, IMDB, SST2) subsampled to 1\u2009K train /\n200 validation. At each epoch we compute bidirectional alignment via two\nJensen\u2013Shannon\u2013based sub\u2010scores: alignment between AI and user model outputs,\nand alignment between the user model and user observed behavior (simulated as\nthe ground truth distribution), combining them as a Mutual Alignment Index\n(MAI). Training loops on GPU update both classifiers in tandem per batch, with\nper\u2010epoch logging of validation loss and MAI. We record train/val losses and MAI\ntrajectories, and capture final AI predictions versus ground truth. All\nplottable data are saved as numpy arrays in \u201cworking/experiment_data.npy\u201d for\ndownstream analysis. This setup validates the CAMMA loop across diverse data,\nshowcasing dynamic co\u2010adaptation gains. Now we implement this end\u2010to\u2010end\nprototype.", "We propose to evaluate CAMMA\u2019s bidirectional alignment on three Hugging Face\ntext\u2010classification benchmarks (AG News, Yelp Review Full, and DBpedia14) by\njointly fine\u2010tuning paired DistilBERT classifiers as the \u201cAI\u201d and \u201cuser\u201d models\non small subsets (1k train/200 eval) for rapid iteration.  For each batch, we\nalternate updates on both models via cross\u2010entropy loss and compute two\nJensen\u2013Shannon divergences: one between the AI and user model output\ndistributions, and another between the user model and the one\u2010hot ground\u2010truth\ndistribution.  We convert each divergence into an alignment sub\u2010score (1\u2212JSD)\nand combine them via the harmonic mean to yield the Mutual Alignment Index\n(MAI).  We train both models for two epochs per dataset, printing validation\nloss and MAI each epoch, and accumulating per\u2010epoch metrics and losses in\n`experiment_data`.  Finally, we save all collected metrics and losses as a NumPy\n`.npy` file in the working directory.  This setup will expose how dynamic,\nco\u2010adaptive alignment scales across tasks of varying class cardinality.", "We can avoid the missing sklearn dependency entirely by implementing TF\u2013IDF in\npure Python. We tokenize each text with regex, count term and document\nfrequencies with collections.Counter, select the top max_features tokens for our\nvocabulary, compute idf, then build and normalize train/val TF\u2013IDF matrices\nmanually. This ensures the script runs without external vectorizer libraries and\npreserves the rest of the training and MAI computation unchanged.", "We extend CAMMA to three diverse HuggingFace text\u2010classification datasets\n(SST\u20102, AG News, DBpedia), using DistilBERT\u2010based AI and user models that\nco\u2010adapt in lockstep.  At each batch both models are fine\u2010tuned on ground truth,\nand we compute two alignment scores via Jensen\u2013Shannon divergences\u2014between AI\nand user model distributions and between user model distributions and true\none\u2010hot labels.  Their harmonic mean defines the Mutual Alignment Index (MAI),\nwhich we track alongside train/validation losses each epoch.  We store per\u2010epoch\nmetrics, predictions, and ground truths in an `experiment_data` dict for each\ndataset, printing validation loss and MAI.  Finally, we save all data as a NumPy\nfile in the working directory for downstream analysis.", "We propose to evaluate our bidirectional mental\u2010model alignment on three diverse\nHF text\u2010classification datasets (AG News, Yelp Polarity, DBpedia14) by\nextracting DistilBERT CLS embeddings and training paired MLPs for the AI\ndecision model and the user belief model. We freeze the transformer encoder and\nonly train the two MLPs with cross\u2010entropy, computing at each epoch both the\nalignment score (1\u2013Jensen\u2013Shannon divergence of their softmax outputs) and a\nbehavior alignment via the user\u2010model\u2019s accuracy. We then combine these into a\nMutual Alignment Index (MAI) via the harmonic mean. GPU acceleration is employed\nfor embedding and training, and we track train/val losses, alignments, and MAI\nper epoch, printing validation loss and MAI. After training, we collect final\npredictions and ground truth, storing all metrics and arrays in an\nexperiment_data dict and saving to disk with np.save. This multi\u2010dataset setup\nreveals cross\u2010domain generalization of CAMMA\u2019s bidirectional alignment.", "We can eliminate the sklearn dependency by writing a small TF-IDF and\nstandard\u2010scaler implementation in NumPy. First, build a vocabulary of the top\nmax_features by document frequency from the train texts, compute IDF weights,\nand vectorize both train and val splits into TF-IDF matrices. Then compute\nper\u2010feature means and stds to normalize the data. The rest of the training\nloop\u2014including MAI computation, metric tracking, and GPU data transfers\u2014remains\nunchanged. Finally, we save all losses, MAI metrics, and final\npredictions/ground truth arrays into a single experiment_data dictionary.", "Seed node", "Seed node", "Seed node", "Aggregate results from multiple seeds"], "code": ["import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Synthetic data generation\nN_train, N_val, D, C = 1000, 200, 10, 3\nW_true = np.random.randn(D, C)\nx_train = np.random.randn(N_train, D)\nx_val = np.random.randn(N_val, D)\ny_train = np.argmax(x_train @ W_true + 0.1 * np.random.randn(N_train, C), axis=1)\ny_val = np.argmax(x_val @ W_true + 0.1 * np.random.randn(N_val, C), axis=1)\nmean = x_train.mean(axis=0)\nstd = x_train.std(axis=0) + 1e-8\nx_train = (x_train - mean) / std\nx_val = (x_val - mean) / std\n\n# DataLoaders\ntrain_dataset = TensorDataset(\n    torch.tensor(x_train, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.long),\n)\nval_dataset = TensorDataset(\n    torch.tensor(x_val, dtype=torch.float32),\n    torch.tensor(y_val, dtype=torch.long),\n)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64)\n\n\n# Simple MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Hyperparameter sweep over learning rates\nlearning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\nnum_epochs = 10\n\n# Initialize experiment_data dict\nexperiment_data = {\n    \"learning_rate\": {\n        \"synthetic\": {\n            \"lrs\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nloss_fn = nn.CrossEntropyLoss()\n\nfor lr in learning_rates:\n    # Reset model weights for fair comparison\n    torch.manual_seed(0)\n    ai_model = MLP(D, 32, C).to(device)\n    user_model = MLP(D, 32, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # Containers for this learning rate\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss, total_align, n_samples = 0.0, 0.0, 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            # Forward passes\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # Cross-entropy losses\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            # Backprop AI\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            # Backprop user\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # Accumulate loss\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            # Alignment (1 - JSD)\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            total_align += torch.sum(1 - jsd).item()\n            n_samples += bs\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_align, v_samples = 0.0, 0.0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                # loss\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                # alignment\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                v_align += torch.sum(1 - jsd).item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        print(\n            f\"LR {lr:.1e} Epoch {epoch}: val_loss = {val_losses[-1]:.4f}, val_align = {val_aligns[-1]:.4f}\"\n        )\n\n    # Store per\u2010epoch metrics\n    sd = experiment_data[\"learning_rate\"][\"synthetic\"]\n    sd[\"metrics\"][\"train\"].append(train_aligns)\n    sd[\"metrics\"][\"val\"].append(val_aligns)\n    sd[\"losses\"][\"train\"].append(train_losses)\n    sd[\"losses\"][\"val\"].append(val_losses)\n\n    # Final validation predictions & ground truth\n    all_preds, all_gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(yb.numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n    sd[\"predictions\"].append(preds_arr)\n    sd[\"ground_truth\"].append(gts_arr)\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Hyperparameters\nN_train, N_val = 1000, 200\nmax_features = 2000\nbatch_size = 32\nnum_epochs = 5\nlr = 1e-3\ndataset_names = [\"ag_news\", \"imdb\", \"yelp_polarity\"]\n\n\n# MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\nloss_fn = nn.CrossEntropyLoss()\nexperiment_data = {}\n\nfor ds_name in dataset_names:\n    # Load and split\n    raw = (\n        load_dataset(ds_name, split=\"train\")\n        .shuffle(seed=42)\n        .select(range(N_train + N_val))\n    )\n    texts = [x[\"text\"] for x in raw]\n    labels = np.array(raw[\"label\"])\n    train_texts, val_texts = texts[:N_train], texts[N_train:]\n    y_train, y_val = labels[:N_train], labels[N_train:]\n    C = int(labels.max()) + 1\n\n    # TF-IDF + StandardScaler\n    tfidf = TfidfVectorizer(max_features=max_features)\n    X_train = tfidf.fit_transform(train_texts).toarray()\n    X_val = tfidf.transform(val_texts).toarray()\n    scaler = StandardScaler(with_mean=True, with_std=True)\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n\n    # DataLoaders\n    train_ds = TensorDataset(\n        torch.tensor(X_train, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long),\n    )\n    val_ds = TensorDataset(\n        torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n    )\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size)\n\n    # Models and optimizers\n    ai_model = MLP(max_features, 128, C).to(device)\n    user_model = MLP(max_features, 128, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # Metrics containers\n    data = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_align1\": [],\n        \"train_align2\": [],\n        \"train_mai\": [],\n        \"val_align1\": [],\n        \"val_align2\": [],\n        \"val_mai\": [],\n    }\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss = total_a1 = total_a2 = n_samples = 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # Losses & updates\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # Alignment1: AI vs user\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            a1 = torch.mean(1 - 0.5 * (kl1 + kl2)).item()\n            # Alignment2: user model vs ground truth\n            P_gt = torch.zeros_like(Q).scatter_(1, yb.unsqueeze(1), 1.0)\n            M2 = 0.5 * (Q + P_gt)\n            k1 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1)\n            k2 = torch.sum(\n                P_gt * (torch.log(P_gt + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n            )\n            a2 = torch.mean(1 - 0.5 * (k1 + k2)).item()\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            total_a1 += a1 * bs\n            total_a2 += a2 * bs\n            n_samples += bs\n\n        train_loss = total_loss / len(train_ds)\n        ta1 = total_a1 / n_samples\n        ta2 = total_a2 / n_samples\n        t_mai = 2 * (ta1 * ta2) / (ta1 + ta2 + 1e-8)\n        data[\"train_loss\"].append(train_loss)\n        data[\"train_align1\"].append(ta1)\n        data[\"train_align2\"].append(ta2)\n        data[\"train_mai\"].append(t_mai)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_a1 = v_a2 = v_samples = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), 1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), 1)\n                v_a1 += torch.sum(1 - 0.5 * (kl1 + kl2)).item()\n                P_gt = torch.zeros_like(Q).scatter_(1, yb.unsqueeze(1), 1.0)\n                M2 = 0.5 * (Q + P_gt)\n                k1 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                k2 = torch.sum(\n                    P_gt * (torch.log(P_gt + 1e-8) - torch.log(M2 + 1e-8)), 1\n                )\n                v_a2 += torch.sum(1 - 0.5 * (k1 + k2)).item()\n                v_samples += yb.size(0)\n\n        val_loss = v_loss / len(val_ds)\n        va1 = v_a1 / v_samples\n        va2 = v_a2 / v_samples\n        v_mai = 2 * (va1 * va2) / (va1 + va2 + 1e-8)\n        data[\"val_loss\"].append(val_loss)\n        data[\"val_align1\"].append(va1)\n        data[\"val_align2\"].append(va2)\n        data[\"val_mai\"].append(v_mai)\n\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n        print(f\"Dataset {ds_name} Epoch {epoch}: MAI = {v_mai:.4f}\")\n\n    experiment_data[ds_name] = data\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Experiment container\nexperiment_data = {}\ndatasets = [\"ag_news\", \"imdb\", \"yelp_review_full\"]\n\nfor dset in datasets:\n    raw = load_dataset(dset)\n    train_split, val_split = raw[\"train\"], raw[\"test\"]\n    texts_train = train_split[\"text\"][:2000]\n    labels_train = train_split[\"label\"][:2000]\n    texts_val = val_split[\"text\"][:500]\n    labels_val = val_split[\"label\"][:500]\n\n    # TF-IDF and normalization\n    vec = TfidfVectorizer(max_features=2000)\n    X_train = vec.fit_transform(texts_train).toarray()\n    X_val = vec.transform(texts_val).toarray()\n    mu, sigma = X_train.mean(0), X_train.std(0) + 1e-8\n    X_train = (X_train - mu) / sigma\n    X_val = (X_val - mu) / sigma\n    y_train = np.array(labels_train)\n    y_val = np.array(labels_val)\n\n    # DataLoaders\n    train_ds = TensorDataset(\n        torch.tensor(X_train, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long),\n    )\n    val_ds = TensorDataset(\n        torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n    )\n    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=64)\n\n    # Models & optimizers\n    in_dim = X_train.shape[1]\n    num_classes = len(set(y_train.tolist()))\n    ai_model = MLP(in_dim, 128, num_classes).to(device)\n    user_model = MLP(in_dim, 128, num_classes).to(device)\n    optim_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n    optim_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Metrics storage\n    train_losses, train_aligns, train_mais = [], [], []\n    val_losses, val_aligns, val_mais = [], [], []\n\n    for epoch in range(1, 6):\n        ai_model.train()\n        user_model.train()\n        t_loss = t_align = t_mai = t_samples = 0\n        for batch in train_loader:\n            batch = {\"xb\": batch[0], \"yb\": batch[1]}\n            batch = {k: v.to(device) for k, v in batch.items()}\n            xb, yb = batch[\"xb\"], batch[\"yb\"]\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optim_ai.zero_grad()\n            loss_ai.backward()\n            optim_ai.step()\n            optim_user.zero_grad()\n            loss_user.backward()\n            optim_user.step()\n            bs = yb.size(0)\n            t_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            sub1 = 1 - jsd\n            one_hot = F.one_hot(yb, num_classes).float()\n            M2 = 0.5 * (Q + one_hot)\n            kl1_2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1)\n            kl2_2 = torch.sum(\n                one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n            )\n            jsd2 = 0.5 * (kl1_2 + kl2_2)\n            sub2 = 1 - jsd2\n            mai = 2 * (sub1 * sub2) / (sub1 + sub2 + 1e-8)\n            t_align += sub1.sum().item()\n            t_mai += mai.sum().item()\n            t_samples += bs\n        train_losses.append(t_loss / len(train_ds))\n        train_aligns.append(t_align / t_samples)\n        train_mais.append(t_mai / t_samples)\n\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_align = v_mai = v_samples = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {\"xb\": batch[0], \"yb\": batch[1]}\n                batch = {k: v.to(device) for k, v in batch.items()}\n                xb, yb = batch[\"xb\"], batch[\"yb\"]\n                logits_ai = ai_model(xb)\n                logits_user = user_model(xb)\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                sub1 = 1 - jsd\n                one_hot = F.one_hot(yb, num_classes).float()\n                M2 = 0.5 * (Q + one_hot)\n                kl1_2 = torch.sum(\n                    Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                kl2_2 = torch.sum(\n                    one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                jsd2 = 0.5 * (kl1_2 + kl2_2)\n                sub2 = 1 - jsd2\n                mai = 2 * (sub1 * sub2) / (sub1 + sub2 + 1e-8)\n                v_align += sub1.sum().item()\n                v_mai += mai.sum().item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_ds))\n        val_aligns.append(v_align / v_samples)\n        val_mais.append(v_mai / v_samples)\n        print(\n            f\"Dataset {dset} Epoch {epoch}: val_loss = {val_losses[-1]:.4f}, val_MAI = {val_mais[-1]:.4f}\"\n        )\n\n    # Final predictions\n    preds, gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            xb = batch[0].to(device)\n            out = ai_model(xb)\n            preds.append(torch.argmax(out, 1).cpu().numpy())\n            gts.append(batch[1].numpy())\n    preds = np.concatenate(preds)\n    gts = np.concatenate(gts)\n\n    experiment_data[dset] = {\n        \"metrics\": {\n            \"train\": {\"loss\": train_losses, \"align\": train_aligns, \"MAI\": train_mais},\n            \"val\": {\"loss\": val_losses, \"align\": val_aligns, \"MAI\": val_mais},\n        },\n        \"predictions\": preds,\n        \"ground_truth\": gts,\n    }\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\ndef jensen_shannon_divergence(P, Q):\n    M = 0.5 * (P + Q)\n    kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    return 0.5 * (kl1 + kl2)\n\n\n# Hyperparameters\nBATCH_SIZE = 64\nEPOCHS = 5\nMAX_FEATS = 2000\nSUB_TRAIN = 2000\nSUB_VAL = 500\nHID_DIM = 128\nLR = 1e-3\n\nexperiment_data = {}\nfor ds_name in [\"ag_news\", \"yelp_polarity\", \"imdb\"]:\n    print(f\"--- Dataset: {ds_name} ---\")\n    ds = load_dataset(ds_name)\n    tr = ds[\"train\"].select(range(min(len(ds[\"train\"]), SUB_TRAIN)))\n    va = ds[\"test\"].select(range(min(len(ds[\"test\"]), SUB_VAL)))\n    texts_tr, y_tr = tr[\"text\"], tr[\"label\"]\n    texts_va, y_va = va[\"text\"], va[\"label\"]\n    vec = CountVectorizer(max_features=MAX_FEATS)\n    X_tr = vec.fit_transform(texts_tr).toarray()\n    X_va = vec.transform(texts_va).toarray()\n    train_dataset = TensorDataset(\n        torch.tensor(X_tr, dtype=torch.float32), torch.tensor(y_tr, dtype=torch.long)\n    )\n    val_dataset = TensorDataset(\n        torch.tensor(X_va, dtype=torch.float32), torch.tensor(y_va, dtype=torch.long)\n    )\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n    num_classes = int(max(y_tr)) + 1\n\n    ai_model = MLP(MAX_FEATS, HID_DIM, num_classes).to(device)\n    user_model = MLP(MAX_FEATS, HID_DIM, num_classes).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=LR)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=LR)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Metrics containers\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n    train_mais, val_mais = [], []\n\n    for epoch in range(1, EPOCHS + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss = total_align = total_mai = 0.0\n        n_samples = 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            xb = F.normalize(xb, p=2, dim=1)\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            GT = F.one_hot(yb, num_classes).float()\n            jsd1 = jensen_shannon_divergence(P, Q)\n            jsd2 = jensen_shannon_divergence(Q, GT)\n            sub1 = 1 - jsd1\n            sub2 = 1 - jsd2\n            mai = 2 * sub1 * sub2 / (sub1 + sub2 + 1e-8)\n            total_align += sub1.sum().item()\n            total_mai += mai.sum().item()\n            n_samples += bs\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n        train_mais.append(total_mai / n_samples)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_align = v_mai = 0.0\n        v_samples = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                xb = F.normalize(xb, p=2, dim=1)\n                logits_ai = ai_model(xb)\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                GT = F.one_hot(yb, num_classes).float()\n                jsd1 = jensen_shannon_divergence(P, Q)\n                jsd2 = jensen_shannon_divergence(Q, GT)\n                sub1 = 1 - jsd1\n                sub2 = 1 - jsd2\n                mai = 2 * sub1 * sub2 / (sub1 + sub2 + 1e-8)\n                v_align += sub1.sum().item()\n                v_mai += mai.sum().item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        val_mais.append(v_mai / v_samples)\n        print(f\"Epoch {epoch}: validation_loss = {val_losses[-1]:.4f}\")\n\n    # Collect predictions\n    all_preds, all_gts = [], []\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            xb = F.normalize(xb, p=2, dim=1)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(yb.numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n\n    experiment_data[ds_name] = {\n        \"losses\": {\"train\": train_losses, \"val\": val_losses},\n        \"aligns\": {\"train\": train_aligns, \"val\": val_aligns},\n        \"mai\": {\"train\": train_mais, \"val\": val_mais},\n        \"predictions\": preds_arr,\n        \"ground_truth\": gts_arr,\n    }\n\n# Save all results\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset\nfrom collections import Counter\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\ndef jensen_shannon_divergence(P, Q):\n    M = 0.5 * (P + Q)\n    kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    return 0.5 * (kl1 + kl2)\n\n\nclass DictTextDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return {\n            \"input\": torch.tensor(self.X[idx], dtype=torch.float32),\n            \"label\": torch.tensor(self.y[idx], dtype=torch.long),\n        }\n\n\n# Hyperparameters\nBATCH_SIZE = 64\nEPOCHS = 5\nMAX_FEATS = 2000\nSUB_TRAIN = 2000\nSUB_VAL = 500\nHID_DIM = 128\nLR = 1e-3\n\nexperiment_data = {}\nfor ds_name in [\"ag_news\", \"yelp_polarity\", \"imdb\"]:\n    print(f\"--- Dataset: {ds_name} ---\")\n    ds = load_dataset(ds_name)\n    tr = ds[\"train\"].select(range(min(len(ds[\"train\"]), SUB_TRAIN)))\n    va = ds[\"test\"].select(range(min(len(ds[\"test\"]), SUB_VAL)))\n    texts_tr, y_tr = tr[\"text\"], tr[\"label\"]\n    texts_va, y_va = va[\"text\"], va[\"label\"]\n\n    # Build manual vocabulary\n    counter = Counter()\n    for txt in texts_tr:\n        counter.update(txt.lower().split())\n    most_common = [tok for tok, _ in counter.most_common(MAX_FEATS)]\n    vocab = {tok: i for i, tok in enumerate(most_common)}\n\n    def vectorize(text):\n        vec = np.zeros(MAX_FEATS, dtype=np.float32)\n        for tok in text.lower().split():\n            idx = vocab.get(tok)\n            if idx is not None:\n                vec[idx] += 1.0\n        return vec\n\n    X_tr = np.stack([vectorize(t) for t in texts_tr])\n    X_va = np.stack([vectorize(t) for t in texts_va])\n\n    train_dataset = DictTextDataset(X_tr, y_tr)\n    val_dataset = DictTextDataset(X_va, y_va)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n    num_classes = int(max(y_tr)) + 1\n    ai_model = MLP(MAX_FEATS, HID_DIM, num_classes).to(device)\n    user_model = MLP(MAX_FEATS, HID_DIM, num_classes).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=LR)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=LR)\n    loss_fn = nn.CrossEntropyLoss()\n\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n    train_mais, val_mais = [], []\n\n    for epoch in range(1, EPOCHS + 1):\n        ai_model.train()\n        user_model.train()\n        total_loss = total_align = total_mai = 0.0\n        n_samples = 0\n        for batch in train_loader:\n            batch = {\n                k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n            }\n            xb = F.normalize(batch[\"input\"], p=2, dim=1)\n            yb = batch[\"label\"]\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            GT = F.one_hot(yb, num_classes).float()\n            jsd1 = jensen_shannon_divergence(P, Q)\n            jsd2 = jensen_shannon_divergence(Q, GT)\n            sub1 = 1 - jsd1\n            sub2 = 1 - jsd2\n            mai = 2 * sub1 * sub2 / (sub1 + sub2 + 1e-8)\n            total_align += sub1.sum().item()\n            total_mai += mai.sum().item()\n            n_samples += bs\n\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n        train_mais.append(total_mai / n_samples)\n\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_align = v_mai = 0.0\n        v_samples = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {\n                    k: v.to(device)\n                    for k, v in batch.items()\n                    if isinstance(v, torch.Tensor)\n                }\n                xb = F.normalize(batch[\"input\"], p=2, dim=1)\n                yb = batch[\"label\"]\n                logits_ai = ai_model(xb)\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                GT = F.one_hot(yb, num_classes).float()\n                jsd1 = jensen_shannon_divergence(P, Q)\n                jsd2 = jensen_shannon_divergence(Q, GT)\n                sub1 = 1 - jsd1\n                sub2 = 1 - jsd2\n                mai = 2 * sub1 * sub2 / (sub1 + sub2 + 1e-8)\n                v_align += sub1.sum().item()\n                v_mai += mai.sum().item()\n                v_samples += yb.size(0)\n\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        val_mais.append(v_mai / v_samples)\n        print(f\"Epoch {epoch}: validation_loss = {val_losses[-1]:.4f}\")\n\n    # Collect predictions\n    all_preds, all_gts = [], []\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {\n                k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)\n            }\n            xb = F.normalize(batch[\"input\"], p=2, dim=1)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(batch[\"label\"].cpu().numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n\n    experiment_data[ds_name] = {\n        \"losses\": {\"train\": train_losses, \"val\": val_losses},\n        \"aligns\": {\"train\": train_aligns, \"val\": val_aligns},\n        \"mai\": {\"train\": train_mais, \"val\": val_mais},\n        \"predictions\": preds_arr,\n        \"ground_truth\": gts_arr,\n    }\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Load tokenizer and encoder\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert.eval()\nfor p in bert.parameters():\n    p.requires_grad = False\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\ndataset_names = [\"ag_news\", \"dbpedia_14\", \"yelp_polarity\"]\nN_train, N_val = 500, 100\nexperiment_data = {}\n\nfor dataset_name in dataset_names:\n    ds = load_dataset(dataset_name)\n    ds_train = ds[\"train\"].select(range(N_train))\n    ds_val = ds[\"test\"].select(range(N_val))\n    # detect text column\n    text_col = [\n        c\n        for c, f in ds_train.features.items()\n        if getattr(f, \"dtype\", None) == \"string\" and c != \"label\"\n    ][0]\n    train_texts = ds_train[text_col]\n    train_labels = np.array(ds_train[\"label\"])\n    val_texts = ds_val[text_col]\n    val_labels = np.array(ds_val[\"label\"])\n\n    # embed extraction\n    def extract(texts):\n        embs = []\n        for i in range(0, len(texts), 32):\n            batch = texts[i : i + 32]\n            toks = tokenizer(\n                batch, padding=True, truncation=True, return_tensors=\"pt\"\n            ).to(device)\n            with torch.no_grad():\n                out = bert(**toks)\n                embs.append(out.last_hidden_state.mean(dim=1).cpu())\n        return torch.cat(embs, dim=0)\n\n    train_emb = extract(train_texts)\n    val_emb = extract(val_texts)\n    # normalize\n    mean = train_emb.mean(0, keepdim=True)\n    std = train_emb.std(0, keepdim=True) + 1e-8\n    train_emb = (train_emb - mean) / std\n    val_emb = (val_emb - mean) / std\n    # DataLoaders\n    train_ds = TensorDataset(train_emb, torch.tensor(train_labels, dtype=torch.long))\n    val_ds = TensorDataset(val_emb, torch.tensor(val_labels, dtype=torch.long))\n    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=64)\n    # models & optimizers\n    num_labels = ds_train.features[\"label\"].num_classes\n    ai_model = MLP(train_emb.size(1), 128, num_labels).to(device)\n    user_model = MLP(train_emb.size(1), 128, num_labels).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n    # metrics storage\n    train_losses, val_losses = [], []\n    train_s1, train_s2, train_mai = [], [], []\n    val_s1, val_s2, val_mai = [], [], []\n    # training loop\n    for epoch in range(1, 6):\n        ai_model.train()\n        user_model.train()\n        tot_loss = tot1 = tot2 = cnt = 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            bs = yb.size(0)\n            tot_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, 1)\n            Q = F.softmax(logits_user, 1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), 1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), 1)\n            s1 = (1 - 0.5 * (kl1 + kl2)).sum().item()\n            tot1 += s1\n            Y = F.one_hot(yb, num_classes=num_labels).float()\n            M2 = 0.5 * (Q + Y)\n            klq = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n            kly = torch.sum(Y * (torch.log(Y + 1e-8) - torch.log(M2 + 1e-8)), 1)\n            s2 = (1 - 0.5 * (klq + kly)).sum().item()\n            tot2 += s2\n            cnt += bs\n        t_loss = tot_loss / len(train_ds)\n        s1_avg = tot1 / cnt\n        s2_avg = tot2 / cnt\n        mai_t = 2 * s1_avg * s2_avg / (s1_avg + s2_avg + 1e-8)\n        train_losses.append(t_loss)\n        train_s1.append(s1_avg)\n        train_s2.append(s2_avg)\n        train_mai.append(mai_t)\n        # validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v1 = v2 = vc = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                la = ai_model(xb)\n                lu = user_model(xb)\n                v_loss += loss_fn(la, yb).item() * yb.size(0)\n                P = F.softmax(la, 1)\n                Q = F.softmax(lu, 1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), 1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), 1)\n                v1 += (1 - 0.5 * (kl1 + kl2)).sum().item()\n                Y = F.one_hot(yb, num_classes=num_labels).float()\n                M2 = 0.5 * (Q + Y)\n                klq = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                kly = torch.sum(Y * (torch.log(Y + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                v2 += (1 - 0.5 * (klq + kly)).sum().item()\n                vc += yb.size(0)\n        v_loss_avg = v_loss / len(val_ds)\n        v1_avg = v1 / vc\n        v2_avg = v2 / vc\n        mai_v = 2 * v1_avg * v2_avg / (v1_avg + v2_avg + 1e-8)\n        val_losses.append(v_loss_avg)\n        val_s1.append(v1_avg)\n        val_s2.append(v2_avg)\n        val_mai.append(mai_v)\n        print(\n            f\"Dataset {dataset_name} Epoch {epoch}: validation_loss = {v_loss_avg:.4f}, MAI = {mai_v:.4f}\"\n        )\n    # record predictions\n    preds, gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds.append(torch.argmax(ai_model(xb), 1).cpu().numpy())\n            gts.append(yb.numpy())\n    experiment_data[dataset_name] = {\n        \"metrics\": {\"train\": train_mai, \"val\": val_mai},\n        \"losses\": {\"train\": train_losses, \"val\": val_losses},\n        \"sub_scores\": {\n            \"train1\": train_s1,\n            \"train2\": train_s2,\n            \"val1\": val_s1,\n            \"val2\": val_s2,\n        },\n        \"predictions\": np.concatenate(preds, 0),\n        \"ground_truth\": np.concatenate(gts, 0),\n    }\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    AdamW,\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\ndef js_divergence(P, Q):\n    M = 0.5 * (P + Q)\n    kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n    return 0.5 * (kl1 + kl2)\n\n\ndef harmonic_mean(a, b):\n    return 2 * a * b / (a + b + 1e-8)\n\n\nexperiment_data = {}\ndatasets_list = [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]\ntrain_size, val_size, num_epochs, batch_size = 800, 200, 2, 16\nfor ds_name in datasets_list:\n    ds = load_dataset(ds_name)\n    # choose split\n    train_ds = ds[\"train\"].shuffle(seed=0).select(range(train_size))\n    if \"validation\" in ds:\n        val_ds = ds[\"validation\"].shuffle(seed=0).select(range(val_size))\n    else:\n        val_ds = ds[\"test\"].shuffle(seed=0).select(range(val_size))\n    # detect text column\n    text_col = next(k for k, v in ds[\"train\"].features.items() if v.dtype == \"string\")\n    num_labels = ds[\"train\"].features[\"label\"].num_classes\n    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\n    # tokenize\n    def tok_fn(ex):\n        return tokenizer(ex[text_col], truncation=True)\n\n    train_tok = train_ds.map(tok_fn, batched=True)\n    val_tok = val_ds.map(tok_fn, batched=True)\n    train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    val_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    collator = DataCollatorWithPadding(tokenizer)\n    train_loader = DataLoader(\n        train_tok, batch_size=batch_size, shuffle=True, collate_fn=collator\n    )\n    val_loader = DataLoader(\n        val_tok, batch_size=batch_size, shuffle=False, collate_fn=collator\n    )\n    # models\n    cfg = AutoConfig.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n    ai_model = AutoModelForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", config=cfg\n    ).to(device)\n    user_model = AutoModelForSequenceClassification.from_config(cfg).to(device)\n    optim_ai = AdamW(ai_model.parameters(), lr=2e-5)\n    optim_user = AdamW(user_model.parameters(), lr=2e-5)\n    val_losses, val_mais = [], []\n    for epoch in range(1, num_epochs + 1):\n        ai_model.train()\n        user_model.train()\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            out_ai = ai_model(**batch, return_dict=True)\n            out_user = user_model(**batch, return_dict=True)\n            optim_ai.zero_grad()\n            out_ai.loss.backward()\n            optim_ai.step()\n            optim_user.zero_grad()\n            out_user.loss.backward()\n            optim_user.step()\n        # validation\n        ai_model.eval()\n        user_model.eval()\n        total_loss = 0.0\n        total_mai = 0.0\n        n = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                out_ai = ai_model(**batch, return_dict=True)\n                out_user = user_model(**batch, return_dict=True)\n                bs = batch[\"labels\"].size(0)\n                total_loss += out_ai.loss.item() * bs\n                P = torch.softmax(out_ai.logits, dim=1)\n                Q = torch.softmax(out_user.logits, dim=1)\n                R = torch.nn.functional.one_hot(batch[\"labels\"], num_labels).float()\n                js1 = js_divergence(P, Q)\n                js2 = js_divergence(Q, R)\n                a1 = 1 - js1\n                a2 = 1 - js2\n                mai = harmonic_mean(a1, a2)\n                total_mai += torch.sum(mai).item()\n                n += bs\n        val_loss = total_loss / len(val_ds)\n        mean_mai = total_mai / n\n        val_losses.append(val_loss)\n        val_mais.append(mean_mai)\n        print(\n            f\"Dataset {ds_name} Epoch {epoch}: validation_loss = {val_loss:.4f}, MAI = {mean_mai:.4f}\"\n        )\n    experiment_data[ds_name] = {\"val_losses\": val_losses, \"val_mai\": val_mais}\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import (\n    AutoTokenizer,\n    DistilBertForSequenceClassification,\n    DataCollatorWithPadding,\n)\nfrom datasets import load_dataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\nbatch_size = 16\nnum_epochs = 3\nlr = 5e-4\neps = 1e-8\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\ncollator = DataCollatorWithPadding(tokenizer)\n\nexperiment_data = {}\ndatasets_info = [(\"ag_news\", None), (\"imdb\", None), (\"glue\", \"sst2\")]\n\nfor name, subset in datasets_info:\n    ds = load_dataset(name, subset) if subset else load_dataset(name)\n    ds_name = subset if subset else name\n    text_col = \"sentence\" if ds_name == \"sst2\" else \"text\"\n    train_split = \"train\" if \"train\" in ds else next(iter(ds))\n    val_split = (\n        \"test\"\n        if \"test\" in ds\n        else (\"validation\" if \"validation\" in ds else train_split)\n    )\n    N_train, N_val = 1000, 200\n    ds_train = (\n        ds[train_split]\n        .shuffle(seed=0)\n        .select(range(min(N_train, len(ds[train_split]))))\n    )\n    ds_val = ds[val_split].shuffle(seed=0).select(range(min(N_val, len(ds[val_split]))))\n    ds_train = ds_train.map(\n        lambda ex: tokenizer(ex[text_col], truncation=True),\n        batched=True,\n        remove_columns=ds_train.column_names,\n    )\n    ds_val = ds_val.map(\n        lambda ex: tokenizer(ex[text_col], truncation=True),\n        batched=True,\n        remove_columns=ds_val.column_names,\n    )\n    train_loader = DataLoader(\n        ds_train, batch_size=batch_size, shuffle=True, collate_fn=collator\n    )\n    val_loader = DataLoader(\n        ds_val, batch_size=batch_size, shuffle=False, collate_fn=collator\n    )\n    num_labels = ds_train.features[\"label\"].num_classes\n\n    ai_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    user_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    for p in ai_model.distilbert.parameters():\n        p.requires_grad = False\n    for p in user_model.distilbert.parameters():\n        p.requires_grad = False\n\n    optimizer_ai = torch.optim.Adam(\n        filter(lambda p: p.requires_grad, ai_model.parameters()), lr=lr\n    )\n    optimizer_user = torch.optim.Adam(\n        filter(lambda p: p.requires_grad, user_model.parameters()), lr=lr\n    )\n\n    train_losses, val_losses, train_MAIs, val_MAIs = [], [], [], []\n\n    for epoch in range(1, num_epochs + 1):\n        ai_model.train()\n        user_model.train()\n        total_loss = total_a1 = total_a2 = n_samples = 0.0\n        for batch in train_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            if \"label\" in batch:\n                batch[\"labels\"] = batch.pop(\"label\")\n            labels = batch[\"labels\"]\n            out_ai = ai_model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=labels,\n            )\n            out_user = user_model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=labels,\n            )\n            loss_ai, logits_ai = out_ai.loss, out_ai.logits\n            loss_user, logits_user = out_user.loss, out_user.logits\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            bs = labels.size(0)\n            total_loss += loss_ai.item() * bs\n            P = torch.softmax(logits_ai, dim=1)\n            Q = torch.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + eps) - torch.log(M + eps)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + eps) - torch.log(M + eps)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            total_a1 += torch.sum(1 - jsd).item()\n            P_gt = torch.nn.functional.one_hot(labels, num_classes=num_labels).float()\n            M2 = 0.5 * (Q + P_gt)\n            kl1_2 = torch.sum(\n                P_gt * (torch.log(P_gt + eps) - torch.log(M2 + eps)), dim=1\n            )\n            kl2_2 = torch.sum(Q * (torch.log(Q + eps) - torch.log(M2 + eps)), dim=1)\n            jsd2 = 0.5 * (kl1_2 + kl2_2)\n            total_a2 += torch.sum(1 - jsd2).item()\n            n_samples += bs\n        train_loss = total_loss / n_samples\n        a1, a2 = total_a1 / n_samples, total_a2 / n_samples\n        train_MAI = 2 * (a1 * a2) / (a1 + a2 + eps)\n        train_losses.append(train_loss)\n        train_MAIs.append(train_MAI)\n\n        ai_model.eval()\n        user_model.eval()\n        v_loss = va1 = va2 = vs = 0.0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {\n                    k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                    for k, v in batch.items()\n                }\n                if \"label\" in batch:\n                    batch[\"labels\"] = batch.pop(\"label\")\n                labels = batch[\"labels\"]\n                out_ai = ai_model(\n                    input_ids=batch[\"input_ids\"],\n                    attention_mask=batch[\"attention_mask\"],\n                    labels=labels,\n                )\n                logits_ai = out_ai.logits\n                v_loss += out_ai.loss.item() * labels.size(0)\n                out_user = user_model(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                )\n                logits_user = out_user.logits\n                P = torch.softmax(logits_ai, dim=1)\n                Q = torch.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + eps) - torch.log(M + eps)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + eps) - torch.log(M + eps)), dim=1)\n                va1 += torch.sum(1 - 0.5 * (kl1 + kl2)).item()\n                P_gt = torch.nn.functional.one_hot(\n                    labels, num_classes=num_labels\n                ).float()\n                M2 = 0.5 * (Q + P_gt)\n                kl1_2 = torch.sum(\n                    P_gt * (torch.log(P_gt + eps) - torch.log(M2 + eps)), dim=1\n                )\n                kl2_2 = torch.sum(Q * (torch.log(Q + eps) - torch.log(M2 + eps)), dim=1)\n                va2 += torch.sum(1 - 0.5 * (kl1_2 + kl2_2)).item()\n                vs += labels.size(0)\n        val_loss = v_loss / vs\n        ma1, ma2 = va1 / vs, va2 / vs\n        val_MAI = 2 * (ma1 * ma2) / (ma1 + ma2 + eps)\n        val_losses.append(val_loss)\n        val_MAIs.append(val_MAI)\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}, MAI = {val_MAI:.4f}\")\n\n    preds, gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {\n                k: (v.to(device) if isinstance(v, torch.Tensor) else v)\n                for k, v in batch.items()\n            }\n            labels = batch.pop(\"label\") if \"label\" in batch else batch.pop(\"labels\")\n            outputs = ai_model(\n                input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n            )\n            preds.append(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n            gts.append(labels.cpu().numpy())\n    experiment_data[ds_name] = {\n        \"losses\": {\"train\": np.array(train_losses), \"val\": np.array(val_losses)},\n        \"metrics\": {\"train\": np.array(train_MAIs), \"val\": np.array(val_MAIs)},\n        \"predictions\": np.concatenate(preds),\n        \"ground_truth\": np.concatenate(gts),\n    }\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import DataLoader\nfrom transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\nfrom datasets import load_dataset\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndatasets = [\"ag_news\", \"yelp_review_full\", \"dbpedia_14\"]\nexperiment_data = {}\n\nfor ds_name in datasets:\n    ds = load_dataset(ds_name)\n    # sample small subsets\n    train_ds = ds[\"train\"].shuffle(seed=42).select(range(1000))\n    val_ds = ds[\"test\"].shuffle(seed=42).select(range(200))\n    # tokenize\n    train_ds = train_ds.map(\n        lambda e: tokenizer(\n            e[\"text\"], padding=\"max_length\", max_length=128, truncation=True\n        ),\n        batched=True,\n    )\n    val_ds = val_ds.map(\n        lambda e: tokenizer(\n            e[\"text\"], padding=\"max_length\", max_length=128, truncation=True\n        ),\n        batched=True,\n    )\n    train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=32)\n\n    num_labels = ds[\"train\"].features[\"label\"].num_classes\n    ai_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    user_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    optimizer_ai = torch.optim.AdamW(ai_model.parameters(), lr=5e-5)\n    optimizer_user = torch.optim.AdamW(user_model.parameters(), lr=5e-5)\n    loss_fn = CrossEntropyLoss()\n\n    experiment_data[ds_name] = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"metrics\": {\"MAI\": []},\n    }\n\n    for epoch in range(1, 3):\n        # training\n        ai_model.train()\n        user_model.train()\n        total_loss, total_mai, total_samples = 0.0, 0.0, 0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            labels = batch.pop(\"label\")\n            out_ai = ai_model(**batch).logits\n            out_user = user_model(**batch).logits\n            loss_ai = loss_fn(out_ai, labels)\n            loss_user = loss_fn(out_user, labels)\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            total_loss += loss_ai.item() * labels.size(0)\n            # compute JSD-based sub-scores\n            P = F.softmax(out_ai, dim=1)\n            Q = F.softmax(out_user, dim=1)\n            one_hot = torch.zeros_like(P).scatter_(1, labels.unsqueeze(1), 1.0)\n            # first JSD between P and Q\n            M1 = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M1 + 1e-8)), 1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M1 + 1e-8)), 1)\n            align1 = 1 - 0.5 * (kl1 + kl2)\n            # second JSD between Q and one_hot\n            M2 = 0.5 * (Q + one_hot)\n            kl3 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n            kl4 = torch.sum(\n                one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), 1\n            )\n            align2 = 1 - 0.5 * (kl3 + kl4)\n            mai = 2 * (align1 * align2) / (align1 + align2 + 1e-8)\n            total_mai += mai.sum().item()\n            total_samples += labels.size(0)\n        train_loss = total_loss / total_samples\n\n        # validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_mai, v_samples = 0.0, 0.0, 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                labels = batch.pop(\"label\")\n                out_ai = ai_model(**batch).logits\n                out_user = user_model(**batch).logits\n                v_loss += loss_fn(out_ai, labels).item() * labels.size(0)\n                P = F.softmax(out_ai, dim=1)\n                Q = F.softmax(out_user, dim=1)\n                one_hot = torch.zeros_like(P).scatter_(1, labels.unsqueeze(1), 1.0)\n                M1 = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M1 + 1e-8)), 1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M1 + 1e-8)), 1)\n                align1 = 1 - 0.5 * (kl1 + kl2)\n                M2 = 0.5 * (Q + one_hot)\n                kl3 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                kl4 = torch.sum(\n                    one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), 1\n                )\n                align2 = 1 - 0.5 * (kl3 + kl4)\n                mai = 2 * (align1 * align2) / (align1 + align2 + 1e-8)\n                v_mai += mai.sum().item()\n                v_samples += labels.size(0)\n        val_loss = v_loss / v_samples\n        val_mai = v_mai / v_samples\n        print(\n            f\"{ds_name} Epoch {epoch}: val_loss = {val_loss:.4f}, MAI = {val_mai:.4f}\"\n        )\n\n        experiment_data[ds_name][\"losses\"][\"train\"].append(train_loss)\n        experiment_data[ds_name][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[ds_name][\"metrics\"][\"MAI\"].append(val_mai)\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport re\nimport math\nfrom collections import Counter\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n\n# Simple MLP\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Tokenizer\ndef tokenize(text):\n    return re.findall(r\"\\b\\w+\\b\", text.lower())\n\n\nexperiment_data = {}\ndatasets_list = [\"ag_news\", \"imdb\", \"yelp_review_full\"]\nmax_features = 2000\n\nfor dset in datasets_list:\n    raw = load_dataset(dset)\n    train_split, val_split = raw[\"train\"], raw[\"test\"]\n    texts_train = train_split[\"text\"][:2000]\n    labels_train = train_split[\"label\"][:2000]\n    texts_val = val_split[\"text\"][:500]\n    labels_val = val_split[\"label\"][:500]\n\n    # Build TF and DF on training data\n    term_counter = Counter()\n    df_counter = Counter()\n    docs_tokens = []\n    for text in texts_train:\n        toks = tokenize(text)\n        docs_tokens.append(toks)\n        term_counter.update(toks)\n        df_counter.update(set(toks))\n\n    # Vocabulary selection\n    common_terms = [w for w, _ in term_counter.most_common(max_features)]\n    vocab = {w: i for i, w in enumerate(common_terms)}\n    N = len(docs_tokens)\n    idf = np.zeros(len(vocab), dtype=np.float32)\n    for term, idx in vocab.items():\n        df = df_counter[term]\n        idf[idx] = math.log((N + 1) / (df + 1)) + 1\n\n    # Build TF-IDF matrices\n    def build_matrix(texts):\n        M = np.zeros((len(texts), len(vocab)), dtype=np.float32)\n        for i, text in enumerate(texts):\n            toks = text if isinstance(text, list) else tokenize(text)\n            tfc = Counter(toks)\n            L = len(toks) if toks else 1\n            for t, cnt in tfc.items():\n                if t in vocab:\n                    idx = vocab[t]\n                    tf = cnt / L\n                    M[i, idx] = tf * idf[idx]\n        return M\n\n    X_train = build_matrix(docs_tokens)\n    X_val = build_matrix(texts_val)\n\n    # Normalize\n    mu, sigma = X_train.mean(axis=0), X_train.std(axis=0) + 1e-8\n    X_train = (X_train - mu) / sigma\n    X_val = (X_val - mu) / sigma\n\n    y_train = np.array(labels_train)\n    y_val = np.array(labels_val)\n\n    # DataLoaders\n    train_ds = TensorDataset(\n        torch.tensor(X_train, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long),\n    )\n    val_ds = TensorDataset(\n        torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n    )\n    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=64)\n\n    # Models & optimizers\n    in_dim = X_train.shape[1]\n    num_classes = len(set(y_train.tolist()))\n    ai_model = MLP(in_dim, 128, num_classes).to(device)\n    user_model = MLP(in_dim, 128, num_classes).to(device)\n    optim_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n    optim_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Metrics\n    train_losses, train_aligns, train_mais = [], [], []\n    val_losses, val_aligns, val_mais = [], [], []\n\n    # Training loop\n    for epoch in range(1, 6):\n        ai_model.train()\n        user_model.train()\n        t_loss = t_align = t_mai = t_count = 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optim_ai.zero_grad()\n            loss_ai.backward()\n            optim_ai.step()\n            optim_user.zero_grad()\n            loss_user.backward()\n            optim_user.step()\n\n            bs = yb.size(0)\n            t_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            sub1 = 1 - jsd\n            one_hot = F.one_hot(yb, num_classes).float().to(device)\n            M2 = 0.5 * (Q + one_hot)\n            kl1_2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1)\n            kl2_2 = torch.sum(\n                one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n            )\n            jsd2 = 0.5 * (kl1_2 + kl2_2)\n            sub2 = 1 - jsd2\n            mai = 2 * (sub1 * sub2) / (sub1 + sub2 + 1e-8)\n            t_align += sub1.sum().item()\n            t_mai += mai.sum().item()\n            t_count += bs\n\n        train_losses.append(t_loss / len(train_ds))\n        train_aligns.append(t_align / t_count)\n        train_mais.append(t_mai / t_count)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_align = v_mai = v_count = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                logits_user = user_model(xb)\n                loss_v = loss_fn(logits_ai, yb)\n                v_loss += loss_v.item() * yb.size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_user, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                sub1 = 1 - jsd\n                one_hot = F.one_hot(yb, num_classes).float().to(device)\n                M2 = 0.5 * (Q + one_hot)\n                kl1_2 = torch.sum(\n                    Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                kl2_2 = torch.sum(\n                    one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                jsd2 = 0.5 * (kl1_2 + kl2_2)\n                sub2 = 1 - jsd2\n                mai = 2 * (sub1 * sub2) / (sub1 + sub2 + 1e-8)\n                v_align += sub1.sum().item()\n                v_mai += mai.sum().item()\n                v_count += yb.size(0)\n\n        val_losses.append(v_loss / len(val_ds))\n        val_aligns.append(v_align / v_count)\n        val_mais.append(v_mai / v_count)\n        print(\n            f\"Dataset {dset} Epoch {epoch}: validation_loss = {val_losses[-1]:.4f}, validation_MAI = {val_mais[-1]:.4f}\"\n        )\n        print(f\"Epoch {epoch}: validation_loss = {val_losses[-1]:.4f}\")\n\n    # Final predictions\n    preds, gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            out = ai_model(xb)\n            preds.append(torch.argmax(out, dim=1).cpu().numpy())\n            gts.append(yb.numpy())\n    preds = np.concatenate(preds)\n    gts = np.concatenate(gts)\n\n    experiment_data[dset] = {\n        \"metrics\": {\n            \"train\": {\"loss\": train_losses, \"align\": train_aligns, \"MAI\": train_mais},\n            \"val\": {\"loss\": val_losses, \"align\": val_aligns, \"MAI\": val_mais},\n        },\n        \"predictions\": preds,\n        \"ground_truth\": gts,\n    }\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom datasets import load_dataset\nfrom transformers import (\n    DistilBertTokenizerFast,\n    DistilBertForSequenceClassification,\n    AdamW,\n)\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n\ndataset_names = [(\"glue\", \"sst2\"), \"ag_news\", \"dbpedia_14\"]\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\nexperiment_data = {}\nepochs = 3\nbatch_size = 16\n\nfor ds in dataset_names:\n    if isinstance(ds, tuple):\n        ds_name = ds[1]\n        data = load_dataset(ds[0], ds[1])\n    else:\n        ds_name = ds\n        data = load_dataset(ds)\n    cols = data[\"train\"].column_names\n    text_col = next((c for c in cols if c in [\"sentence\", \"text\", \"content\"]), cols[0])\n    label_col = \"label\"\n\n    def tokenize_fn(batch):\n        return tokenizer(\n            batch[text_col], truncation=True, padding=\"max_length\", max_length=128\n        )\n\n    data = data.map(tokenize_fn, batched=True)\n    data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", label_col])\n    train_ds = (\n        data[\"train\"].shuffle(seed=0).select(range(min(1000, len(data[\"train\"]))))\n    )\n    val_split = \"validation\" if \"validation\" in data else \"test\"\n    val_ds = (\n        data[val_split].shuffle(seed=0).select(range(min(200, len(data[val_split]))))\n    )\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size)\n    num_labels = len(set(train_ds[label_col].numpy().tolist()))\n    ai_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    user_model = DistilBertForSequenceClassification.from_pretrained(\n        \"distilbert-base-uncased\", num_labels=num_labels\n    ).to(device)\n    optimizer_ai = AdamW(ai_model.parameters(), lr=2e-5)\n    optimizer_user = AdamW(user_model.parameters(), lr=2e-5)\n    exp = {\n        \"metrics\": {\"train\": {\"loss\": [], \"MAI\": []}, \"val\": {\"loss\": [], \"MAI\": []}},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, epochs + 1):\n        ai_model.train()\n        user_model.train()\n        tr_loss = 0\n        tr_mai = 0\n        n_tr = 0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            labels = batch[label_col]\n            out_ai = ai_model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=labels,\n            )\n            out_um = user_model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=labels,\n            )\n            loss_ai, logits_ai = out_ai.loss, out_ai.logits\n            loss_um, logits_um = out_um.loss, out_um.logits\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_um.backward()\n            optimizer_user.step()\n            bs = labels.size(0)\n            tr_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_um, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            s1 = 1 - 0.5 * (kl1 + kl2)\n            one_hot = F.one_hot(labels, num_classes=num_labels).float()\n            M2 = 0.5 * (Q + one_hot)\n            kl21 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1)\n            kl22 = torch.sum(\n                one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n            )\n            s2 = 1 - 0.5 * (kl21 + kl22)\n            mai = 2 * (s1 * s2) / (s1 + s2 + 1e-8)\n            tr_mai += torch.sum(mai).item()\n            n_tr += bs\n        tr_loss /= len(train_loader.dataset)\n        tr_mai /= n_tr\n        exp[\"metrics\"][\"train\"][\"loss\"].append(tr_loss)\n        exp[\"metrics\"][\"train\"][\"MAI\"].append(tr_mai)\n        ai_model.eval()\n        user_model.eval()\n        val_loss = 0\n        val_mai = 0\n        n_val = 0\n        all_preds, all_gts = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                labels = batch[label_col]\n                out_ai = ai_model(\n                    input_ids=batch[\"input_ids\"],\n                    attention_mask=batch[\"attention_mask\"],\n                    labels=labels,\n                )\n                logits_ai = out_ai.logits\n                loss_v = out_ai.loss\n                logits_um = user_model(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                )[0]\n                bs = labels.size(0)\n                val_loss += loss_v.item() * bs\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(logits_um, dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                s1 = 1 - 0.5 * (kl1 + kl2)\n                one_hot = F.one_hot(labels, num_classes=num_labels).float()\n                M2 = 0.5 * (Q + one_hot)\n                kl21 = torch.sum(\n                    Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                kl22 = torch.sum(\n                    one_hot * (torch.log(one_hot + 1e-8) - torch.log(M2 + 1e-8)), dim=1\n                )\n                s2 = 1 - 0.5 * (kl21 + kl22)\n                mai = 2 * (s1 * s2) / (s1 + s2 + 1e-8)\n                val_mai += torch.sum(mai).item()\n                n_val += bs\n                preds = torch.argmax(logits_ai, dim=1).cpu().numpy()\n                all_preds.append(preds)\n                all_gts.append(labels.cpu().numpy())\n        val_loss /= len(val_loader.dataset)\n        val_mai /= n_val\n        exp[\"metrics\"][\"val\"][\"loss\"].append(val_loss)\n        exp[\"metrics\"][\"val\"][\"MAI\"].append(val_mai)\n        exp[\"predictions\"].append(np.concatenate(all_preds))\n        exp[\"ground_truth\"].append(np.concatenate(all_gts))\n        print(\n            f\"Dataset {ds_name} Epoch {epoch}: validation_loss = {val_loss:.4f}, validation_MAI = {val_mai:.4f}\"\n        )\n    experiment_data[ds_name] = exp\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\nimport numpy as np\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizerFast, DistilBertModel\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\ndistilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\ndistilbert.eval()\n\n\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        return self.fc2(F.relu(self.fc1(x)))\n\n\nexperiment_data = {}\nfor name in [\"ag_news\", \"yelp_polarity\", \"dbpedia_14\"]:\n    raw = load_dataset(name, split=\"train\").shuffle(seed=0).select(range(2500))\n    split = raw.train_test_split(test_size=0.2, seed=0)\n    train_ds, val_ds = split[\"train\"], split[\"test\"]\n    text_key = \"text\" if \"text\" in raw.column_names else \"content\"\n\n    def tokenize_fn(batch):\n        return tokenizer(\n            batch[text_key], padding=\"max_length\", truncation=True, max_length=128\n        )\n\n    train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n    val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[text_key])\n    train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=32)\n    num_labels = len(set(train_ds[\"label\"]))\n    ai_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n    user_model = MLP(distilbert.config.hidden_size, 128, num_labels).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=1e-3)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n    experiment_data[name] = {\n        \"losses\": {\"train\": [], \"val\": []},\n        \"alignments\": {\"train\": [], \"val\": []},\n        \"mai\": [],\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    for epoch in range(1, 4):\n        ai_model.train()\n        user_model.train()\n        tot_loss, tot_align, tot_acc, n = 0.0, 0.0, 0, 0\n        for batch in train_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            with torch.no_grad():\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n            logits_ai = ai_model(emb)\n            logits_user = user_model(emb)\n            loss_ai = loss_fn(logits_ai, batch[\"label\"])\n            loss_user = loss_fn(logits_user, batch[\"label\"])\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            bs = batch[\"label\"].size(0)\n            tot_loss += loss_ai.item() * bs\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            tot_align += torch.sum(1 - jsd).item()\n            tot_acc += (torch.argmax(logits_user, dim=1) == batch[\"label\"]).sum().item()\n            n += bs\n        experiment_data[name][\"losses\"][\"train\"].append(tot_loss / len(train_ds))\n        experiment_data[name][\"alignments\"][\"train\"].append(tot_align / n)\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_align, v_acc, v_n = 0.0, 0.0, 0, 0\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                emb = distilbert(\n                    input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n                ).last_hidden_state[:, 0, :]\n                logits_ai = ai_model(emb)\n                v_loss += loss_fn(logits_ai, batch[\"label\"]).item() * batch[\n                    \"label\"\n                ].size(0)\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(emb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                v_align += torch.sum(1 - jsd).item()\n                v_acc += (\n                    (torch.argmax(user_model(emb), dim=1) == batch[\"label\"])\n                    .sum()\n                    .item()\n                )\n                v_n += batch[\"label\"].size(0)\n        val_loss = v_loss / len(val_ds)\n        val_align = v_align / v_n\n        val_acc = v_acc / v_n\n        mai = 2 * (val_align * val_acc) / (val_align + val_acc + 1e-8)\n        experiment_data[name][\"losses\"][\"val\"].append(val_loss)\n        experiment_data[name][\"alignments\"][\"val\"].append(val_align)\n        experiment_data[name][\"mai\"].append(mai)\n        print(\n            f\"Dataset {name} Epoch {epoch}: validation_loss = {val_loss:.4f}, MAI = {mai:.4f}\"\n        )\n\n    preds, gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            emb = distilbert(\n                input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n            ).last_hidden_state[:, 0, :]\n            preds.append(torch.argmax(ai_model(emb), dim=1).cpu().numpy())\n            gts.append(batch[\"label\"].cpu().numpy())\n    experiment_data[name][\"predictions\"] = np.concatenate(preds)\n    experiment_data[name][\"ground_truth\"] = np.concatenate(gts)\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom datasets import load_dataset\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Hyperparameters\nN_train, N_val = 1000, 200\nmax_features = 2000\nbatch_size = 32\nnum_epochs = 5\nlr = 1e-3\ndataset_names = [\"ag_news\", \"imdb\", \"yelp_polarity\"]\n\n\n# MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Utility: build TF-IDF\ndef build_vocab_idf(texts, max_features):\n    from collections import Counter, defaultdict\n\n    N = len(texts)\n    df = defaultdict(int)\n    tf_counts = Counter()\n    for doc in texts:\n        tokens = doc.lower().split()\n        seen = set()\n        for t in tokens:\n            tf_counts[t] += 1\n            if t not in seen:\n                df[t] += 1\n                seen.add(t)\n    # top features\n    top = [w for w, _ in tf_counts.most_common(max_features)]\n    idf = np.array([np.log((N + 1) / (df[w] + 1)) + 1 for w in top], dtype=np.float32)\n    vocab = {w: i for i, w in enumerate(top)}\n    return vocab, idf\n\n\ndef texts_to_tfidf(texts, vocab, idf):\n    X = np.zeros((len(texts), len(idf)), dtype=np.float32)\n    for i, doc in enumerate(texts):\n        for t in doc.lower().split():\n            idx = vocab.get(t)\n            if idx is not None:\n                X[i, idx] += 1\n    X *= idf[np.newaxis, :]\n    return X\n\n\n# Loss\nloss_fn = nn.CrossEntropyLoss()\n\nexperiment_data = {}\nfor ds_name in dataset_names:\n    # load and split\n    raw = (\n        load_dataset(ds_name, split=\"train\")\n        .shuffle(seed=42)\n        .select(range(N_train + N_val))\n    )\n    texts = raw[\"text\"]\n    labels = np.array(raw[\"label\"])\n    train_texts, val_texts = texts[:N_train], texts[N_train:]\n    y_train, y_val = labels[:N_train], labels[N_train:]\n    C = int(labels.max()) + 1\n\n    # build TF-IDF\n    vocab, idf = build_vocab_idf(train_texts, max_features)\n    X_train = texts_to_tfidf(train_texts, vocab, idf)\n    X_val = texts_to_tfidf(val_texts, vocab, idf)\n    # standardize\n    mean = X_train.mean(0)\n    std = X_train.std(0)\n    std[std == 0] = 1.0\n    X_train = (X_train - mean) / std\n    X_val = (X_val - mean) / std\n\n    # DataLoaders\n    train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n    val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size)\n\n    # prepare experiment storage\n    experiment_data[ds_name] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n    data = experiment_data[ds_name]\n\n    # models + optimizers\n    ai_model = MLP(max_features, 128, C).to(device)\n    user_model = MLP(max_features, 128, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # training loop\n    for epoch in range(1, num_epochs + 1):\n        ai_model.train()\n        user_model.train()\n        total_loss = total_a1 = total_a2 = n_samples = 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # losses\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # alignments\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), 1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), 1)\n            a1 = torch.mean(1 - 0.5 * (kl1 + kl2)).item()\n            Pgt = torch.zeros_like(Q).scatter_(1, yb.unsqueeze(1), 1.0)\n            M2 = 0.5 * (Q + Pgt)\n            k1 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n            k2 = torch.sum(Pgt * (torch.log(Pgt + 1e-8) - torch.log(M2 + 1e-8)), 1)\n            a2 = torch.mean(1 - 0.5 * (k1 + k2)).item()\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            total_a1 += a1 * bs\n            total_a2 += a2 * bs\n            n_samples += bs\n\n        train_loss = total_loss / len(train_ds)\n        ta1 = total_a1 / n_samples\n        ta2 = total_a2 / n_samples\n        train_mai = 2 * (ta1 * ta2) / (ta1 + ta2 + 1e-8)\n        data[\"losses\"][\"train\"].append(train_loss)\n        data[\"metrics\"][\"train\"].append(train_mai)\n\n        # validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss = v_a1 = v_a2 = v_samples = 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                P = F.softmax(logits_ai, 1)\n                Q = F.softmax(user_model(xb), 1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), 1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), 1)\n                v_a1 += torch.sum(1 - 0.5 * (kl1 + kl2)).item()\n                Pgt = torch.zeros_like(Q).scatter_(1, yb.unsqueeze(1), 1.0)\n                M2 = 0.5 * (Q + Pgt)\n                k1 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                k2 = torch.sum(Pgt * (torch.log(Pgt + 1e-8) - torch.log(M2 + 1e-8)), 1)\n                v_a2 += torch.sum(1 - 0.5 * (k1 + k2)).item()\n                v_samples += yb.size(0)\n\n        val_loss = v_loss / len(val_ds)\n        va1 = v_a1 / v_samples\n        va2 = v_a2 / v_samples\n        val_mai = 2 * (va1 * va2) / (va1 + va2 + 1e-8)\n        data[\"losses\"][\"val\"].append(val_loss)\n        data[\"metrics\"][\"val\"].append(val_mai)\n\n        print(f\"Epoch {epoch}: validation_loss = {val_loss:.4f}\")\n        print(f\"Dataset {ds_name} Epoch {epoch}: MAI = {val_mai:.4f}\")\n\n    # final predictions & ground truth\n    preds, truth = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            logits = ai_model(xb)\n            preds.extend(logits.argmax(1).cpu().numpy().tolist())\n            truth.extend(yb.cpu().numpy().tolist())\n    data[\"predictions\"] = preds\n    data[\"ground_truth\"] = truth\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Synthetic data generation\nN_train, N_val, D, C = 1000, 200, 10, 3\nW_true = np.random.randn(D, C)\nx_train = np.random.randn(N_train, D)\nx_val = np.random.randn(N_val, D)\ny_train = np.argmax(x_train @ W_true + 0.1 * np.random.randn(N_train, C), axis=1)\ny_val = np.argmax(x_val @ W_true + 0.1 * np.random.randn(N_val, C), axis=1)\nmean = x_train.mean(axis=0)\nstd = x_train.std(axis=0) + 1e-8\nx_train = (x_train - mean) / std\nx_val = (x_val - mean) / std\n\n# DataLoaders\ntrain_dataset = TensorDataset(\n    torch.tensor(x_train, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.long),\n)\nval_dataset = TensorDataset(\n    torch.tensor(x_val, dtype=torch.float32),\n    torch.tensor(y_val, dtype=torch.long),\n)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64)\n\n\n# Simple MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Hyperparameter sweep over learning rates\nlearning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\nnum_epochs = 10\n\n# Initialize experiment_data dict\nexperiment_data = {\n    \"learning_rate\": {\n        \"synthetic\": {\n            \"lrs\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nloss_fn = nn.CrossEntropyLoss()\n\nfor lr in learning_rates:\n    # Reset model weights for fair comparison\n    torch.manual_seed(0)\n    ai_model = MLP(D, 32, C).to(device)\n    user_model = MLP(D, 32, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # Containers for this learning rate\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss, total_align, n_samples = 0.0, 0.0, 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            # Forward passes\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # Cross-entropy losses\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            # Backprop AI\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            # Backprop user\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # Accumulate loss\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            # Alignment (1 - JSD)\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            total_align += torch.sum(1 - jsd).item()\n            n_samples += bs\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_align, v_samples = 0.0, 0.0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                # loss\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                # alignment\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                v_align += torch.sum(1 - jsd).item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        print(\n            f\"LR {lr:.1e} Epoch {epoch}: val_loss = {val_losses[-1]:.4f}, val_align = {val_aligns[-1]:.4f}\"\n        )\n\n    # Store per\u2010epoch metrics\n    sd = experiment_data[\"learning_rate\"][\"synthetic\"]\n    sd[\"metrics\"][\"train\"].append(train_aligns)\n    sd[\"metrics\"][\"val\"].append(val_aligns)\n    sd[\"losses\"][\"train\"].append(train_losses)\n    sd[\"losses\"][\"val\"].append(val_losses)\n\n    # Final validation predictions & ground truth\n    all_preds, all_gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(yb.numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n    sd[\"predictions\"].append(preds_arr)\n    sd[\"ground_truth\"].append(gts_arr)\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Synthetic data generation\nN_train, N_val, D, C = 1000, 200, 10, 3\nW_true = np.random.randn(D, C)\nx_train = np.random.randn(N_train, D)\nx_val = np.random.randn(N_val, D)\ny_train = np.argmax(x_train @ W_true + 0.1 * np.random.randn(N_train, C), axis=1)\ny_val = np.argmax(x_val @ W_true + 0.1 * np.random.randn(N_val, C), axis=1)\nmean = x_train.mean(axis=0)\nstd = x_train.std(axis=0) + 1e-8\nx_train = (x_train - mean) / std\nx_val = (x_val - mean) / std\n\n# DataLoaders\ntrain_dataset = TensorDataset(\n    torch.tensor(x_train, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.long),\n)\nval_dataset = TensorDataset(\n    torch.tensor(x_val, dtype=torch.float32),\n    torch.tensor(y_val, dtype=torch.long),\n)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64)\n\n\n# Simple MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Hyperparameter sweep over learning rates\nlearning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\nnum_epochs = 10\n\n# Initialize experiment_data dict\nexperiment_data = {\n    \"learning_rate\": {\n        \"synthetic\": {\n            \"lrs\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nloss_fn = nn.CrossEntropyLoss()\n\nfor lr in learning_rates:\n    # Reset model weights for fair comparison\n    torch.manual_seed(0)\n    ai_model = MLP(D, 32, C).to(device)\n    user_model = MLP(D, 32, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # Containers for this learning rate\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss, total_align, n_samples = 0.0, 0.0, 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            # Forward passes\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # Cross-entropy losses\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            # Backprop AI\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            # Backprop user\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # Accumulate loss\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            # Alignment (1 - JSD)\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            total_align += torch.sum(1 - jsd).item()\n            n_samples += bs\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_align, v_samples = 0.0, 0.0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                # loss\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                # alignment\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                v_align += torch.sum(1 - jsd).item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        print(\n            f\"LR {lr:.1e} Epoch {epoch}: val_loss = {val_losses[-1]:.4f}, val_align = {val_aligns[-1]:.4f}\"\n        )\n\n    # Store per\u2010epoch metrics\n    sd = experiment_data[\"learning_rate\"][\"synthetic\"]\n    sd[\"metrics\"][\"train\"].append(train_aligns)\n    sd[\"metrics\"][\"val\"].append(val_aligns)\n    sd[\"losses\"][\"train\"].append(train_losses)\n    sd[\"losses\"][\"val\"].append(val_losses)\n\n    # Final validation predictions & ground truth\n    all_preds, all_gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(yb.numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n    sd[\"predictions\"].append(preds_arr)\n    sd[\"ground_truth\"].append(gts_arr)\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 2\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Setup working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Reproducibility\ntorch.manual_seed(0)\nnp.random.seed(0)\n\n# Synthetic data generation\nN_train, N_val, D, C = 1000, 200, 10, 3\nW_true = np.random.randn(D, C)\nx_train = np.random.randn(N_train, D)\nx_val = np.random.randn(N_val, D)\ny_train = np.argmax(x_train @ W_true + 0.1 * np.random.randn(N_train, C), axis=1)\ny_val = np.argmax(x_val @ W_true + 0.1 * np.random.randn(N_val, C), axis=1)\nmean = x_train.mean(axis=0)\nstd = x_train.std(axis=0) + 1e-8\nx_train = (x_train - mean) / std\nx_val = (x_val - mean) / std\n\n# DataLoaders\ntrain_dataset = TensorDataset(\n    torch.tensor(x_train, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.long),\n)\nval_dataset = TensorDataset(\n    torch.tensor(x_val, dtype=torch.float32),\n    torch.tensor(y_val, dtype=torch.long),\n)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64)\n\n\n# Simple MLP definition\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hid_dim, out_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(in_dim, hid_dim)\n        self.fc2 = nn.Linear(hid_dim, out_dim)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n\n# Hyperparameter sweep over learning rates\nlearning_rates = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\nnum_epochs = 10\n\n# Initialize experiment_data dict\nexperiment_data = {\n    \"learning_rate\": {\n        \"synthetic\": {\n            \"lrs\": learning_rates,\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n    }\n}\n\nloss_fn = nn.CrossEntropyLoss()\n\nfor lr in learning_rates:\n    # Reset model weights for fair comparison\n    torch.manual_seed(0)\n    ai_model = MLP(D, 32, C).to(device)\n    user_model = MLP(D, 32, C).to(device)\n    optimizer_ai = torch.optim.Adam(ai_model.parameters(), lr=lr)\n    optimizer_user = torch.optim.Adam(user_model.parameters(), lr=lr)\n\n    # Containers for this learning rate\n    train_losses, val_losses = [], []\n    train_aligns, val_aligns = [], []\n\n    for epoch in range(1, num_epochs + 1):\n        # Training\n        ai_model.train()\n        user_model.train()\n        total_loss, total_align, n_samples = 0.0, 0.0, 0\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            # Forward passes\n            logits_ai = ai_model(xb)\n            logits_user = user_model(xb)\n            # Cross-entropy losses\n            loss_ai = loss_fn(logits_ai, yb)\n            loss_user = loss_fn(logits_user, yb)\n            # Backprop AI\n            optimizer_ai.zero_grad()\n            loss_ai.backward()\n            optimizer_ai.step()\n            # Backprop user\n            optimizer_user.zero_grad()\n            loss_user.backward()\n            optimizer_user.step()\n            # Accumulate loss\n            bs = yb.size(0)\n            total_loss += loss_ai.item() * bs\n            # Alignment (1 - JSD)\n            P = F.softmax(logits_ai, dim=1)\n            Q = F.softmax(logits_user, dim=1)\n            M = 0.5 * (P + Q)\n            kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n            jsd = 0.5 * (kl1 + kl2)\n            total_align += torch.sum(1 - jsd).item()\n            n_samples += bs\n        train_losses.append(total_loss / len(train_dataset))\n        train_aligns.append(total_align / n_samples)\n\n        # Validation\n        ai_model.eval()\n        user_model.eval()\n        v_loss, v_align, v_samples = 0.0, 0.0, 0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                logits_ai = ai_model(xb)\n                # loss\n                v_loss += loss_fn(logits_ai, yb).item() * yb.size(0)\n                # alignment\n                P = F.softmax(logits_ai, dim=1)\n                Q = F.softmax(user_model(xb), dim=1)\n                M = 0.5 * (P + Q)\n                kl1 = torch.sum(P * (torch.log(P + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                kl2 = torch.sum(Q * (torch.log(Q + 1e-8) - torch.log(M + 1e-8)), dim=1)\n                jsd = 0.5 * (kl1 + kl2)\n                v_align += torch.sum(1 - jsd).item()\n                v_samples += yb.size(0)\n        val_losses.append(v_loss / len(val_dataset))\n        val_aligns.append(v_align / v_samples)\n        print(\n            f\"LR {lr:.1e} Epoch {epoch}: val_loss = {val_losses[-1]:.4f}, val_align = {val_aligns[-1]:.4f}\"\n        )\n\n    # Store per\u2010epoch metrics\n    sd = experiment_data[\"learning_rate\"][\"synthetic\"]\n    sd[\"metrics\"][\"train\"].append(train_aligns)\n    sd[\"metrics\"][\"val\"].append(val_aligns)\n    sd[\"losses\"][\"train\"].append(train_losses)\n    sd[\"losses\"][\"val\"].append(val_losses)\n\n    # Final validation predictions & ground truth\n    all_preds, all_gts = [], []\n    ai_model.eval()\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds = torch.argmax(ai_model(xb), dim=1).cpu().numpy()\n            all_preds.append(preds)\n            all_gts.append(yb.numpy())\n    preds_arr = np.concatenate(all_preds, axis=0)\n    gts_arr = np.concatenate(all_gts, axis=0)\n    sd[\"predictions\"].append(preds_arr)\n    sd[\"ground_truth\"].append(gts_arr)\n\n# Save all experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# plotting aggregation code"], "term_out": ["['Using device: cuda', '\\n', 'LR 1.0e-04 Epoch 1: val_loss = 1.0651, val_align =\n0.9922', '\\n', 'LR 1.0e-04 Epoch 2: val_loss = 1.0588, val_align = 0.9923',\n'\\n', 'LR 1.0e-04 Epoch 3: val_loss = 1.0526, val_align = 0.9924', '\\n', 'LR\n1.0e-04 Epoch 4: val_loss = 1.0464, val_align = 0.9925', '\\n', 'LR 1.0e-04 Epoch\n5: val_loss = 1.0403, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 6: val_loss =\n1.0343, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 7: val_loss = 1.0283,\nval_align = 0.9927', '\\n', 'LR 1.0e-04 Epoch 8: val_loss = 1.0224, val_align =\n0.9928', '\\n', 'LR 1.0e-04 Epoch 9: val_loss = 1.0165, val_align = 0.9928',\n'\\n', 'LR 1.0e-04 Epoch 10: val_loss = 1.0106, val_align = 0.9929', '\\n', 'LR\n5.0e-04 Epoch 1: val_loss = 1.0400, val_align = 0.9926', '\\n', 'LR 5.0e-04 Epoch\n2: val_loss = 1.0104, val_align = 0.9929', '\\n', 'LR 5.0e-04 Epoch 3: val_loss =\n0.9821, val_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 4: val_loss = 0.9540,\nval_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 5: val_loss = 0.9259, val_align =\n0.9930', '\\n', 'LR 5.0e-04 Epoch 6: val_loss = 0.8980, val_align = 0.9927',\n'\\n', 'LR 5.0e-04 Epoch 7: val_loss = 0.8697, val_align = 0.9925', '\\n', 'LR\n5.0e-04 Epoch 8: val_loss = 0.8407, val_align = 0.9922', '\\n', 'LR 5.0e-04 Epoch\n9: val_loss = 0.8115, val_align = 0.9918', '\\n', 'LR 5.0e-04 Epoch 10: val_loss\n= 0.7817, val_align = 0.9915', '\\n', 'LR 1.0e-03 Epoch 1: val_loss = 1.0102,\nval_align = 0.9930', '\\n', 'LR 1.0e-03 Epoch 2: val_loss = 0.9538, val_align =\n0.9932', '\\n', 'LR 1.0e-03 Epoch 3: val_loss = 0.8995, val_align = 0.9928',\n'\\n', 'LR 1.0e-03 Epoch 4: val_loss = 0.8438, val_align = 0.9922', '\\n', 'LR\n1.0e-03 Epoch 5: val_loss = 0.7864, val_align = 0.9916', '\\n', 'LR 1.0e-03 Epoch\n6: val_loss = 0.7292, val_align = 0.9909', '\\n', 'LR 1.0e-03 Epoch 7: val_loss =\n0.6713, val_align = 0.9904', '\\n', 'LR 1.0e-03 Epoch 8: val_loss = 0.6147,\nval_align = 0.9902', '\\n', 'LR 1.0e-03 Epoch 9: val_loss = 0.5608, val_align =\n0.9903', '\\n', 'LR 1.0e-03 Epoch 10: val_loss = 0.5101, val_align = 0.9907',\n'\\n', 'LR 5.0e-03 Epoch 1: val_loss = 0.7999, val_align = 0.9919', '\\n', 'LR\n5.0e-03 Epoch 2: val_loss = 0.5444, val_align = 0.9895', '\\n', 'LR 5.0e-03 Epoch\n3: val_loss = 0.3476, val_align = 0.9923', '\\n', 'LR 5.0e-03 Epoch 4: val_loss =\n0.2409, val_align = 0.9956', '\\n', 'LR 5.0e-03 Epoch 5: val_loss = 0.1822,\nval_align = 0.9971', '\\n', 'LR 5.0e-03 Epoch 6: val_loss = 0.1579, val_align =\n0.9980', '\\n', 'LR 5.0e-03 Epoch 7: val_loss = 0.1343, val_align = 0.9983',\n'\\n', 'LR 5.0e-03 Epoch 8: val_loss = 0.1260, val_align = 0.9986', '\\n', 'LR\n5.0e-03 Epoch 9: val_loss = 0.1144, val_align = 0.9987', '\\n', 'LR 5.0e-03 Epoch\n10: val_loss = 0.1039, val_align = 0.9989', '\\n', 'LR 1.0e-02 Epoch 1: val_loss\n= 0.5694, val_align = 0.9887', '\\n', 'LR 1.0e-02 Epoch 2: val_loss = 0.2476,\nval_align = 0.9946', '\\n', 'LR 1.0e-02 Epoch 3: val_loss = 0.1484, val_align =\n0.9973', '\\n', 'LR 1.0e-02 Epoch 4: val_loss = 0.1135, val_align = 0.9985',\n'\\n', 'LR 1.0e-02 Epoch 5: val_loss = 0.0999, val_align = 0.9986', '\\n', 'LR\n1.0e-02 Epoch 6: val_loss = 0.0867, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch\n7: val_loss = 0.0869, val_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 8: val_loss =\n0.0786, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch 9: val_loss = 0.0752,\nval_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 10: val_loss = 0.0739, val_align =\n0.9986', '\\n', 'Execution time: 3 seconds seconds (time limit is an hour).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 8, in <module>\\n\nfrom sklearn.feature_extraction.text import\nTfidfVectorizer\\nModuleNotFoundError: No module named \\'sklearn\\'\\n', 'Execution\ntime: a moment seconds (time limit is an hour).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 12, in\n<module>\\n    from sklearn.feature_extraction.text import\nTfidfVectorizer\\nModuleNotFoundError: No module named \\'sklearn\\'\\n', 'Execution\ntime: a moment seconds (time limit is an hour).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 12, in\n<module>\\n    from sklearn.feature_extraction.text import\nCountVectorizer\\nModuleNotFoundError: No module named \\'sklearn\\'\\n', 'Execution\ntime: a moment seconds (time limit is an hour).']", "['Using device: cuda', '\\n', '--- Dataset: ag_news ---', '\\n', 'Epoch 1:\nvalidation_loss = 1.3269', '\\n', 'Epoch 2: validation_loss = 1.1735', '\\n',\n'Epoch 3: validation_loss = 0.9456', '\\n', 'Epoch 4: validation_loss = 0.7685',\n'\\n', 'Epoch 5: validation_loss = 0.6785', '\\n', '--- Dataset: yelp_polarity\n---', '\\n', 'Epoch 1: validation_loss = 0.6514', '\\n', 'Epoch 2: validation_loss\n= 0.5490', '\\n', 'Epoch 3: validation_loss = 0.4565', '\\n', 'Epoch 4:\nvalidation_loss = 0.4088', '\\n', 'Epoch 5: validation_loss = 0.3732', '\\n', '---\nDataset: imdb ---', '\\n', 'Epoch 1: validation_loss = 0.0000', '\\n', 'Epoch 2:\nvalidation_loss = 0.0000', '\\n', 'Epoch 3: validation_loss = 0.0000', '\\n',\n'Epoch 4: validation_loss = 0.0000', '\\n', 'Epoch 5: validation_loss = 0.0000',\n'\\n', 'Execution time: 34 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'Dataset ag_news Epoch 1: validation_loss = 0.7363,\nMAI = 0.8821', '\\n', 'Dataset ag_news Epoch 2: validation_loss = 0.7212, MAI =\n0.9001', '\\n', 'Dataset ag_news Epoch 3: validation_loss = 0.8479, MAI =\n0.9010', '\\n', 'Dataset ag_news Epoch 4: validation_loss = 0.9331, MAI =\n0.8996', '\\n', 'Dataset ag_news Epoch 5: validation_loss = 1.0167, MAI =\n0.8967', '\\n', 'Dataset dbpedia_14 Epoch 1: validation_loss = 1.3791, MAI =\n0.7660', '\\n', 'Dataset dbpedia_14 Epoch 2: validation_loss = 0.4470, MAI =\n0.9237', '\\n', 'Dataset dbpedia_14 Epoch 3: validation_loss = 0.1238, MAI =\n0.9797', '\\n', 'Dataset dbpedia_14 Epoch 4: validation_loss = 0.0449, MAI =\n0.9926', '\\n', 'Dataset dbpedia_14 Epoch 5: validation_loss = 0.0228, MAI =\n0.9961', '\\n', 'Dataset yelp_polarity Epoch 1: validation_loss = 0.4623, MAI =\n0.9319', '\\n', 'Dataset yelp_polarity Epoch 2: validation_loss = 0.4269, MAI =\n0.9438', '\\n', 'Dataset yelp_polarity Epoch 3: validation_loss = 0.4031, MAI =\n0.9523', '\\n', 'Dataset yelp_polarity Epoch 4: validation_loss = 0.4315, MAI =\n0.9538', '\\n', 'Dataset yelp_polarity Epoch 5: validation_loss = 0.4463, MAI =\n0.9548', '\\n', 'Execution time: 36 seconds seconds (time limit is an hour).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 9, in <module>\\n\nfrom transformers import (\\nImportError: cannot import name \\'AdamW\\' from\n\\'transformers\\'\n(/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/transformers/__init__.py)\\n', 'Execution time: a moment seconds (time\nlimit is an hour).']", "['Using device: cuda', '\\n', '\\rMap:   0%|          | 0/1000 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 1000/1000 [00:00<00:00, 12254.52\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/200 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 200/200 [00:00<00:00, 12796.29 examples/s]', '\\n',\n'Traceback (most recent call last):\\n  File \"runfile.py\", line 65, in <module>\\n\nnum_labels = ds_train.features[\"label\"].num_classes\\n\n~~~~~~~~~~~~~~~~~^^^^^^^^^\\nKeyError: \\'label\\'\\n', 'Execution time: 10 seconds\nseconds (time limit is an hour).']", "['Using device: cuda', '\\n', '\\rMap:   0%|          | 0/1000 [00:00<?, ?\nexamples/s]', '\\rMap: 100%|##########| 1000/1000 [00:00<00:00, 7463.92\nexamples/s]', '', '\\rMap: 100%|##########| 1000/1000 [00:00<00:00, 7267.70\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/200 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 200/200 [00:00<00:00, 6759.88 examples/s]', '\\n', \"Some\nweights of DistilBertForSequenceClassification were not initialized from the\nmodel checkpoint at distilbert-base-uncased and are newly initialized:\n['classifier.bias', 'classifier.weight', 'pre_classifier.bias',\n'pre_classifier.weight']\\nYou should probably TRAIN this model on a down-stream\ntask to be able to use it for predictions and inference.\\n\", \"Some weights of\nDistilBertForSequenceClassification were not initialized from the model\ncheckpoint at distilbert-base-uncased and are newly initialized:\n['classifier.bias', 'classifier.weight', 'pre_classifier.bias',\n'pre_classifier.weight']\\nYou should probably TRAIN this model on a down-stream\ntask to be able to use it for predictions and inference.\\n\", 'ag_news Epoch 1:\nval_loss = 0.6088, MAI = 0.9097', '\\n', 'ag_news Epoch 2: val_loss = 0.5005, MAI\n= 0.9277', '\\n', '\\rREADME.md:   0%|          | 0.00/6.72k [00:00<?, ?B/s]', '',\n'\\rREADME.md: 100%|##########| 6.72k/6.72k [00:00<00:00, 18.3MB/s]', '\\n',\n'\\rtrain-00000-of-00001.parquet:   0%|          | 0.00/299M [00:00<?, ?B/s]',\n'\\rtrain-00000-of-00001.parquet:   4%|3         | 10.5M/299M [00:00<00:24,\n11.8MB/s]', '\\rtrain-00000-of-00001.parquet:   7%|7         | 21.0M/299M\n[00:01<00:23, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  11%|#         |\n31.5M/299M [00:02<00:22, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  14%|#4\n| 41.9M/299M [00:03<00:21, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  18%|#7\n| 52.4M/299M [00:04<00:21, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  21%|##1\n| 62.9M/299M [00:05<00:20, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  25%|##4\n| 73.4M/299M [00:06<00:19, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  28%|##8\n| 83.9M/299M [00:07<00:18, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:\n32%|###1      | 94.4M/299M [00:08<00:17, 11.8MB/s]',\n'\\rtrain-00000-of-00001.parquet:  35%|###5      | 105M/299M [00:08<00:16,\n11.8MB/s] ', '\\rtrain-00000-of-00001.parquet:  39%|###8      | 115M/299M\n[00:09<00:15, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  42%|####2     |\n126M/299M [00:10<00:14, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  46%|####5\n| 136M/299M [00:11<00:13, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:\n49%|####9     | 147M/299M [00:12<00:12, 11.8MB/s]',\n'\\rtrain-00000-of-00001.parquet:  53%|#####2    | 157M/299M [00:13<00:12,\n11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  56%|#####6    | 168M/299M\n[00:14<00:11, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  60%|#####9    |\n178M/299M [00:15<00:10, 11.7MB/s]', '\\rtrain-00000-of-00001.parquet:\n63%|######3   | 189M/299M [00:16<00:09, 11.8MB/s]',\n'\\rtrain-00000-of-00001.parquet:  67%|######6   | 199M/299M [00:16<00:08,\n11.7MB/s]', '\\rtrain-00000-of-00001.parquet:  70%|#######   | 210M/299M\n[00:17<00:07, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  74%|#######3  |\n220M/299M [00:18<00:06, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:\n77%|#######7  | 231M/299M [00:19<00:05, 11.8MB/s]',\n'\\rtrain-00000-of-00001.parquet:  81%|########  | 241M/299M [00:20<00:04,\n11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  84%|########4 | 252M/299M\n[00:21<00:04, 11.8MB/s]', '\\rtrain-00000-of-00001.parquet:  88%|########7 |\n262M/299M [00:22<00:03, 11.3MB/s]', '\\rtrain-00000-of-00001.parquet:\n91%|#########1| 273M/299M [00:23<00:02, 11.4MB/s]',\n'\\rtrain-00000-of-00001.parquet:  95%|#########4| 283M/299M [00:24<00:01,\n11.5MB/s]', '\\rtrain-00000-of-00001.parquet:  98%|#########8| 294M/299M\n[00:25<00:00, 11.6MB/s]', '\\rtrain-00000-of-00001.parquet: 100%|##########|\n299M/299M [00:25<00:00, 11.6MB/s]', '', '\\rtrain-00000-of-00001.parquet:\n100%|##########| 299M/299M [00:25<00:00, 11.7MB/s]', '\\n',\n'\\rtest-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]',\n'\\rtest-00000-of-00001.parquet:  45%|####4     | 10.5M/23.5M [00:00<00:01,\n11.8MB/s]', '\\rtest-00000-of-00001.parquet:  89%|########9 | 21.0M/23.5M\n[00:01<00:00, 11.5MB/s]', '\\rtest-00000-of-00001.parquet: 100%|##########|\n23.5M/23.5M [00:02<00:00, 11.5MB/s]', '', '\\rtest-00000-of-00001.parquet:\n100%|##########| 23.5M/23.5M [00:02<00:00, 11.5MB/s]', '\\n', '\\rGenerating train\nsplit:   0%|          | 0/650000 [00:00<?, ? examples/s]', '\\rGenerating train\nsplit:   2%|1         | 10000/650000 [00:00<00:07, 87679.81 examples/s]',\n'\\rGenerating train split:   5%|4         | 30000/650000 [00:00<00:04, 145739.35\nexamples/s]', '\\rGenerating train split:   8%|7         | 51000/650000\n[00:00<00:03, 170905.98 examples/s]', '\\rGenerating train split:  11%|#1\n| 72000/650000 [00:00<00:03, 180089.73 examples/s]', '\\rGenerating train split:\n15%|#5        | 98000/650000 [00:00<00:03, 172413.01 examples/s]', '\\rGenerating\ntrain split:  18%|#8        | 119000/650000 [00:00<00:02, 180276.54\nexamples/s]', '\\rGenerating train split:  21%|##1       | 138000/650000\n[00:00<00:02, 180526.04 examples/s]', '\\rGenerating train split:  25%|##4\n| 161000/650000 [00:00<00:02, 168355.36 examples/s]', '\\rGenerating train split:\n28%|##7       | 179000/650000 [00:01<00:02, 167279.39 examples/s]',\n'\\rGenerating train split:  31%|###       | 199000/650000 [00:01<00:02,\n172036.74 examples/s]', '\\rGenerating train split:  34%|###3      |\n218000/650000 [00:01<00:02, 163044.34 examples/s]', '\\rGenerating train split:\n37%|###6      | 238000/650000 [00:01<00:02, 169465.32 examples/s]',\n'\\rGenerating train split:  40%|###9      | 259000/650000 [00:01<00:02,\n179192.85 examples/s]', '\\rGenerating train split:  43%|####2     |\n279000/650000 [00:01<00:02, 183100.10 examples/s]', '\\rGenerating train split:\n46%|####6     | 302000/650000 [00:01<00:02, 167904.48 examples/s]',\n'\\rGenerating train split:  50%|#####     | 328000/650000 [00:01<00:01,\n166186.74 examples/s]', '\\rGenerating train split:  54%|#####3    |\n348000/650000 [00:02<00:01, 171057.30 examples/s]', '\\rGenerating train split:\n58%|#####7    | 374000/650000 [00:02<00:01, 161879.57 examples/s]',\n'\\rGenerating train split:  60%|######    | 393000/650000 [00:02<00:01,\n166317.36 examples/s]', '\\rGenerating train split:  64%|######3   |\n413000/650000 [00:02<00:01, 172664.28 examples/s]', '\\rGenerating train split:\n67%|######6   | 433000/650000 [00:02<00:01, 178524.49 examples/s]',\n'\\rGenerating train split:  70%|#######   | 456000/650000 [00:02<00:01,\n167485.72 examples/s]', '\\rGenerating train split:  73%|#######3  |\n476000/650000 [00:02<00:01, 173022.90 examples/s]', '\\rGenerating train split:\n76%|#######6  | 495000/650000 [00:02<00:00, 174949.06 examples/s]',\n'\\rGenerating train split:  80%|#######9  | 518000/650000 [00:03<00:00,\n165105.42 examples/s]', '\\rGenerating train split:  83%|########2 |\n539000/650000 [00:03<00:00, 173782.03 examples/s]', '\\rGenerating train split:\n86%|########6 | 559000/650000 [00:03<00:00, 178031.86 examples/s]',\n'\\rGenerating train split:  89%|########9 | 579000/650000 [00:03<00:00,\n181121.22 examples/s]', '\\rGenerating train split:  93%|#########2|\n603000/650000 [00:03<00:00, 170724.77 examples/s]', '\\rGenerating train split:\n96%|#########6| 624000/650000 [00:03<00:00, 177471.90 examples/s]',\n'\\rGenerating train split:  99%|#########9| 644000/650000 [00:03<00:00,\n180061.32 examples/s]', '', '\\rGenerating train split: 100%|##########|\n650000/650000 [00:03<00:00, 171149.93 examples/s]', '\\n', '\\rGenerating test\nsplit:   0%|          | 0/50000 [00:00<?, ? examples/s]', '\\rGenerating test\nsplit:  28%|##8       | 14000/50000 [00:00<00:00, 131275.07 examples/s]',\n'\\rGenerating test split:  68%|######8   | 34000/50000 [00:00<00:00, 165768.94\nexamples/s]', '', '\\rGenerating test split: 100%|##########| 50000/50000\n[00:00<00:00, 170743.92 examples/s]', '\\n', '\\rMap:   0%|          | 0/1000\n[00:00<?, ? examples/s]', '\\rMap: 100%|##########| 1000/1000 [00:00<00:00,\n7576.13 examples/s]', '', '\\rMap: 100%|##########| 1000/1000 [00:00<00:00,\n7388.81 examples/s]', '\\n', '\\rMap:   0%|          | 0/200 [00:00<?, ?\nexamples/s]', '', '\\rMap: 100%|##########| 200/200 [00:00<00:00, 5678.99\nexamples/s]', '\\n', \"Some weights of DistilBertForSequenceClassification were\nnot initialized from the model checkpoint at distilbert-base-uncased and are\nnewly initialized: ['classifier.bias', 'classifier.weight',\n'pre_classifier.bias', 'pre_classifier.weight']\\nYou should probably TRAIN this\nmodel on a down-stream task to be able to use it for predictions and\ninference.\\n\", \"Some weights of DistilBertForSequenceClassification were not\ninitialized from the model checkpoint at distilbert-base-uncased and are newly\ninitialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias',\n'pre_classifier.weight']\\nYou should probably TRAIN this model on a down-stream\ntask to be able to use it for predictions and inference.\\n\", 'yelp_review_full\nEpoch 1: val_loss = 1.1767, MAI = 0.7940', '\\n', 'yelp_review_full Epoch 2:\nval_loss = 1.0856, MAI = 0.8106', '\\n', '\\rMap:   0%|          | 0/1000\n[00:00<?, ? examples/s]', '', '\\rMap:   0%|          | 0/1000 [00:00<?, ?\nexamples/s]', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\",\nline 26, in <module>\\n    train_ds = train_ds.map(\\n\n^^^^^^^^^^^^^\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 557, in wrapper\\n    out:\nUnion[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 3079, in map\\n    for rank, done,\ncontent in Dataset._map_single(**dataset_kwargs):\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 3525, in _map_single\\n    for i, batch\nin iter_outputs(shard_iterable):\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 3475, in iter_outputs\\n    yield i,\napply_function(example, i, offset=offset)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/arrow_dataset.py\", line 3398, in apply_function\\n\nprocessed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"runfile.py\", line 28,\nin <lambda>\\n    e[\"text\"], padding=\"max_length\", max_length=128,\ntruncation=True\\n    ~^^^^^^^^\\n  File\n\"/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/datasets/formatting/formatting.py\", line 278, in __getitem__\\n    value\n= self.data[key]\\n            ~~~~~~~~~^^^^^\\nKeyError: \\'text\\'\\n', 'Execution\ntime: a minute seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'Dataset ag_news Epoch 1: validation_loss = 0.6928,\nvalidation_MAI = 0.8785', '\\n', 'Epoch 1: validation_loss = 0.6928', '\\n',\n'Dataset ag_news Epoch 2: validation_loss = 0.5988, validation_MAI = 0.9038',\n'\\n', 'Epoch 2: validation_loss = 0.5988', '\\n', 'Dataset ag_news Epoch 3:\nvalidation_loss = 0.6546, validation_MAI = 0.9020', '\\n', 'Epoch 3:\nvalidation_loss = 0.6546', '\\n', 'Dataset ag_news Epoch 4: validation_loss =\n0.6765, validation_MAI = 0.9036', '\\n', 'Epoch 4: validation_loss = 0.6765',\n'\\n', 'Dataset ag_news Epoch 5: validation_loss = 0.7197, validation_MAI =\n0.9011', '\\n', 'Epoch 5: validation_loss = 0.7197', '\\n', 'Dataset imdb Epoch 1:\nvalidation_loss = 0.0000, validation_MAI = 1.0000', '\\n', 'Epoch 1:\nvalidation_loss = 0.0000', '\\n', 'Dataset imdb Epoch 2: validation_loss =\n0.0000, validation_MAI = 1.0000', '\\n', 'Epoch 2: validation_loss = 0.0000',\n'\\n', 'Dataset imdb Epoch 3: validation_loss = 0.0000, validation_MAI = 1.0000',\n'\\n', 'Epoch 3: validation_loss = 0.0000', '\\n', 'Dataset imdb Epoch 4:\nvalidation_loss = 0.0000, validation_MAI = 1.0000', '\\n', 'Epoch 4:\nvalidation_loss = 0.0000', '\\n', 'Dataset imdb Epoch 5: validation_loss =\n0.0000, validation_MAI = 1.0000', '\\n', 'Epoch 5: validation_loss = 0.0000',\n'\\n', 'Dataset yelp_review_full Epoch 1: validation_loss = 1.3710,\nvalidation_MAI = 0.7691', '\\n', 'Epoch 1: validation_loss = 1.3710', '\\n',\n'Dataset yelp_review_full Epoch 2: validation_loss = 1.3073, validation_MAI =\n0.7852', '\\n', 'Epoch 2: validation_loss = 1.3073', '\\n', 'Dataset\nyelp_review_full Epoch 3: validation_loss = 1.4001, validation_MAI = 0.7820',\n'\\n', 'Epoch 3: validation_loss = 1.4001', '\\n', 'Dataset yelp_review_full Epoch\n4: validation_loss = 1.5257, validation_MAI = 0.7748', '\\n', 'Epoch 4:\nvalidation_loss = 1.5257', '\\n', 'Dataset yelp_review_full Epoch 5:\nvalidation_loss = 1.6229, validation_MAI = 0.7694', '\\n', 'Epoch 5:\nvalidation_loss = 1.6229', '\\n', 'Execution time: 45 seconds seconds (time limit\nis an hour).']", "['Traceback (most recent call last):\\n  File \"runfile.py\", line 10, in\n<module>\\n    from transformers import (\\nImportError: cannot import name\n\\'AdamW\\' from \\'transformers\\'\n(/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-\npackages/transformers/__init__.py)\\n', 'Execution time: a second seconds (time\nlimit is an hour).']", "['Using device: cuda', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '\\rMap:  50%|#####     | 1000/2000 [00:00<00:00, 8341.48\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 9393.29\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/500 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 500/500 [00:00<00:00, 11603.01 examples/s]', '\\n',\n'Dataset ag_news Epoch 1: validation_loss = 0.4909, MAI = 0.9305', '\\n',\n'Dataset ag_news Epoch 2: validation_loss = 0.3699, MAI = 0.9358', '\\n',\n'Dataset ag_news Epoch 3: validation_loss = 0.3472, MAI = 0.9427', '\\n', '\\rMap:\n0%|          | 0/2000 [00:00<?, ? examples/s]', '\\rMap:  50%|#####     |\n1000/2000 [00:00<00:00, 8533.25 examples/s]', '\\rMap: 100%|##########| 2000/2000\n[00:00<00:00, 8175.44 examples/s]', '', '\\rMap: 100%|##########| 2000/2000\n[00:00<00:00, 8126.76 examples/s]', '\\n', '\\rMap:   0%|          | 0/500\n[00:00<?, ? examples/s]', '', '\\rMap: 100%|##########| 500/500 [00:00<00:00,\n7337.88 examples/s]', '\\n', 'Dataset yelp_polarity Epoch 1: validation_loss =\n0.4694, MAI = 0.9062', '\\n', 'Dataset yelp_polarity Epoch 2: validation_loss =\n0.3836, MAI = 0.9094', '\\n', 'Dataset yelp_polarity Epoch 3: validation_loss =\n0.3789, MAI = 0.9047', '\\n', '\\rMap:   0%|          | 0/2000 [00:00<?, ?\nexamples/s]', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 10923.22\nexamples/s]', '', '\\rMap: 100%|##########| 2000/2000 [00:00<00:00, 10724.31\nexamples/s]', '\\n', '\\rMap:   0%|          | 0/500 [00:00<?, ? examples/s]', '',\n'\\rMap: 100%|##########| 500/500 [00:00<00:00, 11112.03 examples/s]', '\\n',\n'Dataset dbpedia_14 Epoch 1: validation_loss = 0.7949, MAI = 0.9508', '\\n',\n'Dataset dbpedia_14 Epoch 2: validation_loss = 0.2998, MAI = 0.9797', '\\n',\n'Dataset dbpedia_14 Epoch 3: validation_loss = 0.1728, MAI = 0.9858', '\\n',\n'Execution time: 53 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'Epoch 1: validation_loss = 0.7803', '\\n', 'Dataset\nag_news Epoch 1: MAI = 0.8708', '\\n', 'Epoch 2: validation_loss = 0.5753', '\\n',\n'Dataset ag_news Epoch 2: MAI = 0.9147', '\\n', 'Epoch 3: validation_loss =\n0.5499', '\\n', 'Dataset ag_news Epoch 3: MAI = 0.9235', '\\n', 'Epoch 4:\nvalidation_loss = 0.5535', '\\n', 'Dataset ag_news Epoch 4: MAI = 0.9270', '\\n',\n'Epoch 5: validation_loss = 0.5560', '\\n', 'Dataset ag_news Epoch 5: MAI =\n0.9288', '\\n', 'Epoch 1: validation_loss = 0.5539', '\\n', 'Dataset imdb Epoch 1:\nMAI = 0.9120', '\\n', 'Epoch 2: validation_loss = 0.5160', '\\n', 'Dataset imdb\nEpoch 2: MAI = 0.9291', '\\n', 'Epoch 3: validation_loss = 0.5240', '\\n',\n'Dataset imdb Epoch 3: MAI = 0.9322', '\\n', 'Epoch 4: validation_loss = 0.5590',\n'\\n', 'Dataset imdb Epoch 4: MAI = 0.9310', '\\n', 'Epoch 5: validation_loss =\n0.5738', '\\n', 'Dataset imdb Epoch 5: MAI = 0.9312', '\\n', 'Epoch 1:\nvalidation_loss = 0.4765', '\\n', 'Dataset yelp_polarity Epoch 1: MAI = 0.9185',\n'\\n', 'Epoch 2: validation_loss = 0.3608', '\\n', 'Dataset yelp_polarity Epoch 2:\nMAI = 0.9390', '\\n', 'Epoch 3: validation_loss = 0.3716', '\\n', 'Dataset\nyelp_polarity Epoch 3: MAI = 0.9423', '\\n', 'Epoch 4: validation_loss = 0.4047',\n'\\n', 'Dataset yelp_polarity Epoch 4: MAI = 0.9415', '\\n', 'Epoch 5:\nvalidation_loss = 0.4506', '\\n', 'Dataset yelp_polarity Epoch 5: MAI = 0.9384',\n'\\n', 'Execution time: 34 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'LR 1.0e-04 Epoch 1: val_loss = 1.0651, val_align =\n0.9922', '\\n', 'LR 1.0e-04 Epoch 2: val_loss = 1.0588, val_align = 0.9923',\n'\\n', 'LR 1.0e-04 Epoch 3: val_loss = 1.0526, val_align = 0.9924', '\\n', 'LR\n1.0e-04 Epoch 4: val_loss = 1.0464, val_align = 0.9925', '\\n', 'LR 1.0e-04 Epoch\n5: val_loss = 1.0403, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 6: val_loss =\n1.0343, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 7: val_loss = 1.0283,\nval_align = 0.9927', '\\n', 'LR 1.0e-04 Epoch 8: val_loss = 1.0224, val_align =\n0.9928', '\\n', 'LR 1.0e-04 Epoch 9: val_loss = 1.0165, val_align = 0.9928',\n'\\n', 'LR 1.0e-04 Epoch 10: val_loss = 1.0106, val_align = 0.9929', '\\n', 'LR\n5.0e-04 Epoch 1: val_loss = 1.0400, val_align = 0.9926', '\\n', 'LR 5.0e-04 Epoch\n2: val_loss = 1.0104, val_align = 0.9929', '\\n', 'LR 5.0e-04 Epoch 3: val_loss =\n0.9821, val_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 4: val_loss = 0.9540,\nval_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 5: val_loss = 0.9259, val_align =\n0.9930', '\\n', 'LR 5.0e-04 Epoch 6: val_loss = 0.8980, val_align = 0.9927',\n'\\n', 'LR 5.0e-04 Epoch 7: val_loss = 0.8697, val_align = 0.9925', '\\n', 'LR\n5.0e-04 Epoch 8: val_loss = 0.8407, val_align = 0.9922', '\\n', 'LR 5.0e-04 Epoch\n9: val_loss = 0.8115, val_align = 0.9918', '\\n', 'LR 5.0e-04 Epoch 10: val_loss\n= 0.7817, val_align = 0.9915', '\\n', 'LR 1.0e-03 Epoch 1: val_loss = 1.0102,\nval_align = 0.9930', '\\n', 'LR 1.0e-03 Epoch 2: val_loss = 0.9538, val_align =\n0.9932', '\\n', 'LR 1.0e-03 Epoch 3: val_loss = 0.8995, val_align = 0.9928',\n'\\n', 'LR 1.0e-03 Epoch 4: val_loss = 0.8438, val_align = 0.9922', '\\n', 'LR\n1.0e-03 Epoch 5: val_loss = 0.7864, val_align = 0.9916', '\\n', 'LR 1.0e-03 Epoch\n6: val_loss = 0.7292, val_align = 0.9909', '\\n', 'LR 1.0e-03 Epoch 7: val_loss =\n0.6713, val_align = 0.9904', '\\n', 'LR 1.0e-03 Epoch 8: val_loss = 0.6147,\nval_align = 0.9902', '\\n', 'LR 1.0e-03 Epoch 9: val_loss = 0.5608, val_align =\n0.9903', '\\n', 'LR 1.0e-03 Epoch 10: val_loss = 0.5101, val_align = 0.9907',\n'\\n', 'LR 5.0e-03 Epoch 1: val_loss = 0.7999, val_align = 0.9919', '\\n', 'LR\n5.0e-03 Epoch 2: val_loss = 0.5444, val_align = 0.9895', '\\n', 'LR 5.0e-03 Epoch\n3: val_loss = 0.3476, val_align = 0.9923', '\\n', 'LR 5.0e-03 Epoch 4: val_loss =\n0.2409, val_align = 0.9956', '\\n', 'LR 5.0e-03 Epoch 5: val_loss = 0.1822,\nval_align = 0.9971', '\\n', 'LR 5.0e-03 Epoch 6: val_loss = 0.1579, val_align =\n0.9980', '\\n', 'LR 5.0e-03 Epoch 7: val_loss = 0.1343, val_align = 0.9983',\n'\\n', 'LR 5.0e-03 Epoch 8: val_loss = 0.1260, val_align = 0.9986', '\\n', 'LR\n5.0e-03 Epoch 9: val_loss = 0.1144, val_align = 0.9987', '\\n', 'LR 5.0e-03 Epoch\n10: val_loss = 0.1039, val_align = 0.9989', '\\n', 'LR 1.0e-02 Epoch 1: val_loss\n= 0.5694, val_align = 0.9887', '\\n', 'LR 1.0e-02 Epoch 2: val_loss = 0.2476,\nval_align = 0.9946', '\\n', 'LR 1.0e-02 Epoch 3: val_loss = 0.1484, val_align =\n0.9973', '\\n', 'LR 1.0e-02 Epoch 4: val_loss = 0.1135, val_align = 0.9985',\n'\\n', 'LR 1.0e-02 Epoch 5: val_loss = 0.0999, val_align = 0.9986', '\\n', 'LR\n1.0e-02 Epoch 6: val_loss = 0.0867, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch\n7: val_loss = 0.0869, val_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 8: val_loss =\n0.0786, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch 9: val_loss = 0.0752,\nval_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 10: val_loss = 0.0739, val_align =\n0.9986', '\\n', 'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'LR 1.0e-04 Epoch 1: val_loss = 1.0651, val_align =\n0.9922', '\\n', 'LR 1.0e-04 Epoch 2: val_loss = 1.0588, val_align = 0.9923',\n'\\n', 'LR 1.0e-04 Epoch 3: val_loss = 1.0526, val_align = 0.9924', '\\n', 'LR\n1.0e-04 Epoch 4: val_loss = 1.0464, val_align = 0.9925', '\\n', 'LR 1.0e-04 Epoch\n5: val_loss = 1.0403, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 6: val_loss =\n1.0343, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 7: val_loss = 1.0283,\nval_align = 0.9927', '\\n', 'LR 1.0e-04 Epoch 8: val_loss = 1.0224, val_align =\n0.9928', '\\n', 'LR 1.0e-04 Epoch 9: val_loss = 1.0165, val_align = 0.9928',\n'\\n', 'LR 1.0e-04 Epoch 10: val_loss = 1.0106, val_align = 0.9929', '\\n', 'LR\n5.0e-04 Epoch 1: val_loss = 1.0400, val_align = 0.9926', '\\n', 'LR 5.0e-04 Epoch\n2: val_loss = 1.0104, val_align = 0.9929', '\\n', 'LR 5.0e-04 Epoch 3: val_loss =\n0.9821, val_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 4: val_loss = 0.9540,\nval_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 5: val_loss = 0.9259, val_align =\n0.9930', '\\n', 'LR 5.0e-04 Epoch 6: val_loss = 0.8980, val_align = 0.9927',\n'\\n', 'LR 5.0e-04 Epoch 7: val_loss = 0.8697, val_align = 0.9925', '\\n', 'LR\n5.0e-04 Epoch 8: val_loss = 0.8407, val_align = 0.9922', '\\n', 'LR 5.0e-04 Epoch\n9: val_loss = 0.8115, val_align = 0.9918', '\\n', 'LR 5.0e-04 Epoch 10: val_loss\n= 0.7817, val_align = 0.9915', '\\n', 'LR 1.0e-03 Epoch 1: val_loss = 1.0102,\nval_align = 0.9930', '\\n', 'LR 1.0e-03 Epoch 2: val_loss = 0.9538, val_align =\n0.9932', '\\n', 'LR 1.0e-03 Epoch 3: val_loss = 0.8995, val_align = 0.9928',\n'\\n', 'LR 1.0e-03 Epoch 4: val_loss = 0.8438, val_align = 0.9922', '\\n', 'LR\n1.0e-03 Epoch 5: val_loss = 0.7864, val_align = 0.9916', '\\n', 'LR 1.0e-03 Epoch\n6: val_loss = 0.7292, val_align = 0.9909', '\\n', 'LR 1.0e-03 Epoch 7: val_loss =\n0.6713, val_align = 0.9904', '\\n', 'LR 1.0e-03 Epoch 8: val_loss = 0.6147,\nval_align = 0.9902', '\\n', 'LR 1.0e-03 Epoch 9: val_loss = 0.5608, val_align =\n0.9903', '\\n', 'LR 1.0e-03 Epoch 10: val_loss = 0.5101, val_align = 0.9907',\n'\\n', 'LR 5.0e-03 Epoch 1: val_loss = 0.7999, val_align = 0.9919', '\\n', 'LR\n5.0e-03 Epoch 2: val_loss = 0.5444, val_align = 0.9895', '\\n', 'LR 5.0e-03 Epoch\n3: val_loss = 0.3476, val_align = 0.9923', '\\n', 'LR 5.0e-03 Epoch 4: val_loss =\n0.2409, val_align = 0.9956', '\\n', 'LR 5.0e-03 Epoch 5: val_loss = 0.1822,\nval_align = 0.9971', '\\n', 'LR 5.0e-03 Epoch 6: val_loss = 0.1579, val_align =\n0.9980', '\\n', 'LR 5.0e-03 Epoch 7: val_loss = 0.1343, val_align = 0.9983',\n'\\n', 'LR 5.0e-03 Epoch 8: val_loss = 0.1260, val_align = 0.9986', '\\n', 'LR\n5.0e-03 Epoch 9: val_loss = 0.1144, val_align = 0.9987', '\\n', 'LR 5.0e-03 Epoch\n10: val_loss = 0.1039, val_align = 0.9989', '\\n', 'LR 1.0e-02 Epoch 1: val_loss\n= 0.5694, val_align = 0.9887', '\\n', 'LR 1.0e-02 Epoch 2: val_loss = 0.2476,\nval_align = 0.9946', '\\n', 'LR 1.0e-02 Epoch 3: val_loss = 0.1484, val_align =\n0.9973', '\\n', 'LR 1.0e-02 Epoch 4: val_loss = 0.1135, val_align = 0.9985',\n'\\n', 'LR 1.0e-02 Epoch 5: val_loss = 0.0999, val_align = 0.9986', '\\n', 'LR\n1.0e-02 Epoch 6: val_loss = 0.0867, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch\n7: val_loss = 0.0869, val_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 8: val_loss =\n0.0786, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch 9: val_loss = 0.0752,\nval_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 10: val_loss = 0.0739, val_align =\n0.9986', '\\n', 'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cuda', '\\n', 'LR 1.0e-04 Epoch 1: val_loss = 1.0651, val_align =\n0.9922', '\\n', 'LR 1.0e-04 Epoch 2: val_loss = 1.0588, val_align = 0.9923',\n'\\n', 'LR 1.0e-04 Epoch 3: val_loss = 1.0526, val_align = 0.9924', '\\n', 'LR\n1.0e-04 Epoch 4: val_loss = 1.0464, val_align = 0.9925', '\\n', 'LR 1.0e-04 Epoch\n5: val_loss = 1.0403, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 6: val_loss =\n1.0343, val_align = 0.9926', '\\n', 'LR 1.0e-04 Epoch 7: val_loss = 1.0283,\nval_align = 0.9927', '\\n', 'LR 1.0e-04 Epoch 8: val_loss = 1.0224, val_align =\n0.9928', '\\n', 'LR 1.0e-04 Epoch 9: val_loss = 1.0165, val_align = 0.9928',\n'\\n', 'LR 1.0e-04 Epoch 10: val_loss = 1.0106, val_align = 0.9929', '\\n', 'LR\n5.0e-04 Epoch 1: val_loss = 1.0400, val_align = 0.9926', '\\n', 'LR 5.0e-04 Epoch\n2: val_loss = 1.0104, val_align = 0.9929', '\\n', 'LR 5.0e-04 Epoch 3: val_loss =\n0.9821, val_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 4: val_loss = 0.9540,\nval_align = 0.9931', '\\n', 'LR 5.0e-04 Epoch 5: val_loss = 0.9259, val_align =\n0.9930', '\\n', 'LR 5.0e-04 Epoch 6: val_loss = 0.8980, val_align = 0.9927',\n'\\n', 'LR 5.0e-04 Epoch 7: val_loss = 0.8697, val_align = 0.9925', '\\n', 'LR\n5.0e-04 Epoch 8: val_loss = 0.8407, val_align = 0.9922', '\\n', 'LR 5.0e-04 Epoch\n9: val_loss = 0.8115, val_align = 0.9918', '\\n', 'LR 5.0e-04 Epoch 10: val_loss\n= 0.7817, val_align = 0.9915', '\\n', 'LR 1.0e-03 Epoch 1: val_loss = 1.0102,\nval_align = 0.9930', '\\n', 'LR 1.0e-03 Epoch 2: val_loss = 0.9538, val_align =\n0.9932', '\\n', 'LR 1.0e-03 Epoch 3: val_loss = 0.8995, val_align = 0.9928',\n'\\n', 'LR 1.0e-03 Epoch 4: val_loss = 0.8438, val_align = 0.9922', '\\n', 'LR\n1.0e-03 Epoch 5: val_loss = 0.7864, val_align = 0.9916', '\\n', 'LR 1.0e-03 Epoch\n6: val_loss = 0.7292, val_align = 0.9909', '\\n', 'LR 1.0e-03 Epoch 7: val_loss =\n0.6713, val_align = 0.9904', '\\n', 'LR 1.0e-03 Epoch 8: val_loss = 0.6147,\nval_align = 0.9902', '\\n', 'LR 1.0e-03 Epoch 9: val_loss = 0.5608, val_align =\n0.9903', '\\n', 'LR 1.0e-03 Epoch 10: val_loss = 0.5101, val_align = 0.9907',\n'\\n', 'LR 5.0e-03 Epoch 1: val_loss = 0.7999, val_align = 0.9919', '\\n', 'LR\n5.0e-03 Epoch 2: val_loss = 0.5444, val_align = 0.9895', '\\n', 'LR 5.0e-03 Epoch\n3: val_loss = 0.3476, val_align = 0.9923', '\\n', 'LR 5.0e-03 Epoch 4: val_loss =\n0.2409, val_align = 0.9956', '\\n', 'LR 5.0e-03 Epoch 5: val_loss = 0.1822,\nval_align = 0.9971', '\\n', 'LR 5.0e-03 Epoch 6: val_loss = 0.1579, val_align =\n0.9980', '\\n', 'LR 5.0e-03 Epoch 7: val_loss = 0.1343, val_align = 0.9983',\n'\\n', 'LR 5.0e-03 Epoch 8: val_loss = 0.1260, val_align = 0.9986', '\\n', 'LR\n5.0e-03 Epoch 9: val_loss = 0.1144, val_align = 0.9987', '\\n', 'LR 5.0e-03 Epoch\n10: val_loss = 0.1039, val_align = 0.9989', '\\n', 'LR 1.0e-02 Epoch 1: val_loss\n= 0.5694, val_align = 0.9887', '\\n', 'LR 1.0e-02 Epoch 2: val_loss = 0.2476,\nval_align = 0.9946', '\\n', 'LR 1.0e-02 Epoch 3: val_loss = 0.1484, val_align =\n0.9973', '\\n', 'LR 1.0e-02 Epoch 4: val_loss = 0.1135, val_align = 0.9985',\n'\\n', 'LR 1.0e-02 Epoch 5: val_loss = 0.0999, val_align = 0.9986', '\\n', 'LR\n1.0e-02 Epoch 6: val_loss = 0.0867, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch\n7: val_loss = 0.0869, val_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 8: val_loss =\n0.0786, val_align = 0.9988', '\\n', 'LR 1.0e-02 Epoch 9: val_loss = 0.0752,\nval_align = 0.9990', '\\n', 'LR 1.0e-02 Epoch 10: val_loss = 0.0739, val_align =\n0.9986', '\\n', 'Execution time: 4 seconds seconds (time limit is an hour).']", ""], "analysis": ["The code ran successfully with no runtime errors. Training and validation losses\ndecreased as expected across epochs, and alignment scores behaved reasonably,\npeaking around learning rates 5e-3 and 1e-2. No bugs were detected.", "The script fails immediately with ModuleNotFoundError: No module named\n'sklearn'. The scikit-learn library is not installed in the environment. To fix\nthis, install scikit-learn (e.g., pip install scikit-learn) or include it in the\nproject\u2019s requirements before running the script.", "The script fails at importing TfidfVectorizer due to scikit-learn not being\ninstalled (ModuleNotFoundError). To fix, add 'scikit-learn' to the environment\nrequirements and install it (e.g., pip install scikit-learn) before running the\nscript.", "The script failed at the import of CountVectorizer due to a missing scikit-learn\ndependency (ModuleNotFoundError: No module named 'sklearn'). To fix, install\nscikit-learn (e.g., pip install scikit-learn) or replace the text vectorization\nstep with a tokenizer/feature extraction method available in the current\nenvironment (e.g., Hugging Face tokenizers).", "The validation loss for the IMDb dataset is reported as 0.0000 at every epoch,\nwhich is almost certainly incorrect. This indicates that the IMDb validation\nsamples are not being processed correctly (e.g., the `val_dataset` may be empty\nor the manual vocabulary/vectorization for IMDb is producing all-zero feature\nvectors). As a result, CrossEntropyLoss always returns zero. To fix this, verify\nthat `ds['test']` for IMDb actually contains samples and that `val_loader`\nyields non-empty batches. Inspect the vectorized inputs for IMDb to ensure they\nhave non-zero entries. You may also switch from a simple whitespace-based\ntokenizer to a more robust HuggingFace tokenizer to ensure proper coverage of\ntokens. Additionally, correct the duplicate \u201cseconds seconds\u201d in the final\nexecution-time print statement.", "", "The script fails with ImportError: cannot import name 'AdamW' from\n'transformers'. Transformers library no longer exposes AdamW at the top level.\nFix by importing AdamW from torch.optim (from torch.optim import AdamW) or from\ntransformers.optimization import AdamW.", "The script fails with KeyError: 'label' because the ds_train.map() call uses\nremove_columns=ds_train.column_names, which removes the original 'label' column.\nAs a result, ds_train.features no longer contains 'label'. To fix, only drop the\ntext column when tokenizing (e.g., remove_columns=[text_col]) so that 'label' is\npreserved, or compute num_labels before removing the 'label' feature.", "The script crashes when processing the dbpedia_14 dataset because it uses\ne['text'] for tokenization, but dbpedia_14 has no 'text' column (it uses\n'content' and 'title'). This KeyError stops execution and prevents completing\nthe experiments. Proposed fix: detect or rename the correct text field per\ndataset (e.g., use e['content'] for dbpedia_14) or standardize the column names\nacross datasets before mapping.", "The validation metrics for the imdb dataset are unrealistically perfect\n(validation_loss = 0.0000 and validation_MAI = 1.0000 across all epochs). This\nindicates a bug in how the imdb validation data is being loaded or processed\n(e.g., an empty or mis-sliced validation set, incorrect split selection, or a\nmetric\u2010calculation issue). Proposed fix: add sanity checks to verify that X_val\nand y_val for imdb contain the expected number of samples, ensure the correct\ntest split is used (not overridden), and instrument the validation loop to print\nbatch shapes and intermediate loss values to pinpoint and correct the data or\nmetric computation error.", "The script raised ImportError: cannot import name 'AdamW' from 'transformers'.\nThis is due to recent changes in the Transformers library. To fix, import AdamW\nfrom the correct module, e.g., use `from torch.optim import AdamW` or `from\ntransformers.optimization import AdamW` instead of importing directly from\n`transformers`.", "", "", "", "", "", ""], "exc_type": [null, "ModuleNotFoundError", "ModuleNotFoundError", "ModuleNotFoundError", null, null, "ImportError", "KeyError", "KeyError", null, "ImportError", null, null, null, null, null, null], "exc_info": [null, {"args": ["No module named 'sklearn'"], "name": "sklearn", "msg": "No module named 'sklearn'"}, {"args": ["No module named 'sklearn'"], "name": "sklearn", "msg": "No module named 'sklearn'"}, {"args": ["No module named 'sklearn'"], "name": "sklearn", "msg": "No module named 'sklearn'"}, null, null, {"args": ["cannot import name 'AdamW' from 'transformers' (/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/transformers/__init__.py)"], "name": "transformers", "msg": "cannot import name 'AdamW' from 'transformers' (/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/transformers/__init__.py)"}, {"args": ["label"]}, {"args": ["text"]}, null, {"args": ["cannot import name 'AdamW' from 'transformers' (/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/transformers/__init__.py)"], "name": "transformers", "msg": "cannot import name 'AdamW' from 'transformers' (/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/transformers/__init__.py)"}, null, null, null, null, null, null], "exc_stack": [null, [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 8, "<module>", "from sklearn.feature_extraction.text import TfidfVectorizer"]], [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 12, "<module>", "from sklearn.feature_extraction.text import TfidfVectorizer"]], [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 12, "<module>", "from sklearn.feature_extraction.text import CountVectorizer"]], null, null, [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 9, "<module>", "from transformers import ("]], [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 65, "<module>", "num_labels = ds_train.features[\"label\"].num_classes"]], [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 26, "<module>", "train_ds = train_ds.map("], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 557, "wrapper", "out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)"], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 3079, "map", "for rank, done, content in Dataset._map_single(**dataset_kwargs):"], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 3525, "_map_single", "for i, batch in iter_outputs(shard_iterable):"], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 3475, "iter_outputs", "yield i, apply_function(example, i, offset=offset)"], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/arrow_dataset.py", 3398, "apply_function", "processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)"], ["runfile.py", 28, "<lambda>", "e[\"text\"], padding=\"max_length\", max_length=128, truncation=True"], ["/home/chenhui/miniconda3/envs/ai_scientist/lib/python3.11/site-packages/datasets/formatting/formatting.py", 278, "__getitem__", "value = self.data[key]"]], null, [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 10, "<module>", "from transformers import ("]], null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training alignment", "lower_is_better": false, "description": "Final alignment on the training set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.9929, "best_value": 0.9929}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.9921, "best_value": 0.9921}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.9917, "best_value": 0.9917}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.9988, "best_value": 0.9988}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Final alignment on the validation set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.9929, "best_value": 0.9929}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.9915, "best_value": 0.9915}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.9907, "best_value": 0.9907}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.9989, "best_value": 0.9989}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.9986, "best_value": 0.9986}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Final loss on the training set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 1.0162, "best_value": 1.0162}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.7943, "best_value": 0.7943}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.5274, "best_value": 0.5274}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.0982, "best_value": 0.0982}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.0588, "best_value": 0.0588}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final loss on the validation set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 1.0106, "best_value": 1.0106}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.7817, "best_value": 0.7817}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.5101, "best_value": 0.5101}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.1039, "best_value": 0.1039}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.0739, "best_value": 0.0739}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.6, "best_value": 0.6}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.835, "best_value": 0.835}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.905, "best_value": 0.905}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.96, "best_value": 0.96}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.965, "best_value": 0.965}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss", "data": [{"dataset_name": "ag_news", "final_value": 0.4711, "best_value": 0.4711}, {"dataset_name": "yelp_polarity", "final_value": 0.2558, "best_value": 0.2558}, {"dataset_name": "imdb", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss", "data": [{"dataset_name": "ag_news", "final_value": 0.6785, "best_value": 0.6785}, {"dataset_name": "yelp_polarity", "final_value": 0.3732, "best_value": 0.3732}, {"dataset_name": "imdb", "final_value": 0.0, "best_value": 0.0}]}, {"metric_name": "training alignment score", "lower_is_better": false, "description": "Final training alignment score", "data": [{"dataset_name": "ag_news", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "yelp_polarity", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation alignment score", "lower_is_better": false, "description": "Final validation alignment score", "data": [{"dataset_name": "ag_news", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "yelp_polarity", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "training MAI", "lower_is_better": false, "description": "Final training MAI", "data": [{"dataset_name": "ag_news", "final_value": 0.9191, "best_value": 0.9191}, {"dataset_name": "yelp_polarity", "final_value": 0.9537, "best_value": 0.9537}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation MAI", "lower_is_better": false, "description": "Final validation MAI", "data": [{"dataset_name": "ag_news", "final_value": 0.8863, "best_value": 0.8863}, {"dataset_name": "yelp_polarity", "final_value": 0.9361, "best_value": 0.9361}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}]}, {"metric_name": "validation accuracy", "lower_is_better": false, "description": "Final validation accuracy", "data": [{"dataset_name": "ag_news", "final_value": 0.78, "best_value": 0.78}, {"dataset_name": "yelp_polarity", "final_value": 0.844, "best_value": 0.844}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}]}]}, {"metric_names": [{"metric_name": "training MAI", "lower_is_better": false, "description": "Macro-Averaged Inference Accuracy on the training set", "data": [{"dataset_name": "ag_news", "final_value": 0.9838, "best_value": 0.9838}, {"dataset_name": "dbpedia_14", "final_value": 0.9971, "best_value": 0.9971}, {"dataset_name": "yelp_polarity", "final_value": 0.9837, "best_value": 0.9837}]}, {"metric_name": "validation MAI", "lower_is_better": false, "description": "Macro-Averaged Inference Accuracy on the validation set", "data": [{"dataset_name": "ag_news", "final_value": 0.8967, "best_value": 0.8967}, {"dataset_name": "dbpedia_14", "final_value": 0.9961, "best_value": 0.9961}, {"dataset_name": "yelp_polarity", "final_value": 0.9548, "best_value": 0.9548}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Training loss", "data": [{"dataset_name": "ag_news", "final_value": 0.0288, "best_value": 0.0288}, {"dataset_name": "imdb", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "yelp_review_full", "final_value": 0.0468, "best_value": 0.0468}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Validation loss", "data": [{"dataset_name": "ag_news", "final_value": 0.7197, "best_value": 0.7197}, {"dataset_name": "imdb", "final_value": 0.0, "best_value": 0.0}, {"dataset_name": "yelp_review_full", "final_value": 1.6229, "best_value": 1.6229}]}, {"metric_name": "train alignment", "lower_is_better": false, "description": "Training alignment", "data": [{"dataset_name": "ag_news", "final_value": 0.9996, "best_value": 0.9996}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "yelp_review_full", "final_value": 0.9986, "best_value": 0.9986}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Validation alignment", "data": [{"dataset_name": "ag_news", "final_value": 0.9945, "best_value": 0.9945}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "yelp_review_full", "final_value": 0.9765, "best_value": 0.9765}]}, {"metric_name": "train MAI", "lower_is_better": false, "description": "Training MAI", "data": [{"dataset_name": "ag_news", "final_value": 0.9951, "best_value": 0.9951}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "yelp_review_full", "final_value": 0.9909, "best_value": 0.9909}]}, {"metric_name": "validation MAI", "lower_is_better": false, "description": "Validation MAI", "data": [{"dataset_name": "ag_news", "final_value": 0.9011, "best_value": 0.9011}, {"dataset_name": "imdb", "final_value": 1.0, "best_value": 1.0}, {"dataset_name": "yelp_review_full", "final_value": 0.7694, "best_value": 0.7694}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training set", "data": [{"dataset_name": "ag_news", "final_value": 0.3672, "best_value": 0.3672}, {"dataset_name": "yelp_polarity", "final_value": 0.3435, "best_value": 0.3435}, {"dataset_name": "dbpedia_14", "final_value": 0.2103, "best_value": 0.2103}]}, {"metric_name": "training alignment", "lower_is_better": false, "description": "Alignment on the training set", "data": [{"dataset_name": "ag_news", "final_value": 0.9993, "best_value": 0.9993}, {"dataset_name": "yelp_polarity", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "dbpedia_14", "final_value": 0.9971, "best_value": 0.9971}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation set", "data": [{"dataset_name": "ag_news", "final_value": 0.3472, "best_value": 0.3472}, {"dataset_name": "yelp_polarity", "final_value": 0.3789, "best_value": 0.3789}, {"dataset_name": "dbpedia_14", "final_value": 0.1728, "best_value": 0.1728}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Alignment on the validation set", "data": [{"dataset_name": "ag_news", "final_value": 0.9995, "best_value": 0.9995}, {"dataset_name": "yelp_polarity", "final_value": 0.9999, "best_value": 0.9999}, {"dataset_name": "dbpedia_14", "final_value": 0.9978, "best_value": 0.9978}]}, {"metric_name": "MAI", "lower_is_better": false, "description": "Final MAI", "data": [{"dataset_name": "ag_news", "final_value": 0.9427, "best_value": 0.9427}, {"dataset_name": "yelp_polarity", "final_value": 0.9047, "best_value": 0.9047}, {"dataset_name": "dbpedia_14", "final_value": 0.9858, "best_value": 0.9858}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test set", "data": [{"dataset_name": "ag_news", "final_value": 0.892, "best_value": 0.892}, {"dataset_name": "yelp_polarity", "final_value": 0.824, "best_value": 0.824}, {"dataset_name": "dbpedia_14", "final_value": 0.972, "best_value": 0.972}]}]}, {"metric_names": [{"metric_name": "training MAI", "lower_is_better": false, "description": "Mean accuracy indicator on the training dataset", "data": [{"dataset_name": "ag_news", "final_value": 0.998, "best_value": 0.998}, {"dataset_name": "imdb", "final_value": 0.999, "best_value": 0.999}, {"dataset_name": "yelp_polarity", "final_value": 0.9981, "best_value": 0.9981}]}, {"metric_name": "validation MAI", "lower_is_better": false, "description": "Mean accuracy indicator on the validation dataset", "data": [{"dataset_name": "ag_news", "final_value": 0.9288, "best_value": 0.9288}, {"dataset_name": "imdb", "final_value": 0.9312, "best_value": 0.9312}, {"dataset_name": "yelp_polarity", "final_value": 0.9384, "best_value": 0.9384}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training dataset", "data": [{"dataset_name": "ag_news", "final_value": 0.0111, "best_value": 0.0111}, {"dataset_name": "imdb", "final_value": 0.0055, "best_value": 0.0055}, {"dataset_name": "yelp_polarity", "final_value": 0.0108, "best_value": 0.0108}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset", "data": [{"dataset_name": "ag_news", "final_value": 0.556, "best_value": 0.556}, {"dataset_name": "imdb", "final_value": 0.5738, "best_value": 0.5738}, {"dataset_name": "yelp_polarity", "final_value": 0.4506, "best_value": 0.4506}]}]}, {"metric_names": [{"metric_name": "training alignment", "lower_is_better": false, "description": "Alignment score on the training dataset", "data": [{"dataset_name": "synthetic (lr=1.0e-04)", "final_value": 0.9929, "best_value": 0.9929}, {"dataset_name": "synthetic (lr=5.0e-04)", "final_value": 0.9921, "best_value": 0.9921}, {"dataset_name": "synthetic (lr=1.0e-03)", "final_value": 0.9917, "best_value": 0.9917}, {"dataset_name": "synthetic (lr=5.0e-03)", "final_value": 0.9988, "best_value": 0.9988}, {"dataset_name": "synthetic (lr=1.0e-02)", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Alignment score on the validation dataset", "data": [{"dataset_name": "synthetic (lr=1.0e-04)", "final_value": 0.9929, "best_value": 0.9929}, {"dataset_name": "synthetic (lr=5.0e-04)", "final_value": 0.9915, "best_value": 0.9915}, {"dataset_name": "synthetic (lr=1.0e-03)", "final_value": 0.9907, "best_value": 0.9907}, {"dataset_name": "synthetic (lr=5.0e-03)", "final_value": 0.9989, "best_value": 0.9989}, {"dataset_name": "synthetic (lr=1.0e-02)", "final_value": 0.9986, "best_value": 0.9986}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Loss on the training dataset", "data": [{"dataset_name": "synthetic (lr=1.0e-04)", "final_value": 1.0162, "best_value": 1.0162}, {"dataset_name": "synthetic (lr=5.0e-04)", "final_value": 0.7943, "best_value": 0.7943}, {"dataset_name": "synthetic (lr=1.0e-03)", "final_value": 0.5274, "best_value": 0.5274}, {"dataset_name": "synthetic (lr=5.0e-03)", "final_value": 0.0982, "best_value": 0.0982}, {"dataset_name": "synthetic (lr=1.0e-02)", "final_value": 0.0588, "best_value": 0.0588}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Loss on the validation dataset", "data": [{"dataset_name": "synthetic (lr=1.0e-04)", "final_value": 1.0106, "best_value": 1.0106}, {"dataset_name": "synthetic (lr=5.0e-04)", "final_value": 0.7817, "best_value": 0.7817}, {"dataset_name": "synthetic (lr=1.0e-03)", "final_value": 0.5101, "best_value": 0.5101}, {"dataset_name": "synthetic (lr=5.0e-03)", "final_value": 0.1039, "best_value": 0.1039}, {"dataset_name": "synthetic (lr=1.0e-02)", "final_value": 0.0739, "best_value": 0.0739}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test dataset", "data": [{"dataset_name": "synthetic (lr=1.0e-04)", "final_value": 0.6, "best_value": 0.6}, {"dataset_name": "synthetic (lr=5.0e-04)", "final_value": 0.835, "best_value": 0.835}, {"dataset_name": "synthetic (lr=1.0e-03)", "final_value": 0.905, "best_value": 0.905}, {"dataset_name": "synthetic (lr=5.0e-03)", "final_value": 0.96, "best_value": 0.96}, {"dataset_name": "synthetic (lr=1.0e-02)", "final_value": 0.965, "best_value": 0.965}]}]}, {"metric_names": [{"metric_name": "training alignment", "lower_is_better": false, "description": "Final training alignment on the synthetic dataset", "data": [{"dataset_name": "Synthetic dataset", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Final validation alignment on the synthetic dataset", "data": [{"dataset_name": "Synthetic dataset", "final_value": 0.9989, "best_value": 0.9989}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss on the synthetic dataset", "data": [{"dataset_name": "Synthetic dataset", "final_value": 0.0588, "best_value": 0.0588}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss on the synthetic dataset", "data": [{"dataset_name": "Synthetic dataset", "final_value": 0.0739, "best_value": 0.0739}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Test accuracy on the synthetic dataset", "data": [{"dataset_name": "Synthetic dataset", "final_value": 0.965, "best_value": 0.965}]}]}, {"metric_names": [{"metric_name": "training alignment", "lower_is_better": false, "description": "Final alignment on the training set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.9929, "best_value": 0.9991}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.9921, "best_value": 0.9991}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.9917, "best_value": 0.9991}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.9988, "best_value": 0.9991}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.9991, "best_value": 0.9991}]}, {"metric_name": "validation alignment", "lower_is_better": false, "description": "Final alignment on the validation set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.9929, "best_value": 0.9989}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.9915, "best_value": 0.9989}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.9907, "best_value": 0.9989}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.9989, "best_value": 0.9989}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.9986, "best_value": 0.9989}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Final loss on the training set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 1.0162, "best_value": 0.0588}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.7943, "best_value": 0.0588}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.5274, "best_value": 0.0588}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.0982, "best_value": 0.0588}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.0588, "best_value": 0.0588}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final loss on the validation set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 1.0106, "best_value": 0.0739}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.7817, "best_value": 0.0739}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.5101, "best_value": 0.0739}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.1039, "best_value": 0.0739}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.0739, "best_value": 0.0739}]}, {"metric_name": "test accuracy", "lower_is_better": false, "description": "Accuracy on the test set", "data": [{"dataset_name": "learning rate 1.0e-04", "final_value": 0.6, "best_value": 0.965}, {"dataset_name": "learning rate 5.0e-04", "final_value": 0.835, "best_value": 0.965}, {"dataset_name": "learning rate 1.0e-03", "final_value": 0.905, "best_value": 0.965}, {"dataset_name": "learning rate 5.0e-03", "final_value": 0.96, "best_value": 0.965}, {"dataset_name": "learning rate 1.0e-02", "final_value": 0.965, "best_value": 0.965}]}]}, {"metric_names": [{"metric_name": "value", "lower_is_better": true, "description": "", "data": [{"dataset_name": "default", "final_value": null, "best_value": null}]}]}], "is_best_node": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_7d04e00cb67f4c5b995391df64eb1749_proc_4007053/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7d04e00cb67f4c5b995391df64eb1749_proc_4007053/synthetic_alignment_curves.png"], [], [], [], [], ["../../logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_mai_curves.png", "../../logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_loss_curves.png", "../../logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_accuracy.png"], [], [], [], [], [], ["../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_loss_alignment.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_loss_alignment.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_mai_curve.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_mai.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_loss_alignment.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_val_loss.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_mai_curve.png", "../../logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_mai_curve.png"], ["../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_alignment_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_loss_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_alignment_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_loss.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_alignment_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_alignment.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_loss.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_loss_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_loss_curves.png", "../../logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_alignment.png"], ["../../logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_alignment_curves.png"], ["../../logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_alignment_curves.png"], ["../../logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_loss_curves.png", "../../logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_alignment_curves.png"], ["../../logs/0-run/experiment_results/seed_aggregation_203b7d7007dc4c638e57b7b10fe21dd3/synthetic_loss_curves_aggregated.png", "../../logs/0-run/experiment_results/seed_aggregation_203b7d7007dc4c638e57b7b10fe21dd3/synthetic_alignment_curves_aggregated.png"]], "plot_paths": [["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_7d04e00cb67f4c5b995391df64eb1749_proc_4007053/synthetic_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_7d04e00cb67f4c5b995391df64eb1749_proc_4007053/synthetic_alignment_curves.png"], [], [], [], [], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_mai_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_accuracy.png"], [], [], [], [], [], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_loss_alignment.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_loss_alignment.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_mai_curve.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_mai.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_loss_alignment.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_val_loss.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_mai_curve.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_mai_curve.png"], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_alignment_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_alignment_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_loss.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_alignment_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_alignment.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_loss.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_alignment.png"], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_alignment_curves.png"], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_alignment_curves.png"], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_loss_curves.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_alignment_curves.png"], ["experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/seed_aggregation_203b7d7007dc4c638e57b7b10fe21dd3/synthetic_loss_curves_aggregated.png", "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/seed_aggregation_203b7d7007dc4c638e57b7b10fe21dd3/synthetic_alignment_curves_aggregated.png"]], "plot_analyses": [[], [], [], [], [], [{"analysis": "Training alignment (MAI) rises rapidly for all three datasets, converging near 1.0 by epoch five. dbpedia_14 starts with the lowest MAI (~0.65) but exhibits the steepest improvement, reaching ~0.99 by epoch four. ag_news and yelp_polarity both begin with higher initial MAI (~0.85 and ~0.92, respectively) and achieve similar convergence by epoch five. This suggests the model quickly adapts its internal representations across tasks, with harder datasets (dbpedia_14) benefiting most from additional epochs.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_mai_curves.png"}, {"analysis": "Validation MAI also increases consistently, with dbpedia_14 achieving almost perfect alignment (~0.995) by the final epoch. yelp_polarity shows a steady climb from ~0.93 to ~0.955, whereas ag_news plateaus at ~0.90 after epoch two and slightly declines by epoch five. The plateau on ag_news may indicate a ceiling in alignment under the current training regime and hints at diminishing returns after early convergence.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_loss_curves.png"}, {"analysis": "Training loss decreases sharply across epochs for all datasets, with dbpedia_14 dropping from ~2.3 to ~0.02, ag_news from ~1.05 to ~0.10, and yelp_polarity from ~0.50 to ~0.10. Validation loss trends reveal minimal overfitting on dbpedia_14 (steady decline to ~0.02), slight U-shaped behavior on yelp_polarity (lowest at epoch three, small rebound), and mild overfitting on ag_news (loss decreases slightly then climbs from ~0.72 to ~1.02). This aligns with the MAI patterns: stable generalization on dbpedia_14, some instability on ag_news, and moderately robust performance on yelp_polarity.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_2727c88241c24bd884643666c4e5f63c_proc_4061758/all_datasets_accuracy.png"}], [], [], [], [], [], [{"analysis": "dbpedia_14 training and validation losses plummet rapidly across epochs, from approximately 2.7/0.8 at epoch 1 down to 0.20/0.15 by epoch 3. Concurrently, alignment (1\u2212JSD) for both splits climbs from ~0.97/0.990 to ~0.997/0.998, indicating that the model distribution converges very closely to the target. Very low validation loss by epoch 3 with no sudden gap to training loss suggests minimal overfitting and robust generalization on dbpedia_14.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_loss_alignment.png"}, {"analysis": "ag_news exhibits a similar trend: training loss falls from ~2.1 to ~0.35, validation loss from ~0.49 to ~0.34 by the third epoch. Alignment (1\u2212JSD) begins near 0.968/0.997 and reaches ~0.999/0.9997. Rapid gains in alignment after epoch 1 imply that the model quickly captures class distributions in ag_news, while the relatively small train\u2013val loss gap indicates stable convergence.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_loss_alignment.png"}, {"analysis": "yelp_polarity MAI starts at ~0.906, peaks at ~0.909 on epoch 2, then dips to ~0.905 by epoch 3. The early rise followed by a slight decline suggests that while representation alignment improves initially, prolonged training may induce minor overfitting or saturation effects specific to this sentiment dataset, resulting in a small erosion of alignment quality.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_mai_curve.png"}, {"analysis": "Comparison of MAI across ag_news (~0.93\u21920.94\u21920.943), yelp_polarity (~0.906\u21920.909\u21920.904), and dbpedia_14 (~0.951\u21920.979\u21920.985) confirms that dbpedia_14 achieves the highest alignment gains and overall MAI. ag_news shows steady but moderate improvement. Yelp_polarity lags behind and even slightly backtracks after epoch 2, highlighting dataset-specific difficulty in maintaining alignment.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_mai.png"}, {"analysis": "yelp_polarity loss and alignment (1\u2212JSD) demonstrate training loss dropping sharply from ~1.80 to ~0.32, validation loss from ~0.47 to ~0.37. Alignment for training grows from ~0.956 to ~0.9994, and validation from ~0.997 to ~1.000. This near-perfect distribution match juxtaposed against the MAI dip suggests that while the model aligns to the probability distributions, this may not fully translate into improved instance-level alignment metrics for yelp_polarity.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/yelp_polarity_loss_alignment.png"}, {"analysis": "Cross-dataset validation loss comparison shows dbpedia_14 moving from ~0.80 to ~0.17 in three epochs, the steepest drop among the three. ag_news declines from ~0.49 to ~0.35, and yelp_polarity from ~0.47 to ~0.38 before plateauing. The sharper improvement on dbpedia_14 indicates either greater model capacity exploitation or a simpler classification boundary relative to the other two datasets.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/comparison_val_loss.png"}, {"analysis": "dbpedia_14 MAI steadily increases from ~0.951 to ~0.986 over epochs. This monotonic climb corroborates the loss and distribution alignment curves, underscoring strong mutual adaptation between model predictions and user-inferred behavior on this dataset.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/dbpedia_14_mai_curve.png"}, {"analysis": "ag_news MAI follows a smooth upward trajectory from ~0.930 to ~0.943 across the three epochs. This consistent rise, in concert with improving loss and 1\u2212JSD alignment, suggests that co-adaptive alignment mechanisms successfully enhance mutual understanding for the news classification task.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1ea021d8baba44a581d1cabe6f3b901e_proc_4061757/ag_news_mai_curve.png"}], [{"analysis": "imdb Dataset Alignment Curves show training alignment rising steeply from around 0.904 at epoch 1 to 0.980 at epoch 2 and plateauing near 0.998 by epoch 5. Validation alignment follows a similar trend, climbing from roughly 0.912 to a peak of 0.932 at epoch 3, then holding steady with only a minor dip at epoch 4 before recovering at epoch 5. This indicates strong model alignment with minimal overfitting across epochs.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_alignment_curves.png"}, {"analysis": "ag_news Dataset Loss Curves reveal rapid reduction in training loss from about 1.12 to 0.24 by epoch 2, dropping further to near zero by epoch 5. Validation loss decreases from 0.78 to 0.575 at epoch 2 and bottoms at 0.55 by epoch 3. Slight increases at epochs 4 and 5 (to 0.553, 0.556) suggest that epoch 3 is optimal before minor overfitting sets in.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_loss_curves.png"}, {"analysis": "yelp_polarity Dataset Alignment Curves indicate training alignment improving from around 0.903 at epoch 1 to 0.974 at epoch 2 and nearly 0.998 by epoch 5. Validation alignment climbs from 0.918 to 0.939 at epoch 2, peaks at 0.942 by epoch 3, then gradually declines to 0.937 by epoch 5. This pattern points to very high alignment with slight over-adaptation after epoch 3.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_alignment_curves.png"}, {"analysis": "Comparison of Validation Loss Across Datasets shows that ag_news starts highest (~0.78), reaches its lowest (0.55) at epoch 3, then rises slightly. imdb begins at ~0.554, dips to 0.517 by epoch 2, then increases up to 0.573 by epoch 5. yelp starts lowest (~0.475), bottoms at 0.36 in epoch 2, then climbs to 0.45. All three display a U-shaped curve, with the earliest overfitting on imdb and yelp, and slower convergence on ag_news.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_loss.png"}, {"analysis": "ag_news Dataset Alignment Curves demonstrate training alignment moving from roughly 0.813 at epoch 1 to 0.958 at epoch 2 and nearly 0.999 by epoch 5. Validation alignment rises from 0.872 to 0.915 at epoch 2, then to 0.923 at epoch 3, with marginal gains to 0.929 by epoch 5. Improvement is consistent but at a slower pace compared with other datasets.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/ag_news_alignment_curves.png"}, {"analysis": "Comparison of Validation Alignment Across Datasets reveals that yelp_polarity achieves the highest alignment early (0.918\u21920.942), imdb sits in the middle (0.912\u21920.932), and ag_news trails (0.870\u21920.923) by epoch 3. Beyond epoch 3 all three curves flatten, indicating convergence in alignment performance with yelp maintaining a slight lead.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_validation_alignment.png"}, {"analysis": "Comparison of Training Loss Across Datasets shows ag_news with the highest initial loss (1.12) dropping to 0.06 by epoch 3, whereas imdb and yelp start around 0.56 and fall to approximately 0.12 at epoch 2 and 0.04 by epoch 3. All three approach near-zero training loss by epoch 5. ag_news exhibits slower initial learning dynamics and higher complexity.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_loss.png"}, {"analysis": "imdb Dataset Loss Curves depict training loss declining from 0.55 at epoch 1 to 0.12 at epoch 2 and about 0.005 by epoch 5. Validation loss decreases to 0.515 at epoch 2, then rises steadily to 0.573 by epoch 5, indicating the onset of overfitting shortly after epoch 2.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/imdb_loss_curves.png"}, {"analysis": "yelp_polarity Dataset Loss Curves show a steep drop in training loss from 0.56 to 0.14 by epoch 2 and near zero by epoch 5. Validation loss bottoms at 0.36 in epoch 2, then increases to 0.45 by epoch 5. Optimal generalization appears around epochs 2\u20133 before overfitting emerges.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/yelp_polarity_loss_curves.png"}, {"analysis": "Comparison of Training Alignment Across Datasets illustrates that at epoch 1 ag_news starts lower (~0.813) compared to imdb and yelp (~0.905). By epoch 2 both imdb and yelp exceed 0.98 while ag_news reaches 0.958. All three cross 0.99 by epoch 3 and converge near 0.999 by epoch 5, showing uniformly strong alignment at later epochs.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_25b2224510324609a2bc0d267623d216_proc_4061758/comparison_training_alignment.png"}], [{"analysis": "Loss curves on synthetic data indicate a clear learning\u2010rate dependence. With lr=0.0001, training loss barely decreases over ten epochs, signalling an overly conservative update. At lr=0.0005, both training and validation loss drop steadily but slowly, suggesting safe but sluggish convergence. Increasing to lr=0.001 accelerates reduction, yet remains outpaced by higher rates. lr=0.005 yields a sharp loss decline in the first five epochs before flattening near 0.1 on training and validation, striking a good balance between speed and stability. The highest rate, lr=0.01, drives an extremely rapid fall to below 0.05 by epoch 4 and maintains this low level without signs of divergence; validation follows suit, implying minimal overfitting. Overall, learning rates in the 0.005\u20130.01 range achieve the fastest convergence and lowest final losses, while rates \u22640.001 underfit and converge too slowly.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_loss_curves.png"}, {"analysis": "Alignment curves (1 \u2013 JSD) reveal how well the model\u2019s distribution matches target behavior over time. At lr=0.0001, alignment inches upward from ~0.992 to ~0.993 on both training and validation, indicating reliable but glacial improvement. lr=0.0005 produces a slight early bump around epoch 3, then drifts slightly downward, suggesting marginal gains followed by plateau. lr=0.001 peaks near epoch 2 then slowly declines to ~0.991, pointing to over\u2010adaptation and slight misalignment later. Both lr=0.005 and lr=0.01 lead to rapid alignment gains: lr=0.005 climbs steadily to ~0.999 by epoch 10 on train and val, offering the most stable ascent. lr=0.01 shows an initial dip on validation but recovers quickly, plateauing at ~0.9985\u20130.999; minor post\u2010peak jitter hints at occasional overshoot. In sum, lr\u22480.005 maximizes alignment growth consistently, while lr=0.01 is faster but introduces slight instability near the top.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/synthetic_alignment_curves.png"}], [{"analysis": "Plots show training and validation loss across epochs for different learning rates. Lower learning rates (1e-4, 5e-4) exhibit slow, shallow decreases in loss, plateauing at relatively high values by epoch 10. Moderate rates (1e-3) achieve faster descent but still retain substantial loss. Higher rates (5e-3, 1e-2) drive rapid convergence, with lr=0.01 reaching near-zero training loss by epoch 10. Validation curves mirror this behavior: lr=0.01 and lr=0.005 yield the steepest drop, achieving the lowest validation loss and minimal generalization gap. The slowest rates maintain high validation loss, indicating underfitting, while the highest rates balance fast convergence with stable validation performance, suggesting they best optimize both training and generalization under this setup.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_loss_curves.png"}, {"analysis": "Curves depict alignment (1\u2013JS divergence) on training and validation sets over epochs. Very small rates (1e-4, 5e-4) yield modest, gradual improvements in alignment, peaking around 0.992\u20130.993. A mid rate (1e-3) briefly improves but then declines slightly, indicating suboptimal stability. Higher rates (5e-3, 1e-2) display an initial dip in alignment followed by a rapid rise: lr=0.01 reaches alignment \u22480.999 by epoch 8, lr=0.005 approaches 0.9989 by epoch 10. Validation alignment trends match training: the highest rates achieve the greatest alignment quickly, whereas lower rates converge slowly and to lower maxima. This underscores that larger learning rates not only speed up training but also drive stronger co-adaptation as measured by alignment.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/synthetic_alignment_curves.png"}], [{"analysis": "Training and validation losses both decrease monotonically across all learning rates, with larger rates yielding much faster convergence. The highest rate (0.01) drives loss down to near zero by epoch 10, followed by 0.005. Moderate rates (0.001, 0.0005) plateau at higher loss values (~0.5 and ~0.8 respectively), while the smallest rate (0.0001) shows the slowest decline, barely reaching ~1.0 after 10 epochs. No signs of divergence or severe overfitting appear, suggesting that even aggressive rates remain stable on this synthetic dataset within the training window.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_loss_curves.png"}, {"analysis": "Alignment improves for all rates, but the magnitude and speed of gain strongly correlate with the learning rate. Rates of 0.005 and especially 0.01 boost alignment from ~0.992 to nearly 0.999 by epoch 10 on both training and validation curves. Lower rates achieve only marginal or transient improvements, with 0.001 and 0.0005 eventually drifting downward and 0.0001 rising slowly to ~0.993. Validation alignment closely tracks training, indicating generalizable adaptation without substantial overfitting. The steep early gains for high rates suggest rapid mutual model alignment, while low rates may be too conservative to correct initial discrepancies effectively.", "plot_path": "experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/synthetic_alignment_curves.png"}], []], "vlm_feedback_summary": ["[]", "[]", "[]", "[]", "[]", "Across datasets, the model achieves strong alignment and low loss, especially on\ndbpedia_14 where both MAI and accuracy near 100%. ag_news shows early MAI\nplateauing and slight overfitting in loss, correlating with its lower final\naccuracy. yelp_polarity maintains balanced improvement and stability. These\nfindings highlight dataset-specific dynamics in convergence speed,\ngeneralization, and ceiling effects under current static alignment training.", "[]", "[]", "[]", "[]", "[]", "All three HuggingFace datasets (dbpedia_14, ag_news, yelp_polarity) show rapid\nconvergence in loss and distribution alignment (1\u2212JSD) by epoch 3, with\ndbpedia_14 leading in both alignment gains and loss reduction. MAI trends are\npositive for dbpedia_14 and ag_news, while yelp_polarity exhibits a slight MAI\ndecrease after epoch 2 despite near-perfect 1\u2212JSD, suggesting dataset-specific\nchallenges in translating distributional alignment to instance-level alignment.", "Across three Hugging Face benchmarks, models achieve near-perfect training\nalignment and negligible training loss by epoch 5. Validation metrics peak\naround epoch 2\u20133 then show mild overfitting, especially on imdb and\nyelp_polarity. ag_news converges more slowly and exhibits higher initial\ncomplexity. Overall alignment improves steadily, with yelp_polarity leading,\nfollowed by imdb, then ag_news. Optimal trade-offs occur around epoch 3 for loss\nand alignment before minor drift sets in.", "Higher learning rates (0.005\u20130.01) markedly speed both loss minimization and\nalignment improvement, with lr=0.005 delivering the most stable high\u2010quality\nresults. Lower rates underfit or converge too slowly, and extremely high rates,\nwhile quick, can introduce modest fluctuations in alignment, underscoring the\nimportance of tuning this hyperparameter for efficient co\u2010adaptive model\nbehavior.", "High learning rates (5e-3, 1e-2) clearly outperform lower ones by enabling rapid\nloss reduction and superior alignment on both training and validation data.\nSmall rates underfit and mid rates (1e-3) show unstable alignment. Balanced\nperformance emerges at the highest rates, suggesting they are optimal for both\nconvergence speed and bidirectional mental\u2010model alignment.", "High learning rates (\u22650.005) clearly accelerate both loss minimization and model\nalignment, with lr=0.01 offering the fastest and strongest results. Lower rates\nlead to sluggish or unstable improvements. To ensure robustness and\ngeneralizability of CAMMA, the next step is to evaluate on three diverse\nHuggingFace text\u2010classification datasets (e.g., AG News, Yelp Reviews, SST\u20102),\ncomparing bidirectional adaptation against static and unidirectional baselines\nacross real\u2010world data.", "[]"], "exec_time": [3.7596991062164307, 0.43485116958618164, 0.4355144500732422, 0.43395280838012695, 34.76485538482666, 36.9653742313385, 0.8243956565856934, 10.384702205657959, 84.3590886592865, 45.89266300201416, 1.79549241065979, 53.0629301071167, 34.656118869781494, 3.7395594120025635, 3.8028128147125244, 4.069434404373169, null], "exec_time_feedback": ["", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [[], [], [], [], [], ["['dbpedia_14']"], [], [], [], [], [], ["[dbpedia_14", "ag_news]"], ["[imdb", "ag_news", "yelp_polarity]"], ["[\"synthetic\"]"], ["['synthetic']"], ["[\"synthetic\"]"], []], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\nsd = data.get(\"learning_rate\", {}).get(\"synthetic\", {})\n\n# Plot 1: Loss curves\ntry:\n    lrs = sd.get(\"lrs\", [])\n    train_losses = sd.get(\"losses\", {}).get(\"train\", [])\n    val_losses = sd.get(\"losses\", {}).get(\"val\", [])\n    epochs = range(1, len(train_losses[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, tr in zip(lrs, train_losses):\n        axes[0].plot(epochs, tr, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    for lr, vl in zip(lrs, val_losses):\n        axes[1].plot(epochs, vl, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\n# Plot 2: Alignment curves\ntry:\n    train_align = sd.get(\"metrics\", {}).get(\"train\", [])\n    val_align = sd.get(\"metrics\", {}).get(\"val\", [])\n    epochs = range(1, len(train_align[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, ta in zip(lrs, train_align):\n        axes[0].plot(epochs, ta, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Alignment\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Alignment (1-JSD)\")\n    axes[0].legend()\n    for lr, va in zip(lrs, val_align):\n        axes[1].plot(epochs, va, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Alignment\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Alignment (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_alignment_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n", null, null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\ndatasets = list(data.keys())\n\n# Plot 1: Loss curves comparison\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for ds in datasets:\n        tr, vl = data[ds][\"losses\"][\"train\"], data[ds][\"losses\"][\"val\"]\n        epochs = range(1, len(tr) + 1)\n        axes[0].plot(epochs, tr, label=ds)\n        axes[1].plot(epochs, vl, label=ds)\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"All Datasets - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"all_datasets_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss comparison plot: {e}\")\n    plt.close()\n\n# Plot 2: MAI curves comparison\ntry:\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for ds in datasets:\n        tr, vl = data[ds][\"metrics\"][\"train\"], data[ds][\"metrics\"][\"val\"]\n        epochs = range(1, len(tr) + 1)\n        axes[0].plot(epochs, tr, label=ds)\n        axes[1].plot(epochs, vl, label=ds)\n    axes[0].set_title(\"Training MAI\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"MAI (1-JSD)\")\n    axes[0].legend()\n    axes[1].set_title(\"Validation MAI\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"MAI (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\"All Datasets - MAI Curves\\nLeft: Training MAI, Right: Validation MAI\")\n    plt.savefig(os.path.join(working_dir, \"all_datasets_mai_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating MAI comparison plot: {e}\")\n    plt.close()\n\n# Plot 3: Accuracy bar chart\ntry:\n    accuracies = []\n    for ds in datasets:\n        preds = data[ds][\"predictions\"]\n        gts = data[ds][\"ground_truth\"]\n        accuracies.append(np.mean(preds == gts))\n    fig = plt.figure(figsize=(6, 4))\n    plt.bar(datasets, accuracies)\n    plt.ylim(0, 1)\n    plt.title(\"All Datasets - Validation Accuracy\\nBar Chart per Dataset\")\n    plt.xlabel(\"Dataset\")\n    plt.ylabel(\"Accuracy\")\n    for i, v in enumerate(accuracies):\n        plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n    plt.savefig(os.path.join(working_dir, \"all_datasets_accuracy.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating accuracy plot: {e}\")\n    plt.close()\n\n# Print final evaluation metrics\nfor ds in datasets:\n    final_loss = data[ds][\"losses\"][\"val\"][-1]\n    final_mai = data[ds][\"metrics\"][\"val\"][-1]\n    preds = data[ds][\"predictions\"]\n    gts = data[ds][\"ground_truth\"]\n    acc = np.mean(preds == gts)\n    print(\n        f\"{ds}: Final Val Loss={final_loss:.4f}, Final Val MAI={final_mai:.4f}, Accuracy={acc:.4f}\"\n    )\n", null, null, null, null, null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\n# Dataset-specific loss and alignment plots\nfor name, d in data.items():\n    try:\n        epochs = range(1, len(d[\"losses\"][\"train\"]) + 1)\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        axes[0].plot(epochs, d[\"losses\"][\"train\"], label=\"train\")\n        axes[0].plot(epochs, d[\"losses\"][\"val\"], label=\"val\")\n        axes[0].set_xlabel(\"Epoch\")\n        axes[0].set_ylabel(\"Loss\")\n        axes[0].set_title(\"Loss\")\n        axes[0].legend()\n        axes[1].plot(epochs, d[\"alignments\"][\"train\"], label=\"train\")\n        axes[1].plot(epochs, d[\"alignments\"][\"val\"], label=\"val\")\n        axes[1].set_xlabel(\"Epoch\")\n        axes[1].set_ylabel(\"Alignment (1-JSD)\")\n        axes[1].set_title(\"Alignment\")\n        axes[1].legend()\n        fig.suptitle(f\"{name} Metrics\\nLeft: Loss, Right: Alignment (1-JSD)\")\n        plt.savefig(os.path.join(working_dir, f\"{name}_loss_alignment.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {name} loss_alignment plot: {e}\")\n        plt.close()\n\n# Dataset-specific MAI curves\nfor name, d in data.items():\n    try:\n        epochs = range(1, len(d[\"mai\"]) + 1)\n        plt.figure()\n        plt.plot(epochs, d[\"mai\"], marker=\"o\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MAI\")\n        plt.title(f\"{name} MAI over Epochs\")\n        plt.savefig(os.path.join(working_dir, f\"{name}_mai_curve.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating {name} MAI plot: {e}\")\n        plt.close()\n\n# Comparison of validation loss across datasets\ntry:\n    plt.figure()\n    for name, d in data.items():\n        plt.plot(\n            range(1, len(d[\"losses\"][\"val\"]) + 1),\n            d[\"losses\"][\"val\"],\n            marker=\"o\",\n            label=name,\n        )\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Loss\")\n    plt.title(\"Comparison of Validation Loss Across Datasets\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"comparison_val_loss.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating comparison validation loss plot: {e}\")\n    plt.close()\n\n# Comparison of MAI across datasets\ntry:\n    plt.figure()\n    for name, d in data.items():\n        plt.plot(range(1, len(d[\"mai\"]) + 1), d[\"mai\"], marker=\"o\", label=name)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"MAI\")\n    plt.title(\"Comparison of MAI Across Datasets\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"comparison_mai.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating comparison MAI plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\ntry:\n    data = np.load(data_path, allow_pickle=True).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\n# Per-dataset plots\nfor ds_name, ds_data in data.items():\n    train_losses = ds_data.get(\"losses\", {}).get(\"train\", [])\n    val_losses = ds_data.get(\"losses\", {}).get(\"val\", [])\n    train_align = ds_data.get(\"metrics\", {}).get(\"train\", [])\n    val_align = ds_data.get(\"metrics\", {}).get(\"val\", [])\n    epochs = range(1, len(train_losses) + 1)\n\n    try:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        axes[0].plot(epochs, train_losses, marker=\"o\")\n        axes[0].set_title(\"Training Loss\")\n        axes[0].set_xlabel(\"Epoch\")\n        axes[0].set_ylabel(\"Loss\")\n        axes[1].plot(epochs, val_losses, marker=\"o\")\n        axes[1].set_title(\"Validation Loss\")\n        axes[1].set_xlabel(\"Epoch\")\n        axes[1].set_ylabel(\"Loss\")\n        fig.suptitle(\n            f\"{ds_name} Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n        )\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {ds_name}: {e}\")\n        plt.close()\n\n    try:\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        axes[0].plot(epochs, train_align, marker=\"o\")\n        axes[0].set_title(\"Training Alignment\")\n        axes[0].set_xlabel(\"Epoch\")\n        axes[0].set_ylabel(\"Alignment (1\u2212JSD)\")\n        axes[1].plot(epochs, val_align, marker=\"o\")\n        axes[1].set_title(\"Validation Alignment\")\n        axes[1].set_xlabel(\"Epoch\")\n        axes[1].set_ylabel(\"Alignment (1\u2212JSD)\")\n        fig.suptitle(\n            f\"{ds_name} Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n        )\n        plt.savefig(os.path.join(working_dir, f\"{ds_name}_alignment_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating alignment plot for {ds_name}: {e}\")\n        plt.close()\n\n# Comparison plots across datasets\nds_list = list(data.keys())\nif ds_list:\n    num_epochs = len(data[ds_list[0]][\"losses\"][\"train\"])\n    cmp_epochs = range(1, num_epochs + 1)\n\n    try:\n        plt.figure()\n        for ds in ds_list:\n            plt.plot(cmp_epochs, data[ds][\"losses\"][\"train\"], marker=\"o\", label=ds)\n        plt.title(\"Comparison of Training Loss Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_training_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison training loss plot: {e}\")\n        plt.close()\n\n    try:\n        plt.figure()\n        for ds in ds_list:\n            plt.plot(cmp_epochs, data[ds][\"losses\"][\"val\"], marker=\"o\", label=ds)\n        plt.title(\"Comparison of Validation Loss Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_validation_loss.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison validation loss plot: {e}\")\n        plt.close()\n\n    try:\n        plt.figure()\n        for ds in ds_list:\n            plt.plot(cmp_epochs, data[ds][\"metrics\"][\"train\"], marker=\"o\", label=ds)\n        plt.title(\"Comparison of Training Alignment Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Alignment (1\u2212JSD)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_training_alignment.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison training alignment plot: {e}\")\n        plt.close()\n\n    try:\n        plt.figure()\n        for ds in ds_list:\n            plt.plot(cmp_epochs, data[ds][\"metrics\"][\"val\"], marker=\"o\", label=ds)\n        plt.title(\"Comparison of Validation Alignment Across Datasets\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Alignment (1\u2212JSD)\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, \"comparison_validation_alignment.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating comparison validation alignment plot: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\nsd = data.get(\"learning_rate\", {}).get(\"synthetic\", {})\n\n# Plot 1: Loss curves\ntry:\n    lrs = sd.get(\"lrs\", [])\n    train_losses = sd.get(\"losses\", {}).get(\"train\", [])\n    val_losses = sd.get(\"losses\", {}).get(\"val\", [])\n    epochs = range(1, len(train_losses[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, tr in zip(lrs, train_losses):\n        axes[0].plot(epochs, tr, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    for lr, vl in zip(lrs, val_losses):\n        axes[1].plot(epochs, vl, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\n# Plot 2: Alignment curves\ntry:\n    train_align = sd.get(\"metrics\", {}).get(\"train\", [])\n    val_align = sd.get(\"metrics\", {}).get(\"val\", [])\n    epochs = range(1, len(train_align[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, ta in zip(lrs, train_align):\n        axes[0].plot(epochs, ta, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Alignment\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Alignment (1-JSD)\")\n    axes[0].legend()\n    for lr, va in zip(lrs, val_align):\n        axes[1].plot(epochs, va, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Alignment\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Alignment (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_alignment_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\nsd = data.get(\"learning_rate\", {}).get(\"synthetic\", {})\n\n# Plot 1: Loss curves\ntry:\n    lrs = sd.get(\"lrs\", [])\n    train_losses = sd.get(\"losses\", {}).get(\"train\", [])\n    val_losses = sd.get(\"losses\", {}).get(\"val\", [])\n    epochs = range(1, len(train_losses[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, tr in zip(lrs, train_losses):\n        axes[0].plot(epochs, tr, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    for lr, vl in zip(lrs, val_losses):\n        axes[1].plot(epochs, vl, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\n# Plot 2: Alignment curves\ntry:\n    train_align = sd.get(\"metrics\", {}).get(\"train\", [])\n    val_align = sd.get(\"metrics\", {}).get(\"val\", [])\n    epochs = range(1, len(train_align[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, ta in zip(lrs, train_align):\n        axes[0].plot(epochs, ta, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Alignment\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Alignment (1-JSD)\")\n    axes[0].legend()\n    for lr, va in zip(lrs, val_align):\n        axes[1].plot(epochs, va, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Alignment\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Alignment (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_alignment_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\n# Load experiment data\ntry:\n    data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n    data = {}\n\nsd = data.get(\"learning_rate\", {}).get(\"synthetic\", {})\n\n# Plot 1: Loss curves\ntry:\n    lrs = sd.get(\"lrs\", [])\n    train_losses = sd.get(\"losses\", {}).get(\"train\", [])\n    val_losses = sd.get(\"losses\", {}).get(\"val\", [])\n    epochs = range(1, len(train_losses[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, tr in zip(lrs, train_losses):\n        axes[0].plot(epochs, tr, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    for lr, vl in zip(lrs, val_losses):\n        axes[1].plot(epochs, vl, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot1: {e}\")\n    plt.close()\n\n# Plot 2: Alignment curves\ntry:\n    train_align = sd.get(\"metrics\", {}).get(\"train\", [])\n    val_align = sd.get(\"metrics\", {}).get(\"val\", [])\n    epochs = range(1, len(train_align[0]) + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, ta in zip(lrs, train_align):\n        axes[0].plot(epochs, ta, label=f\"lr={lr}\")\n    axes[0].set_title(\"Training Alignment\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Alignment (1-JSD)\")\n    axes[0].legend()\n    for lr, va in zip(lrs, val_align):\n        axes[1].plot(epochs, va, label=f\"lr={lr}\")\n    axes[1].set_title(\"Validation Alignment\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Alignment (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_alignment_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating plot2: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\nexp_paths = [\n    \"experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_d3388ee27ada46aca832d65717ab8d9d_proc_4061759/experiment_data.npy\",\n    \"experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_afaf04f731bd4975b5f1805f8133bb3f_proc_4061757/experiment_data.npy\",\n    \"experiments/2025-05-21_18-26-09_bidirectional_mental_model_alignment_attempt_0/logs/0-run/experiment_results/experiment_1bfb9a916ea04d0d8f4f43020b6e9adb_proc_4061758/experiment_data.npy\",\n]\n\nall_experiment_data = []\ntry:\n    for p in exp_paths:\n        data = np.load(\n            os.path.join(os.getenv(\"AI_SCIENTIST_ROOT\", os.getcwd()), p),\n            allow_pickle=True,\n        ).item()\n        all_experiment_data.append(data)\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nlr_data = {}\nfor data in all_experiment_data:\n    sd = data.get(\"learning_rate\", {}).get(\"synthetic\", {})\n    lrs = sd.get(\"lrs\", [])\n    tr_losses = sd.get(\"losses\", {}).get(\"train\", [])\n    vl_losses = sd.get(\"losses\", {}).get(\"val\", [])\n    tr_aligns = sd.get(\"metrics\", {}).get(\"train\", [])\n    vl_aligns = sd.get(\"metrics\", {}).get(\"val\", [])\n    for lr, tr, vl, ta, va in zip(lrs, tr_losses, vl_losses, tr_aligns, vl_aligns):\n        lr = float(lr)\n        lr_data.setdefault(\n            lr,\n            {\"train_losses\": [], \"val_losses\": [], \"train_align\": [], \"val_align\": []},\n        )\n        lr_data[lr][\"train_losses\"].append(np.array(tr))\n        lr_data[lr][\"val_losses\"].append(np.array(vl))\n        lr_data[lr][\"train_align\"].append(np.array(ta))\n        lr_data[lr][\"val_align\"].append(np.array(va))\n\nfirst_lr = next(iter(lr_data)) if lr_data else None\n\n# Plot 1: Aggregated Loss Curves\ntry:\n    if first_lr is None:\n        raise ValueError(\"No data available for aggregation\")\n    n_epochs = lr_data[first_lr][\"train_losses\"][0].shape[0]\n    epochs = np.arange(1, n_epochs + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, stats in lr_data.items():\n        arr_tr = np.stack(stats[\"train_losses\"], axis=0)\n        mean_tr = arr_tr.mean(axis=0)\n        sem_tr = arr_tr.std(axis=0, ddof=1) / np.sqrt(arr_tr.shape[0])\n        axes[0].plot(epochs, mean_tr, label=f\"lr={lr} Mean\")\n        axes[0].fill_between(\n            epochs, mean_tr - sem_tr, mean_tr + sem_tr, alpha=0.3, label=f\"lr={lr} SEM\"\n        )\n        arr_vl = np.stack(stats[\"val_losses\"], axis=0)\n        mean_vl = arr_vl.mean(axis=0)\n        sem_vl = arr_vl.std(axis=0, ddof=1) / np.sqrt(arr_vl.shape[0])\n        axes[1].plot(epochs, mean_vl, label=f\"lr={lr} Mean\")\n        axes[1].fill_between(\n            epochs, mean_vl - sem_vl, mean_vl + sem_vl, alpha=0.3, label=f\"lr={lr} SEM\"\n        )\n    axes[0].set_title(\"Training Loss\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Loss\")\n    axes[0].legend()\n    axes[1].set_title(\"Validation Loss\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Loss\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Loss Curves\\nLeft: Training Loss, Right: Validation Loss\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_loss_curves_aggregated.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated loss plot: {e}\")\n    plt.close()\n\n# Plot 2: Aggregated Alignment Curves\ntry:\n    if first_lr is None:\n        raise ValueError(\"No data available for aggregation\")\n    n_epochs = lr_data[first_lr][\"train_align\"][0].shape[0]\n    epochs = np.arange(1, n_epochs + 1)\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    for lr, stats in lr_data.items():\n        arr_tr = np.stack(stats[\"train_align\"], axis=0)\n        mean_tr = arr_tr.mean(axis=0)\n        sem_tr = arr_tr.std(axis=0, ddof=1) / np.sqrt(arr_tr.shape[0])\n        axes[0].plot(epochs, mean_tr, label=f\"lr={lr} Mean\")\n        axes[0].fill_between(\n            epochs, mean_tr - sem_tr, mean_tr + sem_tr, alpha=0.3, label=f\"lr={lr} SEM\"\n        )\n        arr_vl = np.stack(stats[\"val_align\"], axis=0)\n        mean_vl = arr_vl.mean(axis=0)\n        sem_vl = arr_vl.std(axis=0, ddof=1) / np.sqrt(arr_vl.shape[0])\n        axes[1].plot(epochs, mean_vl, label=f\"lr={lr} Mean\")\n        axes[1].fill_between(\n            epochs, mean_vl - sem_vl, mean_vl + sem_vl, alpha=0.3, label=f\"lr={lr} SEM\"\n        )\n    axes[0].set_title(\"Training Alignment\")\n    axes[0].set_xlabel(\"Epoch\")\n    axes[0].set_ylabel(\"Alignment (1-JSD)\")\n    axes[0].legend()\n    axes[1].set_title(\"Validation Alignment\")\n    axes[1].set_xlabel(\"Epoch\")\n    axes[1].set_ylabel(\"Alignment (1-JSD)\")\n    axes[1].legend()\n    fig.suptitle(\n        \"Synthetic Dataset - Alignment Curves\\nLeft: Training Alignment, Right: Validation Alignment\"\n    )\n    plt.savefig(os.path.join(working_dir, \"synthetic_alignment_curves_aggregated.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating aggregated alignment plot: {e}\")\n    plt.close()\n"], "plot_plan": ["First, load the experiment data and extract the synthetic results under the learning rate sweep. Then use two separate try-except blocks to create and save figures: one for the training/validation loss curves and another for the training/validation alignment curves. Each figure will have two subplots\u2014left for training metrics and right for validation\u2014with clear titles, axis labels, legends for each learning rate, and a suptitle specifying \u201cSynthetic Dataset\u201d and the left/right designations. We iterate over the stored learning rates to plot each curve, save the figures to `working_dir` with descriptive filenames, and close them. If any error occurs in plotting or data loading, we print an error message and ensure the figure is closed.", null, null, null, null, "We will load the saved experiment_data dictionary from the working directory and list all dataset keys. Then we will generate three separate figures, each wrapped in its own try-except: (1) a loss curves comparison across all datasets with training losses on the left and validation losses on the right, (2) MAI curves comparison with training MAI left and validation MAI right, and (3) a bar chart of final validation accuracy per dataset. Each plot uses basic matplotlib, includes clear titles and subtitles, and is saved with descriptive filenames in working_dir. After plotting, we compute final validation loss, MAI, and accuracy for each dataset and print them. All figures are closed after saving, and any errors are caught and printed without stopping execution. This provides both high-level comparison plots and dataset\u2010specific summary metrics.", null, null, null, null, null, "We load the experiment data and iterate over each dataset to create dataset\u2010specific visualizations: a combined loss/alignment plot per dataset (left: training & validation loss, right: training & validation alignment) and a separate MAI\u2010over\u2010epochs curve. Each dataset figure is wrapped in a try\u2010except to catch and report errors, and all figures are saved to working_dir with descriptive filenames. After the per\u2010dataset plots, we generate two comparison figures: one overlaying validation loss curves across all datasets and another overlaying MAI curves across datasets. These comparison plots also live in try\u2010except blocks, are clearly titled, and include legends to distinguish datasets. All figures use basic matplotlib, close after saving, and rely solely on the loaded numpy data.", "We will load the saved experiment data from disk and iterate over each dataset to produce dataset\u2010specific visualizations. For each dataset we will create two figures wrapped in try\u2010except blocks: one showing training and validation loss curves, and another showing training and validation alignment (1\u2212JSD) curves, each with clear titles and subtitles. All figures are saved into the working directory with descriptive filenames including the dataset name and plot type. After closing per\u2010dataset figures, we generate comparison plots across all datasets: training loss, validation loss, training alignment, and validation alignment, each overlaid on a single figure with legends. Each comparison figure also lives in its own try\u2010except block, has clear axis labels and a title, and is saved with a descriptive name. We ensure every figure is closed after saving to free resources and catch any exceptions during plotting. This approach offers both per\u2010dataset insights and cross\u2010dataset comparisons using basic matplotlib.", null, null, null, null], "ablation_name": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "hyperparam_name": ["learning_rate", null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null], "is_seed_node": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "parse_metrics_plan": ["Here\u2019s a script that loads the saved experiment data, iterates over each dataset\nand learning rate, extracts the final training/validation alignments and losses,\ncomputes test accuracy from the stored predictions, and prints each metric with\nclear labels at the global scope:", "", "", "", "The script starts by constructing the working directory path and loading the\nsaved NumPy dictionary. It then iterates over each dataset, pulling out the\nfinal values from the training/validation loss, alignment, and MAI lists. For\neach dataset it prints the dataset name followed by clearly labeled metrics\nincluding the final training loss, final validation loss, final training\nalignment score, final validation alignment score, final training MAI, final\nvalidation MAI, and the validation accuracy computed from the stored predictions\nand ground truth. All code is at global scope and runs immediately.", "The following script loads the saved experiment data from the `working`\ndirectory and iterates through each dataset\u2019s stored metrics. For each dataset\nit prints its name and then the final training and validation MAI values,\nclearly labeling them as \u201cFinal training MAI\u201d and \u201cFinal validation MAI.\u201d No\nplots are generated and the code runs immediately at the global scope.", "", "", "Below is a simple script that loads the saved experiment data from the working\ndirectory and iterates over each dataset entry. For each dataset it extracts the\nlast (final-epoch) train loss, validation loss, and MAI values and prints them\nwith clear, descriptive labels. The code runs immediately at the global scope\nwithout any guarded entry points.", "The script loads the saved experiment data, iterates through each dataset\u2019s\nmetrics, and extracts the final epoch values for training and validation loss,\nalignment, and MAI. It prints the dataset name first, followed by clearly\nlabeled metric names and their corresponding final values. The code runs\nimmediately upon execution without any special entry point.", "", "I will load the saved `experiment_data.npy` from the `working` folder, then for\neach dataset extract the final epoch\u2019s training and validation losses and\nalignments, the final MAI, and compute test accuracy from the stored predictions\nand ground truth. Finally, I will print the dataset name followed by each metric\nclearly labeled. The script runs immediately without needing an entry\u2010point\nguard.", "I will load the saved NumPy file from the designated working directory, iterate\nover each dataset\u2019s stored results, and extract the final epoch values for both\nthe MAI metric and the loss on training and validation splits. Each dataset\u2019s\nname is printed first, followed by clearly labeled outputs: \"Final training\nMAI,\" \"Final validation MAI,\" \"Final training loss,\" and \"Final validation\nloss.\" The script runs immediately at the global scope without any special entry\npoint.", "Here\u2019s a script that loads the saved experiment data, iterates over each dataset\nand learning rate, extracts the final training/validation alignments and losses,\ncomputes test accuracy from the stored predictions, and prints each metric with\nclear labels at the global scope:", "Here\u2019s a script that loads the saved experiment data, iterates over each dataset\nand learning rate, extracts the final training/validation alignments and losses,\ncomputes test accuracy from the stored predictions, and prints each metric with\nclear labels at the global scope:", "Here\u2019s a script that loads the saved experiment data, iterates over each dataset\nand learning rate, extracts the final training/validation alignments and losses,\ncomputes test accuracy from the stored predictions, and prints each metric with\nclear labels at the global scope:", ""], "parse_metrics_code": ["import os\nimport numpy as np\n\n# Define working directory and load the data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each dataset under the learning_rate key\nfor dataset_name, ds in experiment_data[\"learning_rate\"].items():\n    print(f\"{dataset_name.capitalize()} dataset:\")\n    lrs = ds[\"lrs\"]\n    # Loop over all learning rates\n    for idx, lr in enumerate(lrs):\n        train_aligns = ds[\"metrics\"][\"train\"][idx]\n        val_aligns = ds[\"metrics\"][\"val\"][idx]\n        train_losses = ds[\"losses\"][\"train\"][idx]\n        val_losses = ds[\"losses\"][\"val\"][idx]\n        preds = ds[\"predictions\"][idx]\n        gts = ds[\"ground_truth\"][idx]\n        # Extract final epoch values\n        final_train_alignment = train_aligns[-1]\n        final_val_alignment = val_aligns[-1]\n        final_train_loss = train_losses[-1]\n        final_val_loss = val_losses[-1]\n        # Compute test accuracy\n        test_accuracy = np.mean(preds == gts)\n        # Print metrics with clear labels\n        print(f\"  Learning rate {lr:.1e}:\")\n        print(f\"    Final training alignment: {final_train_alignment:.4f}\")\n        print(f\"    Final validation alignment: {final_val_alignment:.4f}\")\n        print(f\"    Final training loss: {final_train_loss:.4f}\")\n        print(f\"    Final validation loss: {final_val_loss:.4f}\")\n        print(f\"    Test accuracy: {test_accuracy:.4f}\")\n    print()\n", "", "", "", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate through each dataset and print final metrics\nfor ds_name, metrics in experiment_data.items():\n    print(f\"Dataset: {ds_name}\")\n    # Losses\n    train_loss = metrics[\"losses\"][\"train\"][-1]\n    val_loss = metrics[\"losses\"][\"val\"][-1]\n    print(f\"final training loss: {train_loss:.4f}\")\n    print(f\"final validation loss: {val_loss:.4f}\")\n    # Alignment scores\n    train_align = metrics[\"aligns\"][\"train\"][-1]\n    val_align = metrics[\"aligns\"][\"val\"][-1]\n    print(f\"final training alignment score: {train_align:.4f}\")\n    print(f\"final validation alignment score: {val_align:.4f}\")\n    # MAI scores\n    train_mai = metrics[\"mai\"][\"train\"][-1]\n    val_mai = metrics[\"mai\"][\"val\"][-1]\n    print(f\"final training MAI: {train_mai:.4f}\")\n    print(f\"final validation MAI: {val_mai:.4f}\")\n    # Validation accuracy\n    preds = metrics[\"predictions\"]\n    gts = metrics[\"ground_truth\"]\n    val_accuracy = np.mean(preds == gts)\n    print(f\"validation accuracy: {val_accuracy:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Load the experiment data from the working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate over each dataset and print the final MAI metrics\nfor dataset_name, dataset_info in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n    final_train_mai = dataset_info[\"metrics\"][\"train\"][-1]\n    final_val_mai = dataset_info[\"metrics\"][\"val\"][-1]\n    print(f\"Final training MAI: {final_train_mai:.4f}\")\n    print(f\"Final validation MAI: {final_val_mai:.4f}\\n\")\n", "", "", "import os\nimport numpy as np\n\n# Locate and load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate through each dataset and print final metrics\nfor dataset_name, results in experiment_data.items():\n    print(dataset_name)\n    train_losses = results[\"losses\"][\"train\"]\n    val_losses = results[\"losses\"][\"val\"]\n    mai_scores = results[\"metrics\"][\"MAI\"]\n\n    if train_losses:\n        final_train_loss = train_losses[-1]\n        print(f\"Final Train Loss: {final_train_loss:.4f}\")\n    if val_losses:\n        final_val_loss = val_losses[-1]\n        print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n    if mai_scores:\n        final_mai = mai_scores[-1]\n        print(f\"Final MAI: {final_mai:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Load the experiment data from the working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each dataset and print final metrics\nfor dataset_name, results in experiment_data.items():\n    metrics = results[\"metrics\"]\n    train_metrics = metrics[\"train\"]\n    val_metrics = metrics[\"val\"]\n\n    # Extract final epoch values\n    final_train_loss = train_metrics[\"loss\"][-1]\n    final_train_alignment = train_metrics[\"align\"][-1]\n    final_train_MAI = train_metrics[\"MAI\"][-1]\n    final_val_loss = val_metrics[\"loss\"][-1]\n    final_val_alignment = val_metrics[\"align\"][-1]\n    final_val_MAI = val_metrics[\"MAI\"][-1]\n\n    # Print the results\n    print(f\"Dataset {dataset_name}\")\n    print(f\"train loss: {final_train_loss:.4f}\")\n    print(f\"train alignment: {final_train_alignment:.4f}\")\n    print(f\"train MAI: {final_train_MAI:.4f}\")\n    print(f\"validation loss: {final_val_loss:.4f}\")\n    print(f\"validation alignment: {final_val_alignment:.4f}\")\n    print(f\"validation MAI: {final_val_MAI:.4f}\\n\")\n", "", "import os\nimport numpy as np\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\nfor dataset_name, metrics in experiment_data.items():\n    print(f\"Dataset: {dataset_name}\")\n    # final epoch metrics\n    final_train_loss = metrics[\"losses\"][\"train\"][-1]\n    final_train_align = metrics[\"alignments\"][\"train\"][-1]\n    final_val_loss = metrics[\"losses\"][\"val\"][-1]\n    final_val_align = metrics[\"alignments\"][\"val\"][-1]\n    final_mai = metrics[\"mai\"][-1]\n    # compute test accuracy\n    preds = metrics[\"predictions\"]\n    gts = metrics[\"ground_truth\"]\n    test_accuracy = (preds == gts).mean()\n    # print metrics\n    print(f\"Final training loss: {final_train_loss:.4f}\")\n    print(f\"Final training alignment: {final_train_align:.4f}\")\n    print(f\"Final validation loss: {final_val_loss:.4f}\")\n    print(f\"Final validation alignment: {final_val_align:.4f}\")\n    print(f\"Final MAI: {final_mai:.4f}\")\n    print(f\"Test accuracy: {test_accuracy:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Define the working directory and file path\nworking_dir = os.path.join(os.getcwd(), \"working\")\nfile_path = os.path.join(working_dir, \"experiment_data.npy\")\n\n# Load the experiment data\nexperiment_data = np.load(file_path, allow_pickle=True).item()\n\n# Iterate through each dataset and print the final metrics\nfor ds_name, ds_data in experiment_data.items():\n    train_metrics = ds_data[\"metrics\"][\"train\"]\n    val_metrics = ds_data[\"metrics\"][\"val\"]\n    train_losses = ds_data[\"losses\"][\"train\"]\n    val_losses = ds_data[\"losses\"][\"val\"]\n\n    final_train_mai = train_metrics[-1]\n    final_val_mai = val_metrics[-1]\n    final_train_loss = train_losses[-1]\n    final_val_loss = val_losses[-1]\n\n    print(f\"Dataset: {ds_name}\")\n    print(f\"Final training MAI: {final_train_mai:.4f}\")\n    print(f\"Final validation MAI: {final_val_mai:.4f}\")\n    print(f\"Final training loss: {final_train_loss:.4f}\")\n    print(f\"Final validation loss: {final_val_loss:.4f}\\n\")\n", "import os\nimport numpy as np\n\n# Define working directory and load the data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each dataset under the learning_rate key\nfor dataset_name, ds in experiment_data[\"learning_rate\"].items():\n    print(f\"{dataset_name.capitalize()} dataset:\")\n    lrs = ds[\"lrs\"]\n    # Loop over all learning rates\n    for idx, lr in enumerate(lrs):\n        train_aligns = ds[\"metrics\"][\"train\"][idx]\n        val_aligns = ds[\"metrics\"][\"val\"][idx]\n        train_losses = ds[\"losses\"][\"train\"][idx]\n        val_losses = ds[\"losses\"][\"val\"][idx]\n        preds = ds[\"predictions\"][idx]\n        gts = ds[\"ground_truth\"][idx]\n        # Extract final epoch values\n        final_train_alignment = train_aligns[-1]\n        final_val_alignment = val_aligns[-1]\n        final_train_loss = train_losses[-1]\n        final_val_loss = val_losses[-1]\n        # Compute test accuracy\n        test_accuracy = np.mean(preds == gts)\n        # Print metrics with clear labels\n        print(f\"  Learning rate {lr:.1e}:\")\n        print(f\"    Final training alignment: {final_train_alignment:.4f}\")\n        print(f\"    Final validation alignment: {final_val_alignment:.4f}\")\n        print(f\"    Final training loss: {final_train_loss:.4f}\")\n        print(f\"    Final validation loss: {final_val_loss:.4f}\")\n        print(f\"    Test accuracy: {test_accuracy:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Define working directory and load the data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each dataset under the learning_rate key\nfor dataset_name, ds in experiment_data[\"learning_rate\"].items():\n    print(f\"{dataset_name.capitalize()} dataset:\")\n    lrs = ds[\"lrs\"]\n    # Loop over all learning rates\n    for idx, lr in enumerate(lrs):\n        train_aligns = ds[\"metrics\"][\"train\"][idx]\n        val_aligns = ds[\"metrics\"][\"val\"][idx]\n        train_losses = ds[\"losses\"][\"train\"][idx]\n        val_losses = ds[\"losses\"][\"val\"][idx]\n        preds = ds[\"predictions\"][idx]\n        gts = ds[\"ground_truth\"][idx]\n        # Extract final epoch values\n        final_train_alignment = train_aligns[-1]\n        final_val_alignment = val_aligns[-1]\n        final_train_loss = train_losses[-1]\n        final_val_loss = val_losses[-1]\n        # Compute test accuracy\n        test_accuracy = np.mean(preds == gts)\n        # Print metrics with clear labels\n        print(f\"  Learning rate {lr:.1e}:\")\n        print(f\"    Final training alignment: {final_train_alignment:.4f}\")\n        print(f\"    Final validation alignment: {final_val_alignment:.4f}\")\n        print(f\"    Final training loss: {final_train_loss:.4f}\")\n        print(f\"    Final validation loss: {final_val_loss:.4f}\")\n        print(f\"    Test accuracy: {test_accuracy:.4f}\")\n    print()\n", "import os\nimport numpy as np\n\n# Define working directory and load the data\nworking_dir = os.path.join(os.getcwd(), \"working\")\ndata_path = os.path.join(working_dir, \"experiment_data.npy\")\nexperiment_data = np.load(data_path, allow_pickle=True).item()\n\n# Iterate through each dataset under the learning_rate key\nfor dataset_name, ds in experiment_data[\"learning_rate\"].items():\n    print(f\"{dataset_name.capitalize()} dataset:\")\n    lrs = ds[\"lrs\"]\n    # Loop over all learning rates\n    for idx, lr in enumerate(lrs):\n        train_aligns = ds[\"metrics\"][\"train\"][idx]\n        val_aligns = ds[\"metrics\"][\"val\"][idx]\n        train_losses = ds[\"losses\"][\"train\"][idx]\n        val_losses = ds[\"losses\"][\"val\"][idx]\n        preds = ds[\"predictions\"][idx]\n        gts = ds[\"ground_truth\"][idx]\n        # Extract final epoch values\n        final_train_alignment = train_aligns[-1]\n        final_val_alignment = val_aligns[-1]\n        final_train_loss = train_losses[-1]\n        final_val_loss = val_losses[-1]\n        # Compute test accuracy\n        test_accuracy = np.mean(preds == gts)\n        # Print metrics with clear labels\n        print(f\"  Learning rate {lr:.1e}:\")\n        print(f\"    Final training alignment: {final_train_alignment:.4f}\")\n        print(f\"    Final validation alignment: {final_val_alignment:.4f}\")\n        print(f\"    Final training loss: {final_train_loss:.4f}\")\n        print(f\"    Final validation loss: {final_val_loss:.4f}\")\n        print(f\"    Test accuracy: {test_accuracy:.4f}\")\n    print()\n", ""], "parse_term_out": ["['Synthetic dataset:', '\\n', '  Learning rate 1.0e-04:', '\\n', '    Final\ntraining alignment: 0.9929', '\\n', '    Final validation alignment: 0.9929',\n'\\n', '    Final training loss: 1.0162', '\\n', '    Final validation loss:\n1.0106', '\\n', '    Test accuracy: 0.6000', '\\n', '  Learning rate 5.0e-04:',\n'\\n', '    Final training alignment: 0.9921', '\\n', '    Final validation\nalignment: 0.9915', '\\n', '    Final training loss: 0.7943', '\\n', '    Final\nvalidation loss: 0.7817', '\\n', '    Test accuracy: 0.8350', '\\n', '  Learning\nrate 1.0e-03:', '\\n', '    Final training alignment: 0.9917', '\\n', '    Final\nvalidation alignment: 0.9907', '\\n', '    Final training loss: 0.5274', '\\n', '\nFinal validation loss: 0.5101', '\\n', '    Test accuracy: 0.9050', '\\n', '\nLearning rate 5.0e-03:', '\\n', '    Final training alignment: 0.9988', '\\n', '\nFinal validation alignment: 0.9989', '\\n', '    Final training loss: 0.0982',\n'\\n', '    Final validation loss: 0.1039', '\\n', '    Test accuracy: 0.9600',\n'\\n', '  Learning rate 1.0e-02:', '\\n', '    Final training alignment: 0.9991',\n'\\n', '    Final validation alignment: 0.9986', '\\n', '    Final training loss:\n0.0588', '\\n', '    Final validation loss: 0.0739', '\\n', '    Test accuracy:\n0.9650', '\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "", "", "", "['Dataset: ag_news', '\\n', 'final training loss: 0.4711', '\\n', 'final\nvalidation loss: 0.6785', '\\n', 'final training alignment score: 0.9999', '\\n',\n'final validation alignment score: 0.9999', '\\n', 'final training MAI: 0.9191',\n'\\n', 'final validation MAI: 0.8863', '\\n', 'validation accuracy: 0.7800\\n',\n'\\n', 'Dataset: yelp_polarity', '\\n', 'final training loss: 0.2558', '\\n',\n'final validation loss: 0.3732', '\\n', 'final training alignment score: 0.9999',\n'\\n', 'final validation alignment score: 0.9999', '\\n', 'final training MAI:\n0.9537', '\\n', 'final validation MAI: 0.9361', '\\n', 'validation accuracy:\n0.8440\\n', '\\n', 'Dataset: imdb', '\\n', 'final training loss: 0.0000', '\\n',\n'final validation loss: 0.0000', '\\n', 'final training alignment score: 1.0000',\n'\\n', 'final validation alignment score: 1.0000', '\\n', 'final training MAI:\n1.0000', '\\n', 'final validation MAI: 1.0000', '\\n', 'validation accuracy:\n1.0000\\n', '\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: ag_news', '\\n', 'Final training MAI: 0.9838', '\\n', 'Final validation\nMAI: 0.8967\\n', '\\n', 'Dataset: dbpedia_14', '\\n', 'Final training MAI: 0.9971',\n'\\n', 'Final validation MAI: 0.9961\\n', '\\n', 'Dataset: yelp_polarity', '\\n',\n'Final training MAI: 0.9837', '\\n', 'Final validation MAI: 0.9548\\n', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "", "", "['ag_news', '\\n', 'Traceback (most recent call last):\\n  File \"runfile.py\", line\n14, in <module>\\n    mai_scores = results[\"metrics\"][\"MAI\"]\\n\n~~~~~~~^^^^^^^^^^^\\nKeyError: \\'metrics\\'\\n', 'Execution time: a moment seconds\n(time limit is an hour).']", "['Dataset ag_news', '\\n', 'train loss: 0.0288', '\\n', 'train alignment: 0.9996',\n'\\n', 'train MAI: 0.9951', '\\n', 'validation loss: 0.7197', '\\n', 'validation\nalignment: 0.9945', '\\n', 'validation MAI: 0.9011\\n', '\\n', 'Dataset imdb',\n'\\n', 'train loss: 0.0000', '\\n', 'train alignment: 1.0000', '\\n', 'train MAI:\n1.0000', '\\n', 'validation loss: 0.0000', '\\n', 'validation alignment: 1.0000',\n'\\n', 'validation MAI: 1.0000\\n', '\\n', 'Dataset yelp_review_full', '\\n', 'train\nloss: 0.0468', '\\n', 'train alignment: 0.9986', '\\n', 'train MAI: 0.9909', '\\n',\n'validation loss: 1.6229', '\\n', 'validation alignment: 0.9765', '\\n',\n'validation MAI: 0.7694\\n', '\\n', 'Execution time: a moment seconds (time limit\nis an hour).']", "", "['Dataset: ag_news', '\\n', 'Final training loss: 0.3672', '\\n', 'Final training\nalignment: 0.9993', '\\n', 'Final validation loss: 0.3472', '\\n', 'Final\nvalidation alignment: 0.9995', '\\n', 'Final MAI: 0.9427', '\\n', 'Test accuracy:\n0.8920\\n', '\\n', 'Dataset: yelp_polarity', '\\n', 'Final training loss: 0.3435',\n'\\n', 'Final training alignment: 0.9999', '\\n', 'Final validation loss: 0.3789',\n'\\n', 'Final validation alignment: 0.9999', '\\n', 'Final MAI: 0.9047', '\\n',\n'Test accuracy: 0.8240\\n', '\\n', 'Dataset: dbpedia_14', '\\n', 'Final training\nloss: 0.2103', '\\n', 'Final training alignment: 0.9971', '\\n', 'Final validation\nloss: 0.1728', '\\n', 'Final validation alignment: 0.9978', '\\n', 'Final MAI:\n0.9858', '\\n', 'Test accuracy: 0.9720\\n', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset: ag_news', '\\n', 'Final training MAI: 0.9980', '\\n', 'Final validation\nMAI: 0.9288', '\\n', 'Final training loss: 0.0111', '\\n', 'Final validation loss:\n0.5560\\n', '\\n', 'Dataset: imdb', '\\n', 'Final training MAI: 0.9990', '\\n',\n'Final validation MAI: 0.9312', '\\n', 'Final training loss: 0.0055', '\\n',\n'Final validation loss: 0.5738\\n', '\\n', 'Dataset: yelp_polarity', '\\n', 'Final\ntraining MAI: 0.9981', '\\n', 'Final validation MAI: 0.9384', '\\n', 'Final\ntraining loss: 0.0108', '\\n', 'Final validation loss: 0.4506\\n', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Synthetic dataset:', '\\n', '  Learning rate 1.0e-04:', '\\n', '    Final\ntraining alignment: 0.9929', '\\n', '    Final validation alignment: 0.9929',\n'\\n', '    Final training loss: 1.0162', '\\n', '    Final validation loss:\n1.0106', '\\n', '    Test accuracy: 0.6000', '\\n', '  Learning rate 5.0e-04:',\n'\\n', '    Final training alignment: 0.9921', '\\n', '    Final validation\nalignment: 0.9915', '\\n', '    Final training loss: 0.7943', '\\n', '    Final\nvalidation loss: 0.7817', '\\n', '    Test accuracy: 0.8350', '\\n', '  Learning\nrate 1.0e-03:', '\\n', '    Final training alignment: 0.9917', '\\n', '    Final\nvalidation alignment: 0.9907', '\\n', '    Final training loss: 0.5274', '\\n', '\nFinal validation loss: 0.5101', '\\n', '    Test accuracy: 0.9050', '\\n', '\nLearning rate 5.0e-03:', '\\n', '    Final training alignment: 0.9988', '\\n', '\nFinal validation alignment: 0.9989', '\\n', '    Final training loss: 0.0982',\n'\\n', '    Final validation loss: 0.1039', '\\n', '    Test accuracy: 0.9600',\n'\\n', '  Learning rate 1.0e-02:', '\\n', '    Final training alignment: 0.9991',\n'\\n', '    Final validation alignment: 0.9986', '\\n', '    Final training loss:\n0.0588', '\\n', '    Final validation loss: 0.0739', '\\n', '    Test accuracy:\n0.9650', '\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Synthetic dataset:', '\\n', '  Learning rate 1.0e-04:', '\\n', '    Final\ntraining alignment: 0.9929', '\\n', '    Final validation alignment: 0.9929',\n'\\n', '    Final training loss: 1.0162', '\\n', '    Final validation loss:\n1.0106', '\\n', '    Test accuracy: 0.6000', '\\n', '  Learning rate 5.0e-04:',\n'\\n', '    Final training alignment: 0.9921', '\\n', '    Final validation\nalignment: 0.9915', '\\n', '    Final training loss: 0.7943', '\\n', '    Final\nvalidation loss: 0.7817', '\\n', '    Test accuracy: 0.8350', '\\n', '  Learning\nrate 1.0e-03:', '\\n', '    Final training alignment: 0.9917', '\\n', '    Final\nvalidation alignment: 0.9907', '\\n', '    Final training loss: 0.5274', '\\n', '\nFinal validation loss: 0.5101', '\\n', '    Test accuracy: 0.9050', '\\n', '\nLearning rate 5.0e-03:', '\\n', '    Final training alignment: 0.9988', '\\n', '\nFinal validation alignment: 0.9989', '\\n', '    Final training loss: 0.0982',\n'\\n', '    Final validation loss: 0.1039', '\\n', '    Test accuracy: 0.9600',\n'\\n', '  Learning rate 1.0e-02:', '\\n', '    Final training alignment: 0.9991',\n'\\n', '    Final validation alignment: 0.9986', '\\n', '    Final training loss:\n0.0588', '\\n', '    Final validation loss: 0.0739', '\\n', '    Test accuracy:\n0.9650', '\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Synthetic dataset:', '\\n', '  Learning rate 1.0e-04:', '\\n', '    Final\ntraining alignment: 0.9929', '\\n', '    Final validation alignment: 0.9929',\n'\\n', '    Final training loss: 1.0162', '\\n', '    Final validation loss:\n1.0106', '\\n', '    Test accuracy: 0.6000', '\\n', '  Learning rate 5.0e-04:',\n'\\n', '    Final training alignment: 0.9921', '\\n', '    Final validation\nalignment: 0.9915', '\\n', '    Final training loss: 0.7943', '\\n', '    Final\nvalidation loss: 0.7817', '\\n', '    Test accuracy: 0.8350', '\\n', '  Learning\nrate 1.0e-03:', '\\n', '    Final training alignment: 0.9917', '\\n', '    Final\nvalidation alignment: 0.9907', '\\n', '    Final training loss: 0.5274', '\\n', '\nFinal validation loss: 0.5101', '\\n', '    Test accuracy: 0.9050', '\\n', '\nLearning rate 5.0e-03:', '\\n', '    Final training alignment: 0.9988', '\\n', '\nFinal validation alignment: 0.9989', '\\n', '    Final training loss: 0.0982',\n'\\n', '    Final validation loss: 0.1039', '\\n', '    Test accuracy: 0.9600',\n'\\n', '  Learning rate 1.0e-02:', '\\n', '    Final training alignment: 0.9991',\n'\\n', '    Final validation alignment: 0.9986', '\\n', '    Final training loss:\n0.0588', '\\n', '    Final validation loss: 0.0739', '\\n', '    Test accuracy:\n0.9650', '\\n', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", ""], "parse_exc_type": [null, null, null, null, null, null, null, null, "KeyError", null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, {"args": ["metrics"]}, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, [["/home/chenhui/AI-Scientist-v2/ai_scientist/treesearch/interpreter.py", 144, "_run_session", "exec(compile(code, self.agent_file_name, \"exec\"), global_scope)"], ["runfile.py", 14, "<module>", "mai_scores = results[\"metrics\"][\"MAI\"]"]], null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3"]};

// Add log directory path and stage info to the tree data
treeStructData.log_dir_path = window.location.pathname.split('/').slice(0, -1).join('/');
treeStructData.current_stage = window.location.pathname.includes('stage_')
  ? window.location.pathname.split('stage_')[1].split('/')[0]
  : 'Stage_1';

// Initialize background color
window.bgColCurrent = bgCol;

// Function to set background color that can be called from the console
function setBackgroundColor(color) {
  // Update the global color
  updateBackgroundColor(color);

  // Refresh the current sketch to apply the new background color
  if (currentStage) {
    startSketch(currentStage);
  }
}

// Load all stage data and initialize the visualization
loadAllStageData(treeStructData);

    </script>
    <title>AI Scientist-v2 Visualization</title>
    <style>
      body,
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background-color: #ffffff;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      }
      #canvas-container {
        position: absolute;
        left: 0;
        top: 0;
        width: 40vw;
        height: 100vh;
        background-color: inherit;
        padding-top: 40px;
      }
      canvas {
        float: left;
        height: 100vh;
        width: 100vw;
      }
      #text-container {
        float: right;
        height: 100vh;
        width: 50vw;
        background-color: #282c34;
        overflow: auto;
      }
      #plan {
        /* border-left: 2px solid #282c34; */
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
      }
      #plot_plan {
        background-color: #282c34;
        color: #f2f0e7;
        min-height: 5rem;
        padding: 1em 0 1em 1em;
        white-space: pre-wrap;
      }
      #exec_time_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exec_time {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #exc_info {
        margin-top: 20px;
        padding: 10px;
        background-color: #2c1f1f;
        border-left: 3px solid #ff5555;
        color: #f2f0e7;
      }
      #metrics {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
      }
      #vlm_feedback {
        margin-top: 20px;
        padding: 10px;
        background-color: #1f2c2f;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      #vlm_feedback p {
        margin: 0.5em 0;
        white-space: pre-wrap;
      }
      .datasets_successfully_tested {
        margin-top: 20px;
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        border-left: 3px solid #55ff55;
      }
      .plots-container {
        float: right;
        width: 50vw;
        padding: 1rem;
        background-color: #282c34;
        margin-top: 1rem;
      }

      .plot-item {
        flex: 1 1 300px;
        max-width: 100%;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }

      .plot-item img {
        width: 100%;
        height: auto;
        border-radius: 4px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        display: block;
      }

      .metric-group {
        margin-bottom: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .metric-table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 10px;
      }

      .metric-table th,
      .metric-table td {
        padding: 8px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .metric-table th {
        background-color: #363b44;
      }

      /* Styles for tabs */
      .tabs-container {
        position: fixed;
        top: 0;
        left: 0;
        width: 49vw;
        background-color: #000000;
        z-index: 10;
        display: flex;
        padding: 0;
      }

      .tab {
        cursor: pointer;
        padding: 10px 15px;
        background-color: #333;
        color: #f2f0e7;
        border: none;
        outline: none;
        transition: background-color 0.3s;
        flex: 1;
        text-align: center;
      }

      .tab:hover {
        background-color: #444;
      }

      .tab.active {
        background-color: #4c76af;
        font-weight: bold;
      }

      .tab.disabled {
        opacity: 0.5;
        cursor: not-allowed;
        background-color: #282c34;
      }

      .tab-content {
        display: none;
        padding-top: 40px; /* Space for tabs */
      }

      .tab-content.active {
        display: block;
      }

      .stage-info {
        padding: 10px;
        background-color: #282c34;
        color: #f2f0e7;
        margin-bottom: 10px;
        font-size: 0.9em;
      }

      .stage-status {
        display: inline-block;
        padding: 3px 6px;
        border-radius: 3px;
        margin-left: 8px;
        font-size: 0.8em;
      }

      .stage-status.completed {
        background-color: #4caf50;
      }

      .stage-status.in-progress {
        background-color: #2196f3;
      }

      .stage-status.not-started {
        background-color: #9e9e9e;
      }
    </style>
  </head>
  <body>
    <div class="tabs-container" id="stage-tabs">
      <button class="tab" data-stage="Stage_1" onclick="selectStage('Stage_1')">Stage 1</button>
      <button class="tab" data-stage="Stage_2" onclick="selectStage('Stage_2')">Stage 2</button>
      <button class="tab" data-stage="Stage_3" onclick="selectStage('Stage_3')">Stage 3</button>
      <button class="tab" data-stage="Stage_4" onclick="selectStage('Stage_4')">Stage 4</button>
    </div>

    <div id="canvas-container"></div>

    <pre id="text-container">
        <div id="stage-info" class="stage-info"></div>
        <div id="plan"></div>
        <hr>
        <div id="exc_info"></div>
        <hr>
        <div id="exec_time"></div>
        <hr>
        <div id="exec_time_feedback"></div>
        <hr>
        <div id="metrics"></div>
        <hr>
        <div id="plot_plan"></div>
        <hr>
        <div class="plots-container" id="plots"></div>
        <hr>
        <div id="vlm_feedback"></div>
        <hr>
        <div id="datasets_successfully_tested"></div>
        <hr>
        <code id="code" class="language-python"></code>
        <hr>
        <code id="plot_code" class="language-python"></code>
    </pre>
  </body>
</html>
